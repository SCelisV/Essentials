#export PYSPARK_DRIVER_PYTHON=ipython
#PYSPARK_DRIVER_PYTHON_OPTS=ipython
#pyspark

spark

tempDF = spark.read.option("inferSchema", "true").csv("/user/scelisdev02/1800_1801.csv") 
tempDF.show() 
tempDF.printSchema() 

from pyspark.sql.types import *

devColumns = [
StructField("estacion",StringType()),
StructField("fecha",StringType()),
StructField("tipo",StringType()),
StructField("temperatura",DoubleType())]

devSchema = StructType(devColumns)

temp01DF = spark.read.schema(devSchema).csv("/user/scelisdev02/1800_1801.csv")
temp01DF.printSchema()
temp01DF.show()

# sólo en este caso porque nos dan los grados centigrados múltiplicado por 100, por lo tanto tenemos 
# que dividir por 100
def CtoF(celsius): return (0.01* celsius*9/5) + 32

from pyspark.sql.functions import *

fnCol = temp01DF.tipo
tminCol = (fnCol == "TMIN")    
temp01DF.select( "estacion", "fecha", "tipo", "temperatura").where(tminCol).show()
temp01DF.select( "estacion", "fecha", temp01DF["fecha"].substr(0, 4).alias("anyo"), "tipo", "temperatura").show()

temp01DF.where(tminCol).select( "estacion", "fecha", temp01DF["fecha"].substr(0, 4).alias("anyo"), "tipo", "temperatura").show()


temp01DF. where(tminCol). select( "estacion", temp01DF["fecha"].substr(0, 4). alias("anyo"), "temperatura"). groupBy("estacion", "anyo"). min("temperatura"). withColumnRenamed("min(temperatura)","min_temp"). select(temp01DF.estacion, "anyo", CtoF(format_number("min_temp",2))). show()

temp01DF. where(tminCol). select( "estacion", temp01DF["fecha"].substr(0, 4). alias("anyo"), "temperatura"). groupBy("estacion", "anyo"). min("temperatura"). withColumnRenamed("min(temperatura)","min_temp"). select(temp01DF.estacion, "anyo", CtoF(format_number("min_temp",2))). withColumnRenamed("((((format_number(min_temp, 2) * 0.01) * 9) / 5) + 32)", "minima") .show() 

temp02DF = temp01DF. where(tminCol). select( "estacion", temp01DF["fecha"].substr(0, 4). alias("anyo"), "temperatura"). groupBy("estacion", "anyo"). min("temperatura"). withColumnRenamed("min(temperatura)","min_temp"). select(temp01DF.estacion, "anyo", CtoF(format_number("min_temp",2))). withColumnRenamed("((((format_number(min_temp, 2) * 0.01) * 9) / 5) + 32)", "minima")                         
temp02DF.printSchema()
temp02DF.show()   

temp02DF. select("estacion", "anyo", format_number("minima", 2) .alias("minima")). sort(temp02DF.anyo.desc(), "estacion").show()

# en una sóla línea sería:

# ordena ascendente por estacion
temp01DF. where(tminCol). select( "estacion", temp01DF["fecha"].substr(0, 4). alias("anyo"), "temperatura"). groupBy("estacion", "anyo"). min("temperatura"). withColumnRenamed("min(temperatura)","min_temp"). select(temp01DF.estacion, "anyo", CtoF(format_number("min_temp",2))). withColumnRenamed("((((format_number(min_temp, 2) * 0.01) * 9) / 5) + 32)", "minima") .sort(temp01DF.estacion) . show()

# ordena descendente por estacion
temp01DF. where(tminCol). select( "estacion", temp01DF["fecha"].substr(0, 4). alias("anyo"), "temperatura"). groupBy("estacion", "anyo"). min("temperatura"). withColumnRenamed("min(temperatura)","min_temp"). select(temp01DF.estacion, "anyo", CtoF(format_number("min_temp",2))). withColumnRenamed("((((format_number(min_temp, 2) * 0.01) * 9) / 5) + 32)", "minima") .sort(temp01DF.estacion.desc()) . show()

# ordena ascendente por año
temp01DF. where(tminCol). select( "estacion", temp01DF["fecha"].substr(0, 4). alias("anyo"), "temperatura"). groupBy("estacion", "anyo"). min("temperatura"). withColumnRenamed("min(temperatura)","min_temp"). select(temp01DF.estacion, "anyo", CtoF(format_number("min_temp",2))). withColumnRenamed("((((format_number(min_temp, 2) * 0.01) * 9) / 5) + 32)", "minima") .sort("anyo") . show()

# ordena descendente por año
temp01DF. where(tminCol). select( "estacion", temp01DF["fecha"].substr(0, 4). alias("anyo"), "temperatura"). groupBy("estacion", "anyo"). min("temperatura"). withColumnRenamed("min(temperatura)","min_temp"). select(temp01DF.estacion, "anyo", CtoF(format_number("min_temp",2))). withColumnRenamed("((((format_number(min_temp, 2) * 0.01) * 9) / 5) + 32)", "minima") .sort(col("anyo").desc()) . show()

# ordena descendente por año, y ascendente por estacion
temp01DF. where(tminCol). select( "estacion", temp01DF["fecha"].substr(0, 4). alias("anyo"), "temperatura"). groupBy("estacion", "anyo"). min("temperatura"). withColumnRenamed("min(temperatura)","min_temp"). select(temp01DF.estacion, "anyo", CtoF(format_number("min_temp",2))). withColumnRenamed("((((format_number(min_temp, 2) * 0.01) * 9) / 5) + 32)", "minima") .sort(col("anyo").desc(), temp01DF.estacion) . show()

# ordena descendente por año, y ascendente por estacion
temp01DF. where(tminCol). select( "estacion", temp01DF["fecha"].substr(0, 4). alias("anyo"), "temperatura"). groupBy("estacion", "anyo"). min("temperatura"). withColumnRenamed("min(temperatura)","min_temp"). select(temp01DF.estacion, "anyo", format_number(col("min_temp") * 0.01 * (9.0/5.0) + 32 ,2)). withColumnRenamed("format_number((((min_temp * 0.01) * 1.8) + 32), 2)", "minima").  sort(col("anyo").desc(), temp01DF.estacion) . show()

temp01DF. where(tminCol). select( "estacion", temp01DF["fecha"].substr(0, 4). alias("anyo"), "temperatura"). groupBy("estacion", "anyo"). min("temperatura"). withColumnRenamed("min(temperatura)","min_temp"). select(temp01DF.estacion, "anyo", format_number(CtoF(col("min_temp")), 2)). withColumnRenamed("format_number(((((min_temp * 0.01) * 9) / 5) + 32), 2)", "minima").  sort(col("anyo").desc(), temp01DF.estacion) . show()

# or
from pyspark.sql.types import *

devColumns = [
StructField("estacion",StringType()),
StructField("fecha",StringType()),
StructField("tipo",StringType()),
StructField("temperatura",DoubleType())]

devSchema = StructType(devColumns)

temp01DF = spark.read.schema(devSchema).csv("/user/scelisdev02/1800_1801.csv")
temp01DF.printSchema()
temp01DF.show(5)   


schema = """
  estacion string,
  fecha string,
  tipo string,
  temperatura double
  """

temp01DF = spark.read.schema(schema).csv("/user/scelisdev02/1800_1801.csv")
temp01DF.printSchema()
temp01DF.show(5)   

# sólo en este caso porque nos dan los grados centigrados múltiplicado por 100, por lo tanto tenemos 
# que dividir por 100
def CtoF(celsius): return (0.01* celsius*9/5) + 32

from pyspark.sql.functions import *

fnCol = temp01DF.tipo
tminCol = (fnCol == "TMIN")    

# or

temp01DF.\
where(tminCol).\
select("estacion", temp01DF["fecha"].substr(0, 4).alias("anyo"), "temperatura").\
groupBy("estacion", "anyo").\
min("temperatura").\
withColumnRenamed("min(temperatura)", "min_temp").\
select(temp01DF.estacion, "anyo", format_number(CtoF(col("min_temp")), 2)). \
withColumnRenamed("format_number(((((min_temp * 0.01) * 9) / 5) + 32), 2)", "minima"). \
sort(col("anyo").desc(), temp01DF.estacion) . \
show()

# or

temp01DF.\
where(temp01DF.tipo == "TMIN").\
select("estacion", temp01DF["fecha"].substr(0, 4).alias("anyo"), "temperatura").\
groupBy("estacion", "anyo").\
min("temperatura").\
withColumnRenamed("min(temperatura)", "min_temp").\
select(temp01DF.estacion, "anyo", format_number(CtoF(col("min_temp")), 2)). \
withColumnRenamed("format_number(((((min_temp * 0.01) * 9) / 5) + 32), 2)", "minima"). \
sort(col("anyo").desc(), temp01DF.estacion) . \
show()

# or

temp01DF.\
where(temp01DF.tipo == "TMIN").\
select("estacion", temp01DF["fecha"].substr(0, 4).alias("anyo"), "temperatura").\
groupBy("estacion", "anyo").\
min("temperatura").\
withColumnRenamed("min(temperatura)", "min_temp").\
select( temp01DF.estacion, "anyo", format_number((col("min_temp") * 0.01 * (9.0 / 5.0) + 32.0), 2).alias("minima")).\
sort(col("anyo").desc(), temp01DF.estacion) . \
show()
