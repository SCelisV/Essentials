
in_dir = out_dir

#(spark. read. option ( "sep", "\t" ). csv( in_dir ). show( 10 ) )
# (spark. read. text( in_dir ). orderBy ( "value" ). show( 10, truncate = False  ) )
# (spark. read. json( in_dir ). orderBy ( "order_date" ). show( 10 ) )
# (spark.read. load( in_dir ).  orderBy( "customer_state" ).  show( 10 ) )
#(spark.read.  text( "dataset/result/scenario15/solution" ).  orderBy( "value" ).  show( 20, truncate=False ) )
# spark.read.  text( out_dir ).  orderBy ( "value" ).  show( 10, false )
#(spark.read.  text( "dataset/result/scenario22/solution" ).  show( 5 ) )
#(spark.read.  text( "dataset/result/scenario23/solution" ).  orderBy( "value" ).  show( 10 ) )
# (spark.read.  orc( "dataset/result/scenario18/solution" ).  show( 6 ) )
# df = ( spark.read.table( in_dir ) )
# df.printSchema( )
# df.orderBy( "customer_state" )
# df.show( 10 )
# (spark.read. table( "categories_partitioned" ). orderBy( "category_id" ).  show( 10 ) )
# (spark.read. table ( "customer_replica_parquet" ). show( 10 ) )
# (spark. read. json( in_dir ). orderBy ( "order_date" ). show( 10 ) )
# (spark. read. text ( "dataset/solutions/scq06" ). orderBy ( "value" ). show( 10, truncate = False  ) )
(spark. read. text ( in_dir ). orderBy ( "value" ). show( 10, truncate = False  ) )

