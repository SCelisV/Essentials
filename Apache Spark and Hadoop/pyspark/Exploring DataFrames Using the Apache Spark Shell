#------------------
#Hands-On Exercise: Exploring DataFrames Using the Apache Spark Shell
#------------------

#export PYSPARK_DRIVER_PYTHON=ipython
#PYSPARK_DRIVER_PYTHON_OPTS=ipython
#pyspark

spark

devDF = spark.read.json("/devsh_loudacre/devices.json")

devDF.printSchema()                                                         
devDF.show(5)

rows = devDF.take(5)
type(rows)
for row in rows: print(row)

devDF.count()

makeModelDF = devDF.select("make","model")
makeModelDF.printSchema()
makeModelDF.count()
makeModelDF.show()
makeModelDF.select("make", "model").where("make = 'Ronin'").show()
devDF.select("devnum","make","model").where("make = 'Ronin'").show()

#%ed namefile