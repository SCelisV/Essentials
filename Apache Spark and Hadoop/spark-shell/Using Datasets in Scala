//------------------
//Hands-On Exercise: Using Datasets in Scala
//------------------

// scelisdev03@cluster-cca175-m:~/training_materials/devsh/data$ hdfs dfs -ls /devsh_loudacre/
// scelisdev03@cluster-cca175-m:~/training_materials/devsh/data$ hdfs dfs -put weblogs /devsh_loudacre/
// scelisdev03@cluster-cca175-m:~/training_materials/devsh/data$ hdfs dfs -ls /devsh_loudacre/
spark
import spark.implicits._ // required if not running in shell

case class AccountIP (id: Int, ip: String)
val accountIPRDD = sc. textFile("/devsh_loudacre/weblogs").
    map(line => line.split(' ')).
    map(fields => new AccountIP(fields(2).toInt,fields(0)))

val accountIPDS = spark.createDataset(accountIPRDD)
accountIPDS.getClass
accountIPDS.printSchema
accountIPDS.show

//typed transformation—distinct - (operations that return typed Datasets)
val distinctIPDS = accountIPDS.distinct
distinctIPDS.printSchema
distinctIPDS.show

//untyped transformation—groupBy/count. - (those that return Row Datasets)
val accountIPCountDS = distinctIPDS.groupBy("id","ip").count
accountIPCountDS.printSchema
accountIPCountDS.show

//(returns a DataFrameWriter)
// hdfs://cluster-cca175-m/devsh_loudacre/accountIPS already exists - OJO borrar primero
// hdfs dfs -rm -R /devsh_loudacre/accountIPS
accountIPDS.write.save("/devsh_loudacre/accountIPS")

val accountIPDF = spark.read.load("/devsh_loudacre/accountIPS")
accountIPDF.getClass
accountIPDF.printSchema
accountIPDF.show

// Crear una vista del dataset y hacer consultas
accountIPDS.createOrReplaceTempView("vaccount_ips")
val qryDF = spark.sql("SELECT *  FROM vaccount_ips")
val qryDF = spark.sql("SELECT count(*)  FROM vaccount_ips")
val qryDF = spark.sql("SELECT DISTINCT id, ip FROM vaccount_ips")
qryDF.getClass
qryDF.printSchema
qryDF.show

