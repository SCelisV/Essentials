Unix and Linux Essentials

=================
Shell Programming
Perl Programming
Java Programming
=================

su -

In the next lesson, you will learn some historical information about how UNIX and Linux operating systems has been created and also some of the basics about those operating systems which will allow you to actually execute comments to interact with the main component of those operating systems.

So in the first part, I will describe how UNIX and Linux has been created, and I will give you some design information about those two operating systems. And in the second part, you will learn how to actually execute commands from the command line-- commands that will be, of course, interpreted by the operating system carrying it out.

So let's start with the first part.

First of all, a first try to create a multi-user, multitasking operating system has been made on 1965 when MIT, Bell Labs, and General Electric joined together in order to try to design such an operating system. Unfortunately, the views of the people who were involved in that project were very different, so it was very hard to get an agreement on how this operating system should be developed.

But in 1969, based on the work that has been done during the Multics Project, two engineers from Bell Labs started to work on their own operating system, who was named UNIX. Those two engineers were Ken Thompson and Dennis Ritchie, who were also the pioneers in developing the C operating systems.

They made a significant progress. And in 1977, together with programmers at the University of California-- which provided a lot of enhancements, including network capability-- they were able to release one of the first versions of the UNIX operating system.

The UNIX operating system started to be used more and more in industry but also in education. But unfortunately, that operating system was available under license. So in order to create an operating system that is available to everyone without the need to pay for it, in 1983, Richard Stallman-- formerly an MIT engineer-- began to work on GNU Project and to try to develop a free UNIX-like operating system.

During this project, Richard Stallman together with a lot of enthusiasts were making progress, and they developed utilities applications that are needed for a full operating system to work. But they still miss a kernel.

During this time, of course, the commercial UNIX operating system that was developed by AT&T and University of California evolved. And because there are a lot of differences between the different branches of that operating system that has been developed in time by different organizations, in 1987 the most important branches were folded together into a common release, which is what was called System 5 Release 4. And this release became an interesting standard for the UNIX-based operating systems.

In 1991, the GNU operating system that has been started by Richard Stallman was still in need of a kernel. And at that time, a Finnish computer science student, Linus Torvalds, offered to create a kernel for this operating system. So in September 1991, the Linux kernel and the GNU user space programs that were developed by Richard Stallman and all the people who contributed to this GNU Project were able to release the first version of Linux operating system.

So starting with 1991, we have, in fact, two, let's say, main branches. We have the UNIX-based operating systems, which were developed based on the commercial versions that were evolving over time-- and the free Linux operating system that has been developed based on Richard Stallman and his team contribution.

Of course, the Linux operating system has been greatly inspired and was developed based on UNIX, so there are a lot of similarities between those two operating systems. Both of them are structured around the same kind of elements.

The kernel-- it's the core element of the operating system, which is responsible to manage the interactions between all the other parts and to be able to execute the actual activities. The file system that is responsible to organize the different kind of data that is needed for the kernel to be able to execute the processes. The processes are the actual programs that are running on the operating system-- programs that will probably affect the data that is stored on the file system. The last element will be the shell. That is the interface used by end users to work with the kernel-- with the operating system.

So the kernel is the core element of the operating system. It is responsible to manage all the interactions that occur at the operating system level. So it will manage all the physical resources, all the hardware-- like the memory, the processing power, the device, the storages, file system operation, and also the process management.

So the kernel will be responsible to manage the processors, which provide you support for executing code; the memory that is used by the processor in order to access the data; the disks that will store the persistent data that is needed for your applications; all the operations between CPU, RAM, and disks being coordinated by the kernel. The cardinal will also support the interaction with external resources, networking resources, which provide you support for input/output operations.

So all the data that is needed for the operating system will be organized into files, files that are organized into directories, directories that are organized into a file system. The file system can organize its directories and files in different ways to better support different kinds of operations like accessing the data, modifying the data, or searching the data.

That's why there are different kinds of file systems that are supported. There are specialized file systems for the operating system, like X2, X3, X4. But there are also file systems that were specifically designed to support the specific type of application or a specific type of interaction. For example, you may have file systems that allows you to access data from specific type of devices like DVDs or external disks, but also file systems that support remote access to be able to share data between multiple hardware systems. Also, there are file systems that were created to support the transfer of data between different operating systems, between Windows and Linux and vise versa.

A file system on an operating system is used in order to logically group together a collection of files on partitions, slides, or actual disks. Are the default file systems that are used by UNIX and Linux are called X2, X3, or X4 depending on the version of the file system that you would like to use and provide you support to group together files and directories based on the following properties.

Those file systems are single rooted hierarchies, so those file systems will use a single root directory that will be used to group all the other files and directories. If you want to be able to access multiple file systems, you will need to mount additional file systems into this root file system. So you will need to use a logical path as the root element for the other file systems. In this way, you can access multiple file systems throughout the same hierarchy. But the operating system-- UNIX or Linux-- will always have a single root that will provide you support to navigate all the other file systems.

This is different from Windows, for example, which support multiple root directories for its file systems. On Windows, you can have something like C or D devices that allows you to access other file systems. In Linux, there is always a single root that will be used to access the files.

The file system is required to have a boot directory. It's called boot-- it's a short name for bootstrap-- which will be used to boot up the operating system. Here, the most important drivers that are needed to be able to interact with the hardware devices that are connected to your computer will be stored.

Each file or directory that is part of this file system will be identified by a name, a path, which is the directory in that it resides, and a unique identifier which is called an inode. This inode will allow you to create links to those files. You will learn in one of the following lessons about both symbolic links and hard links that can be created for different elements of your file system files or directories.

Each file system in UNIX and Linux will be self-contained, so there are no dependencies between one file system and another. As I mentioned before, in order to be able to use together multiple file systems, you will need to use a logical name from the root file system that will be associated with the second file system you want to work with-- and in this way to be able to access all the files and directories that are part of this second file system.

UNIX and Linux both are using an hierarchical structure which is based on a single root. Most of the time, this hierarchical structure will be represented as an upside down 3 with the root element at the base of your file system and all the other directories spreading from there.

A version standard that has been created, which it's trying right now to define a common organization of directories for all the different versions that were created for UNIX and Linux over the time. This standard is called POSIX, and it's defining a list of directories that are represented in this slide.

So the most important ones, they are the bin directory, where are the binaries for the most important commands that allows you to work with the operating system will be stored; the dev directory, where the device files that are needed to work with the hardware devices attached to your operating system will be stored.

Etc directory is a very important one. Generally, here the configuration files that will govern how the kernel will work with different devices and also how the different applications that are installed on your operating systems are supposed to work will be stored. The boot directory that I already mentioned before, where the files needed for the operating system to start will be stored. The home directory, where private directories for each user will be created in order to allow that user to keep his own data separated from the others. In fact, at your first log in, you will be positioned automatically to this home directory, where it is supposed that you have the files that you need.

The mount directory-- mnt-- which is recommended to be used as mount point. So when you need to add additional file systems to your operating system, you generally create a logical name in this directory, a logical folder in this directory, which will be used as mount point for those operating systems in this way to be able to access the root element of those file systems.

And so on-- the temp directory will be used by different applications to create temporary files. The user directory, where user space applications are generally installed. The var directory, where the dynamic files that are needed for applications and for operating system will be created.

Also the proc directory, which provides information about the processes that are running on the operating systems. So this directory and virtual file system, in fact, will be created where the kernel will export information about all the processes that are running on your operating system. So this is the main goal for this directory.

Generally, as a user for a UNIX or Linux operating system, you will work on the home directory. Here in your private working directory, you will be able to create your own files to install your own applications-- and in this way to be able to do the tasks that are required for your job.

Everything in UNIX and Linux will be considered to be a file. Even the processes that are run by the operating system are represented as files. Also, the physical devices that are available on your operating system will be represented as files.

There are three basic types of files that are represented on the operating system. First, we have the ordinary files. Those are identified using a hyphen. Then we have the directories, which are represented using a d. Those symbols are used when you list information about the files that are part of one specific directory, for example.

And then we have the special files that have special meaning for the operating system. As I mentioned previously, you can create, for example, links-- symbolic links. You can create sockets that are also represented as files identified by an s.

There are two kinds of storage devices that are generally used by your operating systems-- storage devices that support characters and storage devices that support binary data. You can have character devices or block devices. Pipes and doors will be used as special files to represent the communication channels that you can create between different processes or threads that are running on your operating system.

Every program that you will run in UNIX or Linux will create a process. When you log in and start the shell, in fact, you start such a process. When you run a command or when you open an application, you start another process. Those processes will be able, by using fork, generally, to create additional processes. Also, those processes may create threads that allows you to execute multiple tasks in parallel on the same set of data.

There are a number of processes that are started by the operating system at boot up time. Those processes are called daemons. Daemons will be generally started, as I mentioned before, when the operating system starts by the initial process-- by init process. And those daemons are generally running in the background and are able to provide you different kind of services.

For instance the desktop login daemon provides you a graphical prompt that allows you to log in in an graphical environment to your operating system. There are also other kind of daemons that, for example, support network communication and allows you to share files with other users by using AFTP or an HTTP server and so on.

As a user on the operating system, you will generally use the shell as the main interface to work with the kernel. So the shell will be the common interpreter that provide you support to send commands to the kernel and in this way to make things happen on your operating system. So the shell will accept the commands that a user will enter, will interpret those commands, and will pass those commands to the kernel, which will execute those commands.

Right now, most of the versions of UNIX and Linux operating systems will use the Bourne Again Shell, which has been developed in the GNU Project as the default shell. But, of course, there are other kind of shells that are available. Generally, the difference is the flavor of the programming language that may be used to execute commands. There are generally two kind of shells-- shells that are based on Perl and shells that are based on C.

As I mentioned before, the default shell in both Oracle Linux and Oracle Solaris is the Bourne Again Shell, which is also known as Bash, which has been developed by Brian Fox as part of the GNU Project around 1989.

There are other shells that have been created over time. One of the oldest is the Bourne Shell, which, in fact, was the source of inspiration for the Bash shell. The Bourne Shell-- it's one of the first shells that were developed for the UNIX operating system by Steven Bourne at Bell Labs in 1977.

During the same period of time, Bill Joy at University of California developed the C Shell, which was based on the C programming language around 1978. Another C-based shell is the T Shell that was developed by Ken Greer at Carnegie Mellon University, which is an improved version of the C Shell.

Another commonly used shell is the Korn Shell that was developed by David Korn a Bell Labs 1983, which tries to merge together the functionalities from both Bourne Shell and C-based shells. Another shell that's worth mentioning is the Z Shell, which was developed by Paul Falstad at Princeton University in 1990.

As I mentioned already, right now on most of the operating systems that are based on either UNIX or Linux, the Bash shell is used. Some of the developers are still using C-based shells T Shell or Korn Shell-- of course, improved versions of those shells.

Next, we have our first quiz for our session. You can either pause the video for a few minutes and try to figure out yourself what is the correct answer to this quiz.

So which is the default shell in Oracle or Solaris operating system? The correct answer here should be e, Bash shell. Yeah, Bourne Again Shell is the correct answer.

The Unix and Linux OS structure

Kernel - Core manages all physical resources - CPU - RAM - Disks - I/O
File system - organization of files / directories
(/) - a root directory
/bin - the most important commands OS
/dev - the device files hardware
/etc - configuration how kernel work with devices
/lib -
/boot - boot up (start) the OS
/home - private directories for each user
/mnt - to add a mount point file system (like D or Windows for ex)
/proc - 
/tmp - temporary
/usr -
/var -
/sbin -
/kernel

Shell command interpreter 
- Bourne Again Shell (bash) = Korn (ksn) + C (csh) => default shells in Oracle Linux and Oracle Solaris OSes
- Bourne (sh) 
- C (csh)
- TC (tcsh)
- Korn (ksn)
- Z (zsh)

Files Types

 (-) Ordinary files
 (d) Directories
	Special files
	(l) Symbolic links
	(s) sockets
	Storage devices 
	(c) Character device ( support character data )
	(b) Block device (support binary data )
	Communication channels
	(p) Pipe
	(D) Door

Processes or daemon ex login

we will discuss about a user account.

So in order to be able to work with the different resources that are available for your operating system, first of all, you need to authenticate yourself. 

User accounts are used to identify users and in this way to know which operations are available to be done by those users.

Regular users will be able to log in and use the system but will not be able to do some critical activities that may affect the stability of the system. Only administrators will be allowed to do those kind of activities. The administrators will have special permissions, and in this way they will be able to execute those special commands that allows them to configure how the system should work.

The reason a special identity on a UNIX and Linux operating system, it's called root. 

The root user account is the administrative account that gives you full control of the system. Generally, the administrators will either be able to use this root identity and in this way to do all the possible operations on that operating system, or they may have some special permissions that are delegated to them in order to be able to do those operations.

In order to simplify the process of configuring the security policy for your operating system, administrators can use groups. 

A group is just a collection of users who will be able to share files or other system resources. So generally, the users who need to work on the same project-- so they need to access the same files or the same resources-- could be included in the same group. A group must have a name, a (GID) group identification number, and a list of the usernames that belongs to that group.

A user account is created by defining a username, me a password. Those two, in fact, are the credentials that are needed to an end user in order to work with the operating system. So when you will try to access an operating system, you need to know your username and your password to use them to authenticate at the operating system level-- and, in this way, to be able to access the resources that were intended to you.

Each user account will be identified using a unique ID (UID), user ID number. Then a user account may be associated with a primary group and with one or more secondary groups, though generally a user will have a primary group associated and may be part of multiple groups by associating that account with the secondary groups.

For each account, you will be able to indicate some commands, some descriptive information by using the command or the GECOS field. And very important, each user account will have associated a login shell. The login shell will be the one used by the operating system when a user will be successfully authenticated to the system.

So every time when a user successfully accessed, the operating system will-- the login shell will be started for him in order to allow him to work with the kernel and the user home directory, which is the private directory where the user can keep its own files. So after a successful login, the login shell will be started, and the user will be positioned in its own home directory.

For security reasons, the user passwords may expire on a regular basis. In order to update your password, you can use the passwd command. Generally, the administrator will set up a security policy that will require a special complexity to exist for your password.

So your password may need to comply with a minimum number of characters, numbers, or special symbols and minimum length. And also, generally you cannot reuse one of the previous passwords that you already used in the past. So you need to take into account those requirements when you reset your password.

So the next slide shows you a sample with how you can use this command in order to change the password for the current user on Linux. And on Solaris, as you can see, the process is pretty similar. The text that is displayed is a little different, but otherwise there is nothing special on each case.

On Solaris operating system, you can take advantage of role-based access control. So currently, this functionality-- role-based access control-- is only supported on Oracle Solaris. Some of the Linux versions-- like Fedora Project, for example, from Red Hat-- are in the process of testing a role-based access control mechanism as part of their security-enhanced Linux project for several years. But has not been, let's say, officially launched yet.

So let's learn a few things about roles and rights profiles. Unlike a standard user account, which provides you support to log into the system to access the system, a role cannot be used as a login account but can be used in order to simplify the process of controlling which resources are accessible to a specific user. 

So each role-- you will be able to create multiple roles for your operating system, and each role may be associated with a rights profile. A rights profile is just a convenient way to group together a number of authorizations that can allow a specific group of users to work with some special commands that would normally be restricted only to the root user.

So once a user has signed on, the user will be able to substitute its identity, so to use the su commands in order to assume one of the roles that were assigned to that login account-- and in this way to be able to execute the commands that were associated with that role throughout rights profiles. As I mentioned before, this functionality that allows you to take advantage of role-based access control, it's only supported for Solaris right now.

As a user, you will be able to take advantage of the substitute user command in order to change the ownership of the current login session and in this way to assume the identity of another user. The substitute user command is commonly used in order to be able to switch to the root users or assume the root role. You will switch to the root user for Linux-based operating systems and assume the root role for Solaris-based operating systems.

The dash option that can be used with substitute user allows you to specify that you want not only to assume the identity of that user but also to re-initialize the environment based on the settings for the switched-to user. So in this way to be able to create and configure all the environment variables according to the new user or the new role that you want to switch to.

If you do not specify the username attribute, then the switch will be made to the root user or to the root role.

When you first log in to the UNIX or Linux operating system, you will be taken by default to your home directory. The home directory is the place where you should create and organize all your private files and directories.

In order to quickly go to your home directory, if you navigate in some other parts of your file system, you can use either change directory command-- cd without any parameter-- or cd followed by space and the tilde. A tilde is an alias for the current user home directory.

If you want to navigate to the home directory of another user, you can take advantage of the same tilde symbol followed by the name of the user whose home directory you want to access. This expression is, in fact, a path name expansion of the user's home directory. You will learn more about path name expansions in some of the following modules.

Of course, the security settings generally will prevent users to access or to view the home directory of another user, so this command may fail in such cases. Only if that user has been provided to you the permissions that are needed to access that directory, you will be able to safely execute such a command. Of course, the root user will be able to access any directory on the system so will be able to use such commands.

Next, again we have a quiz. You can take a short break and try to figure out for yourself what is the correct answer to this quiz.

So the correct answer for this quiz is false. As I mentioned during the presentation, a role cannot be used as a login account. A role is only used to configure the security policy for your operating system.

Over the years, different variants of the operating systems has been created based on UNIX. Here you can see some of the most popular variants that had been created.

BSD-- Berkeley Software Distribution-- it's one of the main branches that were created which were used as a source of inspiration for most of the to-date operating systems like SunOS, for example, which is the predecessors of Solaris. Mac OS has also been developed based on BSD version of UNIX.

The others like AIX, HP-UX, and UNIXWare were developed based on system 5-- the version of the UNIX operating system that has been created when the different branches has been merged together in the '90s that were developed until then.

So during this training session, we will focus on Oracle Linux and Oracle Solaris.

So Oracle Solaris is the predecessor of SunOS, which is an UNIX-based operating system that was developed by Sun based on BSD UNIX version 4.2. This version has been created based on system 5, which was a merge between different versions that were created over the time by AT&T, BSD, and others.

System 5 release 4 being one of the, let's say, most important steps in the evolution of UNIX. System 5 release 4 being, in fact, in most cases, the predecessor of the most important UNIX-based operating systems that are used today.

In the same time, the Linux operating system has been developed with the contribution of a lot of enthusiasts. And it's packaged and distributed for both desktop and server machines. Over the last 20 years, there are different distributions that have been created for specific purposes. So right now, there are over 600 such Linux distributions that were created. You can learn about the most important ones at distrowatch.com.

Most of those Linux distributions are based on the same kernel that is still developed by Linus Torvalds with his team. But each distribution may supply a different set of user space programs that may better support different activities that you would like to execute on those operating systems.

Some of the most popular Linux distributions are listed in this slide. Red Hat is an open source organization that promotes Linux and provides you an important set of such distributions. Most important ones are Fedora, CentoOS, but also Red Hat Enterprise Linux.

Oracle is using Red Hat Enterprise Linux as the base distribution for creating Oracle Linux. The Oracle Linux is one of the operating systems that are explored in this training session alongside Solaris.

There are other distributions available out there like the Debian, Slackware, openSUSE, Gentoo, and so on.

So most of those distributions are based on the same kernel but provide different programs with different configurations to better support the different type of applications that need to run on those distributions. You may have I the need for a very lightweight operating systems to be installed on some old laptops or something like that. Or you may need another operating system that may be needed for a very powerful server, so a different set of programs will need to be installed on the operating system and configured in order to support your specific hardware. So each such distribution may support a different configuration that is needed for different needs.

Sometimes, you may even need a desktop environment to work with. A desktop environment is provided on UNIX or Linux using a specific component of your operating system.

It's important to note that both UNIX and Linux are developed as modular operating systems, and most of the functionalities that is needed are provided as modules. The desktop environment it is provided like such a module-- a module that allows you to perform activities like starting a graphical session, adding or deleting workspaces on that graphical session, changing backgrounds, managing files, executing graphical applications, listening for different events that may be generated by your end users, and so on.

As I mentioned before, this graphical environment is generally provided as an optional module, so it's not mandatory. In fact, there are a lot of situations when the servers that are running UNIX or Linux operating systems are not using a graphical interface at all because such a graphical interface may require a lot of hardware resources that may be better used for running the actual business processes for those operating systems. Or maybe your device is a small one. It doesn't make sense to have an graphical environment for that device.

Also, the graphical environment may prove a liability for your operating system because it may require some programs to be started which may add to the security risks that exist for that specific environment. So some administrators may prefer to avoid configuring such a desktop environment for security reasons.

We will use, during the practical activities, such a graphical environment in order to familiarize yourself with such environment. Because sometimes, such graphical environments may be helpful. For example, if you just want to develop some applications, and you are using an desktop machine that is not running critical processes, it makes sense to have such a graphical environment available to be able to run, for example, an integrated development environment.

So in order to access the graphical environment, you need to start first to configure your operating system to start the X server, which provides you this kind of functionality. And when you start your application, you will be able to select the user that you would like to use to access this operating system and then provide the correct password to start and login session.

Next slide shows you in a screenshot with the desktop that is available when you start the graphical session on Linux.

As you can see, you have access to a number of menus here. You can see some information about the current date and time in the right part of the screen. You can also use this icon in order to control the lifecycle of your operating system. And you will be able to use this desktop in order to create shortcuts and in this way to access your files of your applications.

Out of the box, you will be able to access quickly the home directory, where it is expected to have your private files. In a similar way, you will be able to log in to Solaris operating system by indicating the username, the password, and then the Solaris desktop will be displayed.

Solaris desktop is pretty similar with Linux one. So nothing very special here. Of course, the desktop world will be different taking into account the daemons that were configured for your operating system program so that you would like to be started automatically when your operating system is started.

You can also log in to a Linux-, or UNIX-, or Solaris-based operating system by using command line. When you start the command line option, again, you will need to provide the username, the password. And as you can see in both cases, you will be located to your home directory where you can access your private files.

After you finished your daily tasks, you'd probably like to close the operating system. So depending on the interface you are using to interact with your operating system, you can use different commands or steps to log out.

To log out from the graphical user interface, you need to go click on System or the down arrow in the far right-hand side on Linux. Next, in Solaris, click on Log Out Username. Or in Linux, just click on your username and then click Log Out and confirm that operation. To log out from the command line interface, just type exit.

Components of a User account

Username ór login name
password
(UID) user identification number unique identification within the system

(GID) group identification number identificatin of the group the user belongs. The two types of groups that a user can belong to are as:
    - Primary group: Specifies a group that the operating system assigns to files that are created by the user. Each user must belong to a primary group.
    - secondary group: Specifies one or more groups to which a user also belongs.
(GECOS) Comments General Electric Comprehensive OS information that idenfies the user.
User's home directory is the portion of a file system allocated to a user for storing private files
User's login shell is the user's work environment set up by the initialization files which are defined by the user's login shell
Prompts for bash shell for a regular user ($)
Prompts for the root user/role shell (#)

change a passwd on Oracle and Solaris
$ passwd

(RBAC) role-based access control

$ su [-] [username] => assume an identify of other user
$ cd
$ cd ~username 

~~~~~~~~~~~~~~~~~~
UBUNTU: "AltGr+ñ"
MAC: "option+ñ"
~~~~~~~~~~~~~~~~~~

A role in Oracle Solaris is a login account just like a user account => False because a role cannot be used as a login account a role is only used to configure the security policy for your OS

(BSD) Berkeley Software Distribution
(SunOS) BSD - predecessor or Solaris UNIX version 4.2.
(Oracle Solaris) - AT&T's Bell Labs - System V.
(AIX) - IBM - System V.
(Mac OS X) - Apple - BSD version of UNIX
(HP-UX) - Hewlett Packard - System V.
(UNIXWare) - Novell - System V.

Linux Distributions (distro) - DistroWatch.com

- Red Hat Enterprise Linux (RHEL) including Fedora, CentOS
- Oracle Linux (OL) based on RHEL with Oracl's Unbreakable Enterprise Kernel (UEK)
- Debian GNU/Linux including Ubuntu, Linux Mint, and others
- Slackware
- openSUSE (SUSE)
- Gentoo

GUI graphical user interface

Oracle Linux -> 
Ctrl+Alt+F6 switch to the command line mode.
Ctrl+Alt+F1 or Alt + Right Arrow keys reverts to the desktop window.

Oracle Solaris -> 
Ctrl+Alt+F6 switch to the command line mode.
Ctrl+Alt+F7 reverts to the desktop window

some shells -> Ctrl+D

In the next part of this module, you will learn about how to execute commands from the command line. So in order to execute commands, first you need to start in shell session. If you access the operating system by using a terminal, so you don't use a graphical environment, a shell session will be started for you automatically after the login. But if you access the operating system by using a graphical environment, you will need to start this shell session.

The simplest way to start a shell session will be to just go into an open area of your desktop, Right-Click on that area, and the pop-up window will be displayed on both Unix or Linux, on both Solaris or Oracle Linux. From the options that are displayed in this pop-up, you should select Open Terminal, which will launch the shell session that you can use further in order to execute commands, to send commands to the kernel in order to be executed.

The commands that are supported by the operating systems depends on the users-based programs that are installed. On a normal, let's say, operating system, a common operating system that is used for a standard desktop or laptop may have hundreds of such commands. All the commands will be described, of course, fully in the documentation. And in the last part of this section, you will learn about how to access the documentation for those commands.

But most of the commands will use a very similar syntax which allows you to specify the command's name, the command options, and the command argument. It's important to note that in both Linux and Solaris, the commands are case sensitive. So you cannot modify the case when you specify the command name.

The command may have or not. Options and arguments are not mandatory elements. But most times, those two additional elements that you can use with the command allows you to indicate or change the behavior of the command. So taking into consideration the combination of options and arguments, the behavior of the command will be indicated.

The command generally will identify an executable and user space application that will be executed by the kernel. The option will indicate how the commands should run. The options are indicated using a dash symbol. And arguments generally are used to specify what will be affected by that command. It can be, I don't know, generally a file, a directory, or I don't know, any kind of text that is needed to allow the command to successfully execute. It can be, for example, a pattern that may indicate multiple files or directories.

The philosophy of Unix and implicitly of Linux is to create commands as small, efficient programs that are able to do a specific task very well. And if you need to execute a more complex task, you should group those as commands together using pipe and other operators. You will learn about the operators that allow you to group together multiple commands and, in this way, to use the output of a command as input for another command in one of the following lessons.

As I mentioned, there is a very large number of commands that may be available on our operating system. Of course, it's very hard to learn about all of them. That's why very good documentation is provided, documentation that you can use to search for commands in order to learn about them.

During this training session, you will learn about the most important commands, the ones that are expected to be needed for a regular user for a Unix or Linux operating system.

So let's start with some of them. In order to display operating system information, you can use the uname command. In order to display the current date and time, you can use the date command. The date command, again, supports a lot of options and arguments that you can use in order to change its behavior.

To clear the terminal window, if from any reasons you generated a lot of, I don't know, texts that you want to be deleted, you can take advantage of clear command. As I mentioned, even if there are a lot of commands, generally, a normal, regular user, it only needs a couple of dozens of those commands. And the most important ones will be covered in these queries, either during the lectures or during the practical activities.

The commands can support options. Options are specified using the dash symbol. You can use more than one option when you define a command. It's up to you if you list those options separately. Or you can combine all of them together using the same dash.

If you need help to learn about the options that are supported by a specific command, you can use the command name followed by two dashes and the help option. In this way, a text that will describe the possibilities that you have for your command will be displayed.

Next, you can see some samples that shows you how to combine options together. So here, -i option, it's used to display the name of the hardware platform. And -n option can be used to print the hostname of the local system, can see how you can use those options.

Or you can combine two options together. For example, -s allows you to display the name of the kernel. And -r allows you to display the release number for your kernel, as you can see here. Using a single dash, I can combine those two options together in order to display both the name of the kernel and the release number for my kernel. The same syntax can be used also on Solaris, as you can notice in this slide.

Alongside options, you can use an argument that allows you to define additional information that will control the execution of your command. This additional information can be, I don't know, the elements that will be affected by the command or any other configurations that are needed. For example, here, I used a calendar command, the cal command with two arguments, 12 and 2015, in order to indicate the month and the year that will be displayed by my calendar.

You can also use commands without options or arguments. As you can see here, the list command, ls, allows you to display files and the directories that exist in the current file system location. But you can also add options that will display a long listing. ls -l displays the long listing.

An argument that will display the information about any specific file only or to combine an option and an argument in order to display the long listing only for a specific element, dante file. Yeah, this is a file, because the first symbol, as you can see, it's a dash, which indicates a regular file. If this first symbol had been, I don't know, d, this means that this element is in directory. The first symbol will always display the type of the element.

You can also enter multiple commands on the same line by combining those commands using semicolons to separate the commands. The shell will recognize the semicolon as common separator and will execute those commands in order, from left to right when, of course, you press Enter.

Oh, as you can see here, I used date to display the current date information and then uname to display the name of the operating system. And both commands will be specified on the same line. Given the uname -a command, which type of Unix command component does -a represent? Again, you can pause the video and try to figure out for yourself what is the correct answer. So the correct answer here is A, -a is an option.

In the last section for this part of our training course, you will learn about the help system that is available on both Solaris and Linux. So the documentation for the commands are provided throughout the online technical reference manual, which is called simply man, which provide you full details about syntax that should be used to execute a specific command, description for all the options, all the arguments that are available, and also some sample usages of that command.

In order to access the manual, you can use man followed by the name of the command. Of course, the man command supports a number of options. So in order to see the options that are supported, you can go to the man page. Yeah.

Here is how the documentation looks like for the uname command. As you can see, you have information about the name of the command, some usages, the description of the command, and also a description for each option that is supported by this command.

In the end of the Help, you will be able to also find some sample usages. Here, you can see the keyboard commands that are reconfigured to allow you to scroll throughout the man pages. Each provides you a description of all scrolling capabilities.

Generally, space bar is used to display the next screen of the man page. Return or Enter allows you to display the next line of a man page. b to move back one full screen, /pattern allows you to search forward for a regular expression and allows you to find the next occurrence of the pattern(patron). Upper N allows you to change the direction of the search. And q allows you to exit the man and return to the shell prompt.

The man command, in fact, it's using the less command in the background in order to scroll throughout the man pages. You will learn more about the less command in the lesson titled Working with Files and Directories.

You can search throughout the man pages either by section number or by keyword. So in order to organize the information, the man is using multiple sections. Here you can learn about the sections that are defined for Solaris and for Linux. So in order to search in any specific section on Linux, you can indicate the section number as the first argument. While on Solaris, you can indicate the section number using the -s option.

When you are unsure of the name of the command, you can use the man command with the -k option. And you will be able to indicate a keyword that allows you to search for matching man page entries. So in this case, you will be able to access a list of commands and descriptions that contains the keyword that you indicated. In this way, you will be able to search the man pages by keyword.

For additional information about Oracle products. Of course, you can access the OTN documentation website, which is available under docs.oracle.com.

Next, we have another quiz. Again, it will be good to pause the video and try to figure out for yourself what is the correct answer for this quiz. Which of the following man command options allows you to display a specific to search in a specific section of the men documentation? So the correct answer here is -s, yeah, so C option.

Next, you can follow up with the last two practices for this lesson. These two practices will conclude the module 2 of our training session.

command, option, argument

Display the OS information
$ uname
$ uname --help
$ uname -i
$ uname -n
$ uname -rs
$ uname -a
$ uname -r -s

$ date

$ clear

command with Arguments 
$ cal
$ cal mm yyyy

(ls)  a long listing for the informations command withOUT Options and Arguments
$ ls
command with Options

show the username and the group that owns the object: $ ls -l
show the UID and GID numbers corresponding to who owns the object $ ls -n

command with Options and Arguments
$ ls -l Downloads

multiple commands on a single line separated by (;)
$ command [options] [argument]; command [options] [argument]
$ date; uname; hosname

$ man man
(linux)
Display the man pages section 1: /$ man 1 man
$ man 2 man 

(solaris)
$ man -s1 man
$ man -s2 exit 


$ man uname

comandos de ayuda dentro de uname:

h help
Space bar
Enter
b
/pattern
n
N
q

display man pages for información on the man command using the keyboard man: man -k man

display all options where the keyword is: man -k who

display a specific section: man -s 

www.oracle.com => documentación

display en man lo que contiene la key "dir"
$man -k dir 

During the third lesson, you will learn how to work with files and directories.

So first of all, you will learn about the command that allows you to determine your current location in the directory structure. If you remember, the UNIX and Linux operating systems are using a single rooted hierarchy, so you will have a single root that will be used in order to start the hierarchical structure that will organize the files that are part of your operating system.

So you will be able to navigate this hierarchical structure, and sometimes you will need to remember what is your current location in this directory structure. So first you will learn about the command that you can use to determine this current location. Then you will learn about how you can display the content of different files that you may have on your file system, how you can work with files and directories by copying and moving, by creating and removing, and by searching for such elements of your file system.

So let's quickly start with the first part.

A directory will be used on a file system in order to group multiple files or other directories. So in fact, a directory is just a list of references to other objects-- other objects that can be either files, sub-directories, or symbolic links. Because a directory may contain other directories as sub-directories, you will be able to build this hierarchical representation, hierarchical structure.

Each reference that is created for defining the content of a directory will consist in two main components. So we will have a name that is the set of characters that will be needed to identify and access a specific object. And a number-- the number will be used to uniquely identify that specific object. That specific element can be, as I mentioned before, either a file, a sub-directory, or a symbolic link.

In order to be able to learn about the metadata that is stored for this object, this organization has been used in order to provide you very good performance when you just need to display information about your files and directories. So most of the time, you will not need to access the content of those files or directories. You just want to learn about either the permissions, about the ownership information, about statistical information-- last modified time, creation time, size, and so on-- just want to learn about their existence, not really accessing their content.

So all this kind of metadata will be stored in a specific region of your file system, and this metadata will be identified using this number. In this way, you will be able to quickly search through all this metadata and, for example, to display the information about the objects that are part of a directory without navigating a lot on your file system. This number will be associated with the name that it used to identify and access the object and will also be associated with a physical location on your file system where the actual content of this object will be stored.

So only when you will need to access the content the file system will need to navigate to that specific region to display the information. Both Linux and Solaris operating systems provide you a command that you can use to display the content of the current directory, to change the current directory to display the information about the current location in the file system hierarchical structure, and so on.

So first of all, how you can determine the current directory, how you can determine the location in the hierarchical structure used by your file system. In order to display the current directory, you can use the print working directory. Pwd command allows you to display the full or the absolute name of the current working directory. This command works in the same way in both Solaris and Linux, even if the directory structure may be different.

In order to display the content of a directory, you can use the list command-- ls command. The general syntax for the ls command is ls followed by an optional set of options and an optional set of file names or directories.

So in order to display the content of a specific directory, generally you will need to navigate to that directory. In order to navigate to a directory, you can use the change directory command-- cd. You will learn about this comment later. And then you can simply enter the ls command without any options or arguments. In this way, you will get the full list of files and directories that are part of that specific directory. So you will get a list of files and directories that are part of the current directory.

It's important to note that not all the files and directories that are part of that directory will be displayed. Some of them will be missing. The hidden ones will not be displayed. You will learn immediately that there is a specific type of files and directories that can be hidden by defining their name with a dot in front.

By default, the hidden files and directories will not be displayed. So only the visible ones will be displayed out of the box by the list command. In order to display also the hidden ones, you need to use a special option-- -a. You will learn about this option in the next slide.

If you want to display the content of a specific sub-directory, you can enter the ls command followed by the name of the sub-directory. As you can see, the name of the sub-directory is specified as a relative path. We don't have a slash in front.

So there are generally two kind of paths used to navigate the file system. We have the absolute paths like here or the relative paths like here. The absolute paths are the ones that are starting with root and allows you to specify the actual path that you should follow in order to reach a specific object. The relative path needs to be combined with another path. Most of the time, the relative path will be combined with the local directory.

Here, for example, the dir1 will be combined with the local directory to identify this sub-directory whose content will be displayed here. If you want to display the content of another directory, of course, you can always use the full path name, which is indicated using an absolute location as argument to the list command.

The -l option-- it's one of the most commonly used with the list command-- allows you to display a long listing for file information. So generally, this will be the way you can display the metadata about a specific file or a directory.

The long listing will include as the first character the file type. It can be dash for a regular file, or d for a directory, s as a symbolic link, and so on. Then you have the permissions set that is defined for this specific file.

You will learn about the permissions set in one of the next lessons. You can specify here permissions like readable, writeable, executable, and no permission for the owner, for the group owner, and also for all the other users that are authenticated on this operating system.

Then the link count will be displayed. This number will indicate the number of hard links that were created for this specific object. Then you can see the user owner for this object, the group owner. This is the user owner, the group owner, information about the size of the object, details about the last modification date and time, and the file and directory name. Those data are read pretty fast from the inode information from the metadata, so no need to go and access the actual content of the file in order to be able to display all those metadata.

As I mentioned before, by default the list command will not list all the files or directories that are part of another directory. The hidden ones will not be displayed. In order to display information about the hidden files and directories, you should use the -a option-- minus all. The hidden files and directories are those that begin with an dot symbol or a period, which is sometimes called that dot file.

You can also use ls -i in order to display inode node information for a specific object. Here you can see how to display the inode 4 and a file, dante, that exist on this directory.

You can also display detailed information about the directory without showing its contents using the -d option combined with -l-- long listing. The -d option that specify that I only want to see details about this specific object and not its content.

You can also take advantage of -r option. That's available for the list comment in order to display in a recursive manner information about the files and sub-directories that are part of this directory. It's important to note here a difference that exists between Solaris and Linux. On Solaris, you should use an lowercase -r for recursive operations, while on Linux sometimes you need to use an uppercase -R for the same thing, for requesting recursive operation to be executed.

In this case, the sub-directories that are part of the indicated directory will be displayed. And for each sub-directory, its content will be displayed.

Next, we have the first quiz for this section of our training queries. Again, it will be a good thing to take a pause to the video and try to figure out for yourself the current-- the correct answer-- to this quiz.

So what is the function of the ls minus -a command?

The correct answer here is that it will display all the files in a directory, including the hidden ones. So D should be the correct answer here. -a does not display detailed information. In order to display detailed information, you should use -l-- long listing.

You can take advantage of -F option in order to display details about the type of the file that is part of any specific directory. Information about the type of the file you can also get by using the file command.

So the ls -F command will generate an output that will contain some symbols that will indicate the type of the file. You may notice a star that indicates an executable file, a slash that indicates a directory.

You can see here this is a directory. This is a directory. All the others are regular files because there is no special symbol displayed after the file name.

Some other symbols that may be generated by this command are equal for socket, email symbol for a symbolic link, or a pipe for a First In First Out file. Generally, a First In First Out file-- it's also called a pipe file-- and it's used to communicate between two processes that are running on the same operating system.

The file command, on the other hand, displays descriptive and human-readable information that will indicate what kind of content there is in that specific object. So the file comment can help you to determine the type of content that may exist in any specific object.

Here is the syntax that you should use. You can indicate an optional number of options followed by the file name. If you try this command on a text file, you may notice that ASCII English text description will be generated to your output.

If you try to execute this command on a binary file like passwd, this is a special system file that is used to store information about the current user account that can access this operating system. You may notice that this is a binary file, which is dynamically linked and used by the operating system. Of course, more information about the output that is generated by the file comment, you can learn by using the man page for this command.

When you work with a directory hierarchy, you need to be able to navigate this hierarchy. Always you will be in a specific location, which is identified as current working directory. In order to print the current working directory, you can use the bwd command.

As I mentioned in the beginning, when you log into the system, the current working directory will be set to your home directory. And in order to change the current working directory, you need to use the cd command-- change directory command. If you use the change directory command without any options or argument, you will be positioned back to your home directory.

In order to move around the directory hierarchy, you can use either a relative or an absolute path name. An absolute path name will always start with the root directory and allows you to define the full path that you need to navigate in order to access a specific object. A relative path name does not start with a slash and generally needs to be combined with another absolute path name in order to be able to locate the actual object. Generally, the relative path names are combined with the current working directory.

There are some special symbols that are supported by both Linux and UNIX-- symbols that allows you to indicate the current working directory and the parent directory, which is the directory directly above the current working directory. You can use those symbols if you need to navigate.

The second one is very useful. It's commonly used to quickly go to the parent directory.

The home directory, as I mentioned in the beginning of this training session, is the directory where you are supposed to create your private files and where you will be placed after logging in. Generally, the name of the home directory is the same as your login name, your username. And it's placed either in home or in export home directory.

This will be the place where you are located after an successful login, and this will be generally the place where you want to be when you work with your private files. That's why in order to quickly return to this directory, you can just use the simple cd command.

So in order to return to your home directory, you can either use cd command or use cd followed by tilde. Tilde is a metacharacter that allows you to identify the current user home directory. If you are an administrator and you have permissions to access another user's home directory, you can also use cd followed by tilde followed by the username of the user whose home directory you would like to access.

Next, we have another quiz. Again, it will be a good thing to make a pause to this video and try to figure out for yourself the correct answer.

When you use the cd command without options or arguments, the current working directory changes to your home directory or not?

The correct answer here is true. Cd without options and arguments will change the current working directory to the home directory.


pwd (print wroking directory) command => full pathname , 
absolute pahts are starting with  root

ls dir1 => relative  path needs to be combined with another  path

d directory
s link 
link count => number of hard links were created for un specific object

Display all the files in a directory, including hidden files: $ ls -a
Display inode number (When a file is created on a system, a file name and Inode number is assigned to it.) and its corresponding name $ ls -i 
Display long list and detail information about and specific object: files: $ ls -ld
Display recursive manner information de files and directories: $ ls -R
Display the type of file: $ ls -F
Describe the type of file: $ file Pictures
* Executable
/ directory
= Socket
@ Symbolic link
| First in First Out (FIFO)

file [options] filename: determine certain file types: $ file /etc/ppp/ip*
file /usr/bin/passwd

file command output are: Text, Data, Executable or binary

$ file a* = $ file [a]*
acpi:           directory
adduser.conf:   ASCII text
alternatives:   directory
anacrontab:     ASCII text
apm:            directory
apparmor:       directory
apparmor.d:     directory
apport:         directory
appstream.conf: ASCII text
apt:            directory
avahi:          directory

cd command is a bash built-in command

changing Directories: $ cd directory

. Current or working directory
-- Parent directory, the directory directly above the current working directory

cd ór cd ~ => return to your home directory

you will learn about how you can access the file contents. So on both Linux and Solaris, there are several commands that you can use to display the content of a text file in read-only format. Right now, we only want to be able to see the content of the file. We don't want to change it yet. In one of the next lessons, you will learn about how you can take advantage of editors, like v, for example, to change the file content. But for now, we want to be able to see the content of the file.

So you can use commands like cat, which is a shortcut for concatenate. cat can also be used to concatenate several files into a single file. But its most common usage is to just display the content of a relatively small text file. More often, commands like more or less are used to be able to display the content of a text file that will not fit in a single screen or page. So you would like to be able to display that content one screen or page at a time.

The recommended tool right now to do something like that, it's less, which is more robust than the legacy more tool. The more was the first one that was developed for the Unix systems. Less was created during the GNU project as a replacement for more. less has been created in order to provide you a more efficient way to display, navigate, and search the content of that file, again displaying one screen or a page at a time.

Right now, very common, the less command is used by both end users and administrators when they need to display the content of a text file. If you do not want to display the entire content, but you are only interested by the first few lines or the last few lines, you can take advantage of tail, which allows you to display lines of text at the end of a text file, or head, which allows you to display lines of text at the beginning at the text file.

If you don't want to display the content but you want some statistics about the content of the file, you can use the word count command, which can count new lines, words, bytes, and characters that are part of your text file. The last command listed here, diff allows you to display the differences between two text files.

The cat command, it's one of the most commonly used to display the content of short text files, text files that are not more than one screen. Here is a sample that shows you how you can display the content of the dante text file. Probably this text file will have the entire story of the life and times of Dante.

I guess a more good option for displaying this content, which I expect to be pretty large, is to use less not cat. But generally, cat is very useful for short text files, like some files that can be used to configure some applications that needs to run on your machine. Of course, more information about cat, you can see by accessing the man page for this cat.

Before you attempt to open a file by using the cat command, it's recommended that you first run the file command to determine the file type to be sure that this file is a text-based one, not a binary one, because if you try to display a binary file using cat, it's possible to affect your terminal. So you will need and clear to be able to continue working after that.

The second command that can be used to display the content of a text file is more. More has been developed as the main command to be used for Unix operating systems when you need to display large text files. When you use more, the content will be displayed page by page. And a message will be used at the bottom of each screen, showing you the percentage of the file that has been already displayed. When the entire file has been displayed, the shell prompt will appear. And you will be able to do any other kind of commands you need.

While you are displaying the content of the file, you can use a number of shortcuts that allows you to scroll throughout the file. So Space bar allows you to display the next screen or the page. The Enter allows you to go to the next line. B allows you to move back one full screen. /pattern allows you to search forward for a regular expression.

n allows you to find the next occurrence of the pattern(patron) after you have used /pattern. Upper N allows you to change the direction of the search and maybe to search backwards. h provides you a description of all the scrolling capabilities. And q allows you to exit this viewer and to return to the shell prompt.

Similar commands are available for less, as I mentioned before. The less has been created as a users-based program in the GNU project as a response to more but with more features and actions. All the actions that are part of the table from the previous slide will not work only for more but also for less. For a complete list of features, you can use the man for less or to use less -?.

The next two commands allows you to display part of the text files, either the first part or the last part. Or you can use the head command to display by default the first 10 lines of a file. You can control the number of the lines that are displayed by using the -n option.

So in this sample, you can see how you can display the first five lines from this file, words file that is part of /usr/dict directory. tail command allows you to display the last 10 lines from a file. Again, you will be able to change the number of the lines that are displayed by using the -n and +n options. The -n options allows you to display the end lines from the end of the file. The +n options displays the file from line n to the end of the file.

A very popular option that is used with tail is -f, follow, which allows you to follow the data that is being appended to the end of the file. This option is very useful when you want to monitor, for example, a log file while the information is generated. You would like to be able to update the content of the file that is displayed when additional information is generated in that file. So it can be very useful when you want to monitor the log information that is generated for one of your applications.

The word count command allows you to display the number of lines, words, and characters that are contained in a specific file. Again, you can use a number of options to control which statistics will be displayed. -l allows you to display the line count, -w, the word count, -c, the byte count, and -m, the character count.

The last tool that we will cover in this section is the diff command that allows you to display the differences between two ASCII text files. So it's important to note that in the output of this command, the lines that are unique to filename1 will be identified by the less than symbol, while the lines that are unique to filename2 are identified by greater than symbol. The lines that are identical in both files are not displayed. Again, you should use the man page in order to learn more about this command.

We have another quiz. So again, it's a good time to take a pause to this video and try to figure out for yourself the correct answer to this one. So the correct answer here should be b. The default number of lines that are displayed by the head command is 10.

In the next section of this lesson, you'll learn about how you can copy and move files and directories. The copy command, cp, allows you to copy a single or multiple files and directories. The cp command supports a number of options followed by a number of source files and a last target or destination file. So the source can be either multiple files. And the target destination should be a single file or directory.

In order to copy a file to a new file in the same directory, for example, you need to use the copy command with the name of the source file and the name of the target file specified as arguments. Yeah, so copy followed by the source file followed by the target file.

During the next few slides, you will learn more ways to take advantage of this command to copy not only single files but multiple files or even directories. So to copy multiple files to a different directory, you should use the copy command with multiple filenames for the source and the single directory name as the target.

So as you can see here, I specify feathers and feathers_6 as source files and dir1 as target directory. So in this case, the feathers and feathers_6 files will be copied from the current directory to this new directory.

You have some options that you can use with the copy commands. The most common used options are -i that can be used to prevent from accidentally overwriting existing files or directories. And -r, lower r for Solaris, upper R for Linux, that allows you to indicate a recursive operation. Generally, this allows you to copy a directory with all its content into another directory.

So -r option allows you to recursively copy a directory. If the target directory does not exist, this command will create a new directory with that name. If the target directory exists, this command will create a new subdirectory with that name below the destination directory. The source can be one or more directory names. The target should always be a single directory name.

The -i option allows you to prevent existing files from being overwritten with the new files. When you use the -i option, the system will prompt you before overwriting any files. So you will need to confirm with a yes or no response if you'd like that operation to be actually executed.

So here, when you try to copy feathers into feathers_6, you will be asked if you really want to overwrite feather_6 with the content of feathers file. if you don't want just to copy files, but you would like to move them, you need to use the move command, mv command. So this command allows you to move or rename files and directories within the directory hierarchy.

Take special measures, because move is a destructive command. So if you do not use it with the correct option, you may lose some files, because this command will not keep the files in their original place. So if you want to be sure, generally it's much better to just use copy. And after you make sure that your files are in the new location, go back and remove the files from the previous location.

The move command does not affect the content of the files or the directories but the location of those files and directory. The moved/renamed file will maintain its original inode number but will be just located in another place in your file system.

So here is a sample. Don't worry, you can see how you can take advantage of this command in order to move the brands file from the coffees directory to the home /home/Oracle directory. So first of all, I need to quickly navigate to the coffees directory.

I will check that I am in the correct directory. I will list the content of this directory. And then I use move command to move one of the local files, brands, into another directory. In this case, I used tilde to indicate the home directory. I want to move this file into my home directory. Then I can list again the content of the current directory.

You may notice that the brands file is not here anymore. It has just been moved. So I can quickly navigate to my home directory. I can check that I am in the correct directory. And then I can list the details about the new file that was just moved in this directory.

You can also move a directory and its contents. In order to be able to move a full directory with all its content, you need to use either move -r. Or if you are in the same directory, you can do that without any additional operation.

So you can see here, I am navigating quickly to the lab directory. I displayed the current working directory. I list the content of the practice subdirectory, the long listing for this subdirectory. I create here a new directory, letters. I list details about this directory. And then I move this directory to a new directory that was called letters, a new one that I just created.

The move commands can also be used for renaming existing files or directories. So here you can see how you can just rename one of the existing directories to be able to use another name. I list the current working directory. And then I move dante to dantenew. Yeah, so in this case, this existing directory, dante, will be renamed in dantenew. Of course, all its contents will be preserved.

So let's assume that in your home directory, you created a directory called the newdir as a placeholder for a variety of files. You'll notice that this directory now contains monthly_reports. What will be the proper syntax in order to rename this new directory to monthly_reports?

Take special care, the note is very important. You are not in your home directory. So you can take a pause of the video and try to figure out the correct answer for yourself.

The correct answer here is a, yeah. You need to indicate the path of the directory that will be renamed. That's why you need to use tilde as the alias for the home directory, because you are not in the home directory. If you were in the home directory, then b also should work. This will conclude the second part of this lesson. 

You can configure systems to use /home directory, instead of the /export/home directory as the default home directory.

cat (short for concatenate) or view file contents: $ cat filename

Don't use to read binary files.
cat first_file second_file > retult_file

more (screen or page but not change)
less (GNU less) navigate, and search but not change display screen or page at a time.
less -?
less --help
less -V
less --version

wc (word count) counts newlines, words, bytes, and characters in a text file
-l Line count
-w word count
-c byte count
-m character count


head display lines of text at the beginning of the text file
$ head -10 filename
$ head -5 /usr/share/dict/words
$ head filename

tail displays lines of text at the end of the text file
$ tail -10 filename
$ tail -5 /usr/share/dict/words
$ tail +25136 /usr/share/dict/words
$ tail filename

diff displays the differences between two files
$ diff filename1 filename2
(< less than) filename1
(> greater than) filename 2

cp command copy files and directories

$ cp sourcefile targetfile
$ cp filename newfile
$ cp fileOne fileTwo dirOne
$ cp fileOne -i dirOne
$ cp dirOne -r(Solaris)/-R(Linux) dirTwo
$ cp -r directory1 directory2
$ cp -ri directory1 directory2

mv (is a destructive) command moving and renaming files and directories not keep the files in their original places. maintain its original inode number. 

$ mv [options] source(s) target/destination
$ mv ~/newdir ~/monthy_reports
option -i prevent from automatically overwriting existing files: $ mv -i source target

When you move a single directory to a target directory that doesn't exist you actually rename the current directory and its path.

When you move multiple directories to a target directory that doesn't exist: mv: target directory not found

In the last part of this lesson, you learned about how you can create and remove files and directories and how you can search for files and directories. So let's quickly start. 
In order to create files, you can use the touch command. The touch command allows you to create a new empty file-- if, of course, this file does not already exist. If the file already exists, the touch command will just update the modification time and the access time for the current file. 
The touch command allows you to create multiple files with the same command. You can even create hidden files using the touch command. You can use either absolute or relative path names when you create files using the touch command. 
In order to create directories, you can use make directory command-- mkdir. The mkdir command allows you to create empty directories. You can even take advantage of -p option that allows you to specify a full path. And all the missing directories on this path will be created. So in this way, you can create multiple directories by creating all the required intermediate directories on your pathway. 
Here we can see a sample that shows you how you can create a new directory named reports in the home directory-- in the home oracle directory using the mkdir command. And here you can see how you can create a new Weekly directory in the Reports directory that you just created previously. 
In order to permanently remove files from the directory [INAUDIBLE], you can use the remove command-- rm command. Again, you need to use this command carefully because this is a destructive command, and you may lose information. 
The most important options that are available for this command are listed in the slide. So you can use -r execute this command in an intuitive way. In this way, you will be able to remove not only a file but an entire directory with all its contents. -i which prevents the accidental removal of existing files and directories by prompting you for a yes or a no. And -f, --force, which will force the removal of existing files and directories. So it's the opposite of -i-- without any prompting. 
Here you can see some samples about how you can remove the file named projection from the Letters directory. You're going to navigate first to this directory. Then list the content and remove the file, and then list the content again. And you may notice that this file is missing the second time. 
The second option allows you to see how you can take advantage of -i Option. That will ask you for a confirmation for each file that will be deleted. Here a global expression has been used. You will learn about global syntax in the next lesson. 
This pattern, in fact, allows you to identify all the files that are starting with your expression. So all the files that are starting with file-- all the objects that are starting with file-- followed by any other combination of characters will be included in the command. So that's why you are asked to confirm that you want to remove file 1, file 2, file 3, and so on if you have multiple such files. 
The remove commands can be used with the option -r to also remove directories that contain files and sub-directories. So here we can see a sample on how you can remove the Letters directory and its contents by using this command. This is the-- yeah. 
In order to remove empty directories, you can also use the remove dir command-- rmdir. This command can be used to remove only empty directories. So if the directory is not empty, an error message will be displayed. 
So also it's important to note that you cannot remove a directory that you are currently working in. So you need first to get out of that directory to navigate to the parent directory before removing that directory. 
The next section provides you some information about the two types of links that are supported by both Linux and Solaris. Both operating systems are supporting symbolic links and hard links. 
First of all, let us learn about hard links. A hard link, it's another name that is created for the same file. So a hard link can be created only for files that are on the same file system. And a hard link will be created based on the same inode. So a hard link will just be another name that you create for the same content-- a name that can be stored in another directory. 
In order to create a hard link, you need to have the content already to have the inode, and you will be able to view the number of the hard links that were created when you long-list the information about your files. And you can find the hard links for the same file by comparing the inode numbers. The hard links will always have the same inode . Numbers 
So the inode needs to exist. That's why you cannot create hard links for fires that are not existing or for files that are on another file systems, because those inodes will not have any meaning for the current file system. 
The second type of link that can be created on both UNIX or Solaris-- Linux or Solaris-- are the symbolic link. Symbolic links are also called sym link or soft link. And a symbolic link-- it's a pointer that will not use the inode of the file to refer to an existing file, but we'll use a path. 
So a symbolic link, in fact, it's a new object that is created on your file system. Object that will have its own inode but will have as content the path to another file or another directory. So a symbolic link, as you can see, will contain the full path name to another file or directory. 
Because I don't need an inode in order to create a symbolic link, symbolic links can be created for files or directories that exists on other file systems or even for files or directory that does not exist. That's why sym links may be broken. So a sym link, it's broken if the link to file is removed-- if the link to file does not exist. 
The symbolic link files are identified by the letter l in the file type field. And in order to view the file that is the path that is stored in a symbolic link, you can use the long listing for the list command. 
Next, let's learn how you can create both symbolic links and hard links. We will start with symbolic links. 
In order to create a symbolic link, you can use the ln command-- link command-- with the option -s from symbolic link. So ln -s source and target allows you to identify the new link file that will be created and the target file for this link. You can use either relative or absolute path names when you create such links. And as I mentioned before, it's not mandatory for a target to exist when you create a symbolic link. 
So here is a sample where you can see how you can create a symbolic link. This symbolic link is called dante. Symbolic link, it's-- sorry, called dante_link, and refers to that dante file from var/tmp directory. 
So when you will use right now list -f comment, you will notice the @ symbol that it used to specify that this dante link is in fact a symbolic link, not a traditional file. 
If you create a link by using ln command without the option -s, a hard of link will be created. Again, you can use either relative or the absolute path names when you create the hard link in order to identify the source and the target for this command. 
So in order to remove both symbolic and hard links, you can use the same command-- remove-- just as you do for standard files. Here you can see how you will remove the dante_link that you just created previously. 
Next, we have a quiz. Which command creates two new directories with the second directory as a sub-directory of the first? 
Again, it will be a good thing to pause the video and try to figure out for yourself what is the correct answer. 
The correct answer here is B. Mkdir -p will do just that. 
The second quiz-- the rm -r command removes non-empty directories. True or false? 
Yeah. The correct answer here is A, true. If you remember, -r, it uses as an option to specify recursive action-- allows you to remove non-empty directories. 
The last section will be about the tools that you can use in order to search for files and directories. So usually, when you need to search in both UNIX and Linux, a simple text string is all you need. But sometimes you will need to be able to identify more complex file names, so you can take advantage of wildcards. 
To define wildcards, you can use regular expressions. And most of the user space programs that you can use to perform searches will take advantage of such regular expressions-- grep more or less, vi vim, emacs, and so on. All of them can use such regular expressions. 
The regular expressions that are supported by both UNIX and Linux are based on the ones that are defined initially for Perl. So-- are similar with the ones that are also used by other programming languages. So if you already learned about regular expressions in Java, or in PHP, or in Python, for sure we'll be able to learn very quickly the ones that are available for Linux or UNIX. 
So these are the most important wildcards that you can use to create regular expressions. Asterisk or glob, that should be used to match 0 or more characters. Question mark-- that matches 0 or a single character. Period-- that will match a single character. Caret-- that will match the beginning of the line. Dollar-- that is used to match the end of the line. 
Brackets-- that allows you to define a character class or characters that are inside the brackets will be part of this character class and should match one character position. Single quotation marks-- that will tell the shell to ignore any enclosed metacharacters. Double quotation marks-- that will be used to enclose a space, for example. And backslash-- that can be used to escape metacharacters that will follow. 
So let's see some samples regarding patterns. 
So the first command list will display the current files in the working directory. So if you want to list only the file 2 and file 4, you should create a character class that will refer to those two characters and then build the regular expression by using the file prefix. And this will only list file 2 and file 4. 
You can also create character classes using dash. For example here, you accept any character between 0 and 9. Of course, full details about regular expressions and how you can build such regular expressions with samples, you can find in the man in the documentation. 
During the practice, you will have a lot of exercises that will allow you to familiarize yourself with these kind of regular expressions. 
Here you will display all the numbers that start with file are followed by a number between 0 and 9 and are finished with 3. 
In order to search files and directories, you can use the find command. The find command will need a path name-- this is the location to start the search-- followed by a number of searching criteria. The most commonly used searching criteria, it's the name of the file. So -name indicates the searching criteria. And the file name pattern indicates the regular expression that will be used to match the files. 
The find command will search in a recusive way. And when a file will match the pattern(patron) that was specified, the full directory path will be printed. 
You can search by multiple criteria like the type of the file, the permissions, size, group, group owner, the user owner, and many others. Again, in the man you can find complete details about the options that are available for find. 
Here we can see some samples. I want to search for a file named myscript in the current directory. Second one shows you how to search for any file named mypage beginning with the root directory. And the last one allows you to search for all the files that start with mess, probably from messages, that are located in the var directory. 
Most of the time, you would like to do something with the files that you are able to find using this command So you can specify an expression after the find that allows you to specify what to do with those files. 
So the expression will generally use exec command that allows you to indicate a command that will be executed on the files that were identified here. So -exec allows you to specify a command. This command will be executed for each file that is identified, and the file name will replace this syntax. So the file name will take place of the two braces in order to be able to execute that command. 
For example, here I want to list-- to generate the long listing for each file that was identified by my find. And I looked for files that start with file from the opt directory. 
You can also search files and directories using the locate command. The locate command will use a database that is generally updated once a day. So if you just created some files or directories, probably those files and directories will not be included in the search results. 
In order to update the database, you should run a command update db. Generally, as I mentioned before, this command is scheduled to run once a day in order to update the information from the database. So generally, using locate you will be able to quickly find files or directories that were created until today. 
Of course, because the locate command will work on a database, it will provide the results much faster than the find command, which is looking directly on the file system. 
The locate command works pretty similar with the grep command that will be covered in the following slides and allows you to search for files that contains a specific pattern-- as I mentioned before-- based on an database that is updated daily in most cases. 
The grep command-- a global regular expression print-- allows you to search for a specified pattern in one or more files, printing any lines that will contain the specified pattern. The grep is very useful when you don't want to search for metadata, but you want to search in the content of the file. 
For example, here to search for the occurrence of first pattern in the file Hello, you can use this command, and the line that contains the first string will be displayed. 
Sometimes, it will be useful to highlight what was being searched for. So you can take advantage of the option --color, which will highlight the searched item in the output. You can see here that first is displayed in red this time. 
Next, we have a quiz. Which of the following copy commands will result in an error message? 
Again, you can pause the video and try to think for yourself. 
The correct answer here is A. You cannot copy a directory into another directory without specifying the recursive option. 
During the practice, you will familiarize yourself with the commands that can be used to access files, directories, commands that you can use to work with files and directories, and command that allows you to locate files or to search for files that contains specific text. 
This concludes the third lesson of our training session. 

$ touch command create a new empty file.
$ touch space
$ touch moon sun cosmos

mkdir make dir command 
$ mkdir [options] directory_name
$ mkdir -p directory_name: includes a pathname and the intermediate directories, create all of the nonexisting parent directories that to 
$ mkdir /Reports/Weekly/

rm removing command (destructive command)
$ rm -r(Solaris)/-R(Linux) 
check if existing files or directories by prompt: $ rm -i
borra recursivamente y solicita confirmación $ rm -iR ~/monthy_reports/
fuerza el borrado: $ rm -f, --force 

Links symbolic and hard

A symbolic link called a symlink (l) or soft link is a pointer that contains the full pathname to another fiel or directory
can link files and directories located across different file systems.
broken if the linked to file is removed
ls -l

A hard link shares the inode of another file and increases the link count  of the linked to file
must be on the same file system and persist even if the other fill is removed
ls -li and compare the inode numbers and link counts

Create a symbolic link: $ ln -s source_file target_link

$ ln -s fileOne.txt ~/tmp/link_fileOne.txt
$ ls -F ~/tmp/
link_fileOne.txt@

Example:

$ ln -s Alan_Beaulieu-Examples-SQ.txt link_Alan.txt
$ link_Alan.txt -> Alan_Beaulieu-Examples-SQ.txt*
$ cat link_Alan.txt

$ ln -s /etc/profile myprofile
$ cat -n myprofile -> number lines

Hard link: 
$ ln fileOne.txt ~/tmp/Hardlink_fileOne.txt
$ ls -F ~/tmp/
Hardlink_fileOne.txt  link_fileOne.txt@

The simbol @ indicates that the file is a symbolic link.

$ cat ~/tmp/Hardlink_fileOne.txt 
ver el contenido del archivo con el número de línea: (number line): $ cat -n ~/tmp/Hardlink_fileOne.txt

Whe creating a hard link, if the source doesn't exist then fails.
(Solaris): ln: cannot access <source>
(Linux): ln: failed to access '<source>': no such file or directory

Hard link can be used to make a backup of the original file. 
Thus if someone tries to move or remove the original file, the backup would remain.

This will not protect the original file from saved editing changes.

wild cards patterns
regular expressions (regex or regexp)  

programs like grep, more, less, vi, vim, emacs, sed, awk, tcl, ls, find, Microsoft Office use searches

languages like Perl, Java, PHP (Hypertext Preprocessor), Python and Microsoft C and C++ use regex_patterns

wild cards (metacharacters)
* Asterisk (glob) matches zero or more characters
? Question mark matches zero or a single character
. Period matches a single character
^ Caret at the beginning of the line 
$ Dollar at the end of the line
[] Brackets (a character class). The characters inside the brackets match one character position.
`` Single quotation marks (apostrophe) tell the shell to ignore any enclosed metacharacters.
"" Doble quotation marks enclose a space.
\ Backslash escapes the following metacharacters.

(Linux)$ man 7 regex
(Solaris)$ man -s 5 regex

$ touch file1 file11 file2 file23 file3 file32 file4 file45

$ ls file[24]
file2
file4

$ ls file[0-9]
file1
file2
file3
file4

$ ls file[0-9][3]
file23

$ ls file[3]
file3

$ ls file[3]?
file32

Searching Files and Directories

find [pathname] -name filename_pattern
find [pathname] [expression]

-name
-type
-perm
-empty
-size
-group
-user

$ find -name 'Alan_Beaulieu?'*
./Alan_Beaulieu-Learning_SQL-EN.pdf
./Alan_Beaulieu-Examples-SQ.txt
./MotoG4_BackUp/WhatsApp/Media/WhatsApp Documents/Sent/Alan_Beaulieu-Learning_SQL-EN.pdf
./CFTIC/SQL/Alan_Beaulieu-Learning_SQL-EN.pdf

Busca desde la raíz todos los ficheros que contengan 'file': $ find / -name 'file*'
[expression] puede ser: ls -l, cp or mv, 
(-exec, -ok) y or Y acknowledgment

Busca desde /opt todos los archivos que empiezan con 'file' y luego ejecuta el command ls -l por cada archivo que encuentre y será reemplazado por esa siintaxis 
$ find /opt -name 'file*' -exec ls -l {} \;
-rw-r--r-- 1 root root 1712 oct 14 11:23 /opt/ORCLfmap/prot1_64/etc/filemap.ora
-rw-r--r-- 1 uucp 143 354 dic  8  2017 /opt/java-jdk/jdk1.8.0_231/lib/missioncontrol/plugins/com.jrockit.mc.console.ui.notification_5.5.2.174165/icons/file_obj.gif

$ find -type f
              	b      block (buffered) special
		c      character (unbuffered) special
              	d      directory
              	p      named pipe (FIFO)
              	f      regular file
              	l      symbolic link; this is never true if the -L option or the -follow option is in effect, unless the symbolic link is  broken.   If  you
                     want to search for symbolic links when -L is in effect, use -xtype.
		s      socket
		D      door (Solaris)

$ find ~ -type d
$ find ~ -type f
$ find . -name *.txt

find files were modified in the last day: $ find . -mtime -1

find files ordinary files of size 0 include an option prompting you with yes or no: $ find /etc -type f -size 0 -ok ls -l  {} \;
< ls ... /etc/sensors.d/.placeholder > ? yes
-rw-r--r-- 1 root root 0 abr  5  2017 /etc/sensors.d/.placeholder
< ls ... /etc/subgid- > ? yes
-rw-r--r-- 1 root root 0 oct 14  2019 /etc/subgid-
find: ‘/etc/ssl/private’: Permission denied


locate command will use a database that is generally updated once a day.
locate works similar with grep command
locate is dependent on the system administrator schedulling and updatedb command, which updates the location database.
Usually the schedulling of the updatedb command is only once daily.
Therefore, the files you just created might not be found by locate until the following day.

$ locate [option] regex_pattern
$ locate filename

Busca los ficheros que empiezan por 'file': $ locate -b '\file'

ASAP ( as soon as possible )

Grep command: global regular expression print, permite you search a pattern in one or more files.

grep [options] regex_pattern [files(s)]

Busca "select" en el fichero LearningSQLExample.sql: $ grep select LearningSQLExample.sql

$ grep select --color LearningSQLExample.sql 

-v, --invert-match - Invert the sense of matching, to select non-matching lines.
$ grep -v root /etc/group

Display all the lines that have the pattern(patron) "net" in the /usr/lib/sysctl.d/50-default.conf file with line numbers
$ grep -n net /usr/lib/sysctl.d/50-default.conf 

Display the number of lines that contain the pattern(patron) "net" in the /usr/lib/sysctl.d/50-default.conf file
$ grep -c net /usr/lib/sysctl.d/50-default.conf
 
Display the number of lines that contain at least one instance of the pattern(patron) "net" both in uppercase and lowercase (ignore case) 
in the /usr/lib/sysctl.d/50-default.conf file
$ grep -ic net /usr/lib/sysctl.d/50-default.conf

In addition, originally there were two variant programs: egrep and fgrep.

egrep has been replaced by grep -E => Interprets pattern as an extended-regexp regular expression 
$ egrep '(users|root)' /etc/group
Display all lines in the filename that contain either the "Sales" or "Finance" pattern: $ egrep '(Sales|Finance)' filename

fgrep has been replaced by grep -F => Interprets pattern as a list of fixed-strings separated by newlines, any of which is to be matched

Id command details about the current user and the current session:
$ id
uid=1001(hadoop) gid=1001(hadoop) groups=1001(hadoop),27(sudo)

$ who
sc       tty7         2021-01-15 22:42 (:0)

vim Editor, which is one of the most used text editors on both Unix and Linux.

So first of all, you will learn how to start the vim editor, and then what are the key combinations that you can use inside the vim editor in order to modify text files. As I mentioned in the beginning, both Unix and Linux have been created in order to represent almost anything like files. And that's why all the configurations that are needed for different applications to run are generally represented using textual files.

One of the most common operations that an administrator or a user on the Unix or Linux operating system will be to modify textual information that exists in your files. Vim editor, as I mentioned, is commonly used for this kind of operation.

We will start quickly with the first section. The vim editor-- it's an interactive command line editor that you can use to create or modify text files. As you will notice during the lecture and also during the practice, the vim editor is a very powerful editor. It supports hundreds of key shortcuts that you can use to do almost any kind of modification to your text files.

In fact, for the same kind of operation, there are multiple key combinations that you can use to do it. This is because the text editors that were used during the last 30 years were made using different editors that were created on the different branches available for Unix and Linux. And each such editor that was used in the past had its own key combinations to be used.

In Vim, a merge operation has been tried in order to support as many as possible of those key combinations, and in this way to allow administrators from different Unix or Linux branches to be able to use the same editor without the need to learn a specific set of key combinations. In fact, the vim editor is an improved version of another well-known editor-- it's called vi-- which is an improved version of another well-known editor that was used a lot, the x editor.

Right now, in both Oracle Solaris and Oracle Linux, the vim editor is the default editor that is configured out of the box. Of course, you can add other editors if you need. But as you will see, because it is very powerful, most of the administrators prefer to use the vim.

In order to start the vim editor, you can use the vi command in both Linux and Solaris, because on both operating systems, a symbolic link has been created that allows you to start the vim editor with the vi command.

So in order to create, edit, and view files using the vim editor, you should use the vi command. When you start the vim editor, you can either start it with an empty buffer that allows you to just write some text that can be then saved in an file, or you can start the editor by indicating a special file, which will be created if does not exist, or it will be opened if it already exists.

When you start the vim editor, you can specify some options. The most commonly used options are -R, which allows you to open a file in read only mode, in order to prevent accidental overwriting of the content of the file. This is useful sometimes because, as I mentioned before, the vim editor is mostly used to modify configuration files, and sometimes you would like to only have a look in such a configuration file to search for some specific configurations in order to learn about them, but you don't intend to actually modify that file.

So vi -R allows you to start the vim editor in read only mode, and in this way to be able to just check the content of the file without actually modifying that file.

Another interesting option is the -r, which allows you to recover from a crash. So if you are in the process of editing a file and something is wrong, and because of that your vim editor needed to be restarted, you can do that by using the recovery mode. That allows you to recover some of the changes from the buffer that was created for your vim session. Of course, for more information about the vim editor, you can use the main page that is available.

Next, you can see what is the first view that is displayed when you start the vim editor on both Linux and Solaris. Here you will be able to see some details about the version of vim that you have on your operating system, and some information about the most commonly used commands that are available for your version.

The vim editor is a modal editor, so it supports multiple modes of operations, and provide you support for six basic modes of operation. The most commonly used modes are the first two, command mode and the insert mode.

The command mode is the default mode, which is configured when the vim starts, and allows you to enter commands that will be executed. Generally, it's very useful when you need, for example, to search a text or to do a global search and replace or something like that.

The insert mode is useful when you need to modify the text, and you need to add text or replace the text that is already in your file. In order to switch from command mode to insert mode, you need to use some keystrokes.

For example, in order to switch from command mode to insert mode, you can use the i shortcut that allows you to enter into the insert mode and insert text before the cursor, or o, that opens a new blank line below the cursor and allows you to add text. a-- that allows you to append text after the cursor. R, which allows you to replace the text after the cursor. You can also use I. That allows you to insert text at the beginning of the line. O, that allows you to open a new black line above the cursor, and A, that allows you to append text at the end of the line.

Those are the most commonly used key commands that allows you to switch from command mode to insert mode. To go back to the command mode, you just need to hit Escape.

The visual mode allows you to configure how the text will be highlighted in your visual editor. The select mode is the default mode that is used on Microsoft Windows operating system, which allows you to select fragments of text. The command line mode allows you to enter ex commands, as I mentioned before. The vi editor, which is the ancestor of the improved vim editor, was initially the visual interface to the ex editor, which in turn is an extended version of the ed editor.

So those text editors have a very long history. First, the ed editor has been created, then the ex editor, then the vi editor has been created as a visual interface for ex in order to finally have the vim editor that is used right now for most distributions of Unix and Linux.

And the last mode is the ex mode. That is optimized for batch processing, when you need to do a set of operations on multiple files. So, to repeat the same operation on the current file.

As I mentioned before, the command and the insert mode are the most commonly used, and will be the ones that you will familiarize with during this training course. In order to switch between those two modes, you need to use the keys like I, O, A and R-- upper or lower case. And in order to return to the command mode, just press the Escape key. And then you will be able to enter commands.

In order to enter commands, if you are in the command mode, just use double points, and then add the command. For example, write quit allows you to save the changes in the file, and then exit the editor.

The second part of this lesson provides information about the most commonly used key combinations for modifying files with the vim editor. As I mentioned in the beginning, you can use vim with -R option in order to open a file in read only mode. Most of the Linux and Linux distributions includes a symbolic link called view that allows you to, in fact, execute this command. So the view command will invoke the vim editor in read only mode, which means that you cannot change the content of the file. You cannot save any changes you try to do on that file.

In order to exit from this read only mode, you just need to enter the q command. The q command allows you to quit. If you made some changes, then you should also add this symbol in order to exit without saving.

So next, let's see the most commonly used key sequences that allow you to work with the vim editor. First, the key sequences that you can use to move around in your editor. H, left arrow or Backspace to go one character left, J or down arrow to go down one line, and so on. Here in this table you can find the most common combinations that are used when you need to navigate around in your editor.

Next, you can see another set of key sequences that you can use to navigate in the editor. Go scroll down, up, one screen, or 1/2 screen, and so on.

The next table provides the information about the command that you can use to insert or append text to a new or an existing file by using the vim editor. Most of those commands are the ones that allow you to switch from command mode into the insert mode.

Next, you can see the command that you can use in order to delete text by using the vim editor. Next, you can see the commands that you can use to change text, undo a change, repeat an edit function in the vim editor.

Next, we have the first quiz for this section. Again, it will be good to pause the video and try to figure out for yourself the correct answer to this quiz.

In which vim modes are commands normally initiated? In order to execute commands, you need to be in command mode. So, C is the correct answer here.

The next table shows you the commands that you can use to search for or substitute text using the vim editor. You may recognize here some commands that you already used, and we already discussed. For example, searching text in i

Next, you can see the commands that you can use to copy and paste text in the vim editor.

Next, you can see the commands that you can use to save and quit the vim editor. You may notice here the command that I was pointing out previously, which allows you to quit without saving the changes. You can also use the q for that.

In order to save and quit, you can use write and quit, or you can use x, or you can use zz.

You can also customize a vim session by setting options. There are a lot of options that you can use in order to customize the vim editor.

So in the seventh version of vim, there are more than 295 options. Of course, not all of them are used very common, but the most important ones will be listed in the next slide.

You can use those options in order to enable features that are not activated by default. And in order to set those options, you'll need to use the set command.

Here you can see the most commonly used options that allows you to customize the vim editor. The interesting ones are show line numbers, search in case sensitive mode, display invisible characters, display the current mode of operations, display all the variables that are set.

Next, we'll have another quiz. Which three commands can you use in order to save the changes in your file and then quit the vim editor? Again, you can pause the video and try to figure out for yourself which is the correct answer.

So the correct answer here is write and quit. Write, quit without save. I already saved it, so, without save, doesn't matter too much, and zz.

Next one. Which of the following commands searches backwards for a pattern? Again, you can pause the video and try to figure it out for yourself. So the correct answer here is A. This one allows you to search backwards.

Those are the most important topics about the vim editor and how you can use vim editor in order to modify the files. During the practice, you will try to use vim tutor in order to experience with most commonly used combinations. And then you will use the vim editor to create a file and to make some modifications to that file.

$ vi [options] filename
$ vim [options] filename

to recover the file if the system fail or crashes: $ vi -r filename 
open in read-only mode $ vi -R filename

(Linux and Solaris)$ man vim ór $ man vi
(Linux)$ whic vimtutor
(Solaris)$ vimtutor


vi provides six basic modes of operation 
1. command mode (normal) - default (delete, change, copy and move text)
2. Insert (and replace) mode

 i - inserts text before the cursor
 o - Opens a new blank line below the cursor
 a - appends text after the cursor
 R - Replaces text after the cursor
 I - inserts text at the beginning of the line
 O - Opens a new blank line above the cursor
 A - appends text at the end of the line
 :r - Read and inserts the contents of another file

3. Visual mode
4. Select mode
5. Command-line mode
6. Ex mode

Moving the Cursor:

 H - Left one CHARACTER
 J - Down one LINE
 K - Up one LINE
 L - Right ONE CHARACTER
 W - forward one WORD
 B - Back one WORD
 E - End of the current WORD
 $ - End of the LINE
 0 - Beginning of the LINE
 ^ - FIRST non-white space CHARACTER on the LINE
 Enter - Down to the beginning of the NEXT LINE
 G - To the LAST line of the FILE
 1G - to the FIRST line of the FILE
 :n - to line N
 nG - to line n
 Ctrl + F - Pages FORWARD ONE screen
 Ctrl + D - Scrolls DOWN ONE half screen
 Ctrl + B - Pages BACK ONE screen
 Ctrl + U - Scrolls UP ONE half screen
 Ctrl + L - Refreshes the screen
 Ctrl + G - Displays current buffer information

Deletion Commands
 R - Overwrites or replaces characters
 C - Changes or overwrites
 s - Substitutes a string for a character 
 x - Deletes a character at the cursor
 nx - Deletes n characters beginning at the cursor
 dw - Deletes a word or part of the word to the right of the cursor 
 dd - Deletes the line containing the cursor
 ndd - Deletes n lines beginning with the line containing the cursor
 D - Deletes the line from the cursosr to the right end of the line
 :n, nd - Deletes lines n-n. For ex: :5-20d deletes lines 5-20

Edit Commands
 cw Changes or overwrites characters at the cursor location to the end of that word
 r - Replaces the character at the cursor with one other character
 J - Joins the current line and the line below
 xp - Transposes the character at the cursor and the character to the right of the cursor
 ~ - Changes letter casing to uppercase or lowercase, at the cursor
 u - Undoes the previous command
 U - Undoes all changes to the current line
 . - Repeats the previous command

Searching for Substituting (Replacing) Text Within a File:

 /pattern - Searches forward for the pattern(patron)/string (regex_pattern)
 ?pattern - Searches backward for the pattern(patron)/string (regex_pattern)
 n - Searchs for the next ocurrence of the pattern(patron)
 N - Searches for the previous ocurrence of the pattern(patron).
 :%s/oldstring/newstring/g - Searches for the old string and substitutes(replaces) it with the new string. The % searches the whole file and g replaces every ocurrence of oldstring with newstring

:%s/Dante/Homer/ -> change first ocurrences on line
:%s/Dante/Homer/g -> change all ocurrences 
:%s/Dante$/Homer/ -> change the ocurrences at the end of line
:%s/^Dante/Homer/ -> change the ocurrences at the beginning of line

Copy and Paste commands:

 yy -  a copy of a line containing the cursor
 nyy -  a copy of n lines containing the cursor
 P - Puts  (yy) or deleted (dd) text after the line containing the cursor
 p - Puts  (yy) or deleted (dd) text before the line containing the cursor
 :n, n co n - Copies lines n-n and puts them after line n ex:1,3 co 5 copies lines 1-3 and puts them after line 5
 :n, n m n - Moves lines n-n to line n ex:4,6 m 8 moves lines 4-6 to after line 8

Save and Quit commands

 :w - Saves the file with changes by writing to the disk
 :w new_filename - Writes the contents of buffer to new_filename
 :wq - Saves the file with changes and quit the editor
 :x - Saves the file with changes and quit the editor
 ZZ Saves the file with changes and quit the editor 
 :q! - Quits without saving chages
 ZQ - Quits without saving chages

Session Customization Commands

 :set nu - Shows line numbers
 :set nonu - Hide line numbers
 :set ic - Search / ignore case sentitive
 :set noic - Search to be case sensitive 
 :set list - Display invisible characters, such as ^I for a TAB and $ for endline 
 :set nolist - Turn off Display invisible characters
 :set showmode - Display the current mode of operation
 :set noshowmode - Turn off the current mode of operation
 :set - Displays all the vim variables that are set
 :set all - Displays all vim variables and their current values

https://www.vim.org/
/usr/share/vim/vim80/doc/help.txt
/usr/share/doc/vim/html/index.html
https://vimhelp.org/#help.txt

files that vi use for customization: .exrc and .vimrc 

Para modificar la configuración al arrancar e incluido la línea set nu al final del fichero: /etc/vim/vimrc.tiny

Bash Shell
 
This is the default shell that is used on most Unix and Linux distributions, and it's commonly used by most administrators in order to execute commands on the operating system.

So you will learn about shell expansion that allows you to generate shell tokens. You will learn about metacharacters that you can use in the shell in order to redirect the output of a command to be used by other commands. You will learn about how to define variables, local variables and environment variables, that can be used by current processes, by the current shell instance, or variables that can be used by all shell instances that are created by fork, for example.

You will also learn about the command history that is available in Bourne again shell, which allows you to repeat previous commands. And you'll learn about the files, the configuration files, that you can use in order to customize the work environment.

So let's quickly start with the first section, shell expansion. While you are working in an shell instance, you will need sometimes to repeat the same information or very similar information, or to define sets of ranges of information that may contain a lot of elements. So, in order to define those sets of ranges of information manually, you can take advantage of shell expansion.

Set expansion allows you to generate a large number of shell tokens by using a very compact syntax. Expansion will be performed on the command line after the command is split into tokens, each token being generated by a specific syntax. Some of the most common types of shell expansions that are used in practical use cases are brace expansion, tilde expansion.

In fact, tilde expansion, you already used during the previous practices. Tilde expansion, if you remember, allows you to refer to the current user home directory, and in this way, with a single character to refer sometimes to a pretty long path.

Parameter expansion. That is based on local variables or environment variables. Command substitution, which allows you to use the output of one command in order to build another command. And path name expansion or file name generation. So lets try to explore all those kinds of shell expansion.

We will start with brace expansion. Brace expansion allows you to generate a number of arbitrary strings based on different combination of characters. So you will be able to define patterns that will include braces that can contain a series of comma-separated strings or a sequence expression. Yes, that it's using a def. Followed, of course, by an optional postscript.

So you will be able to define a preamble, which is optional, and postscript, which also is optional. And inside the braces, you can define a comma-separated list of strings. In this way, a number of strings will be generated by combining the preamble with the first string and with the postscript, the preamble with the second script and with the postscript, and so on.

So, in this way, you will be able to generate a number of strings based on a PATTERN  - ("patron") -  that allows you to refer to a very large number, let's say, of elements within very compact syntax. For example, this brace expansion will generate three different strings-- ade, ace, and abe. You can even use more such combinations in order to generate complex strings that may be needed for your applications or for your automating scripts.

The tilde expansion allows you to refer, using a single character, to the home directory of the current user. You can also use the tilde symbol followed by a user name to refer to the home directory of a specified user.

The parameter expansion is based on variables, local variables or environment variables. You will learn about the differences between those two kinds of variables in a few slides. So in Unix and Linux, you can define hundreds of parameters, variables, and then use those variables in your commands by prefixing the name of the variable with the dollar sign.

So here, you can see how you can refer to the current user name, how you can refer to the current user home path, and so on. You can even define your own variables and then use those variables inside your command in order to take advantage of this parameter expansion.

Command substitution is another very powerful mechanism that allows you to use the output of a command in order to build another command. The command substitution can be specified in two ways. You can either use a dollar followed by a pair of parentheses, or you can use a pair of backquotes in order to indicate the command that you want to be executed first, whose output will be included in the second command.

You can see here such an example. I use ls -l in order to list the long set of attributes for a set of files. Which files? The ones that are returned by this second command.

So, in fact, here, first, which passwd will be executed, which will return the path to the passwd file, passwd executable. And then the output of these command will be used to build the second command, which will be ls -l on /usr/bin/passwd. Which will display, as you can see, the long listing, the attributes for this passwd file.

The same effect you will get if you use the second syntax that it takes advantage of backquotes. So, in this way, you can build complex commands that may use the output of other commands.

The path name expansion simplifies the location changes within the directory hierarchy. The path name expansion, or file name generation, includes symbols like the asterisk, which matches zero or more characters. It's also called the globbing. The question mark symbol, which matches zero or a single character. A pair of square brackets, which will match a single character. And the dash symbol, which represents the previous working directory. It's important to note that the asterisks, the question mark, and the square brackets are also metacharacters that are supported by regular expressions.

Next, you can see an example on how you can take advantage of the asterisk expansion symbol. As I mentioned before, this symbol-- which is also a wildcard character or a glob, and it's used to match zero or more characters, except the leading period of a hidden file-- can be used when you need to refer to long names using a shorter prefix.

So, for example, here I would like to be able to list all the files that start with f. So I can use this path expansion by taking advantage of the asterisk symbol. So f followed by asterisk allows me to display here all the files that starts with f from the current directory, all the objects that starts with f from the current directory.

The question mark expansion symbol-- again, it's also a wildcard character, can be used in regular expressions-- allows you to refer, to match, any single character, excepting the leading period of a hidden file. Using this character, you will be able to list, for example, all the files and directories that will start with the string dir and are followed by one other character. So dir1, dir2, and dir3 will be listed in this case.

The square bracket expansion symbol can be used to create a character class which can represent a set or a range of characters for a single character position. So I don't want to allow any kind of character in a specific position, but I want to be able to specify a set of characters or a range of characters to be allowed in that specific position.

So in order to define a set of characters, you just need to list those characters inside brackets. The order does not matter. In order to define a range of characters, you just need to include inside the brackets the starting character, followed by dash, and the end character of the range.

Next, we have the first quiz for this lesson. So which of the following expansion symbols equates to the absolute path name of the user's home directory? It will be good to pause the video and try to figure out for yourself which is the correct answer. So the correct answer here is tilde. Tilde allows you to expand to the absolute path name of the user's home directory.

In the second section, you will learn about the shell metacharacters that can be used for command redirection. Shell metacharacters are specific characters, generally simple symbols, that have special meaning within the shell.

So the most important metacharacters that are recognized as special characters by the Bourne again shell are pipe, which allows you to connect multiple commands together by sending the output of a command as input to another command. So the output of the command from the left will be used as input by the command on the right of the symbol.

Ampersand, which specifies background execution. Semicolon, which is used as command separator. You already saw some examples with semicolon already. Backslash, that allows you to escape the next metacharacter in order to use it as it is and to remove its special meaning. The round brackets, that you can used to group commands. You already saw round brackets used previously when you want to include output of a command into another command, dollar sign in front.

Angle brackets-- less than, greater than, redirection symbol, and & special character. Backquotes and dollar, which is used for command substitution. Space, tab, newline, which are used as internal separators for commands. In the next few slides, you will learn about redirection symbols in order to see how you can use the output of a command in order to preserve it, generally, and to use it when you need to troubleshoot some specific issues.

So, by default, any process that is started by the shell will receive or read inputs from a specific communication channel which is called standard input. By default, this is connected to the keyboard. So you will be able to use the keyboard to send input to your application.

And we'll be able to display messages or errors by using two communication channels which are called standard output and standard error. By default, both of those communication channels are connected to the screen, to the terminal that it used to start that process, to the shell that started the process. Those three communication channels are also called stdin0, stdout1, and stderr2.

Input redirection allows you to configure a process to read the input from somewhere else, not from the keyboard. Most commonly, your application, your process, will be able to read the input from a file. You already prepared all the input data that is needed, so you just want to provide it to your application.

The output redirection allows you to send the output that is generated by your application from the screen, from the terminal, into something else, into another communication channel. Generally, you will use a file instead of the terminal. So, in this way, you will be able to store the output and the error messages that are generated by your program into a file, where you can take a look later in order to investigate any potential issues you may have with that specific application.

So each process will be able to work with these three communication channels by using three file descriptors. Each file descriptor will have a number associated and a symbol, an abbreviation. The standard command input its abbreviated stdin, and it's using the 0 file descriptor number. The standard command output, it's abbreviated stdout, and it's using 1 as file descriptor number. And standard command error, it's abbreviated stderr, and it's using the file descriptor number 2.

You will be able to redirect those file descriptor numbers using the special characters that you already saw, the metacharacter that you already saw. So, in order to redirect the standard input, you can use the lower than sign. To redirect the standard output with the overwrite, you use the greater than character. To redirect the standard output with append, you use two greater than characters one after the other.

To redirect the standard error, you use 2, which is the file descriptor for standard error, and the redirection character. To redirect both standard error and standard output to the same file, you need first to redirect the standard output. And then you configure 2 channel to be redirected to the same file descriptor, to be redirected to 1. So, in this way, standard error and standard output will be redirected to the same descriptor which is configured for standard output.

The last metacharacter that we will cover in this lesson-- it's very commonly used. It's the pipe symbol. As you will see, the pipe symbol allows you to connect multiple commands together in order to use the output of one command as input for the second command, so to redirect the standard output from one command to be used as standard input for the second command. A very powerful mechanism that allows you to combine multiple commands, multiple simple commands, in order to implement a more complex processing logic.

So, next, you can see some examples of using the redirect for standard input. In this case, you will take the content of the dante file and use it as input for the mailx command. So I will send a mail to the oracle user by using the content from dante file. So this symbol allows me to redirect the standard input. You can use either this one or this one. So indicating explicitly the file descriptor, it's also a possibility. If you remember, the file descriptor for standard input is 0.

In a similar way, you will be able to redirect the standard output either with overwrite or with append. If the file does not exist, the shell will create that file. If the file exists, in the first case the content of the file will be overwritten. In the second case, the command will append the output to the end of the file. And here you can see an example that will redirect the output of list command into the directory_list file in the current directory.

In a similar way, you will be able to redirect the standard error. So the error messages will go to /dev/null in the first case. You will ignore the errors. In the second case, you will redirect both the standard error and the standard output to the same file. So, as you can see, I redirect here the standard output to dat file and the standard error to the standard output. So, in this way, both of them will go to the same file, to dat. So when you will display dat, you will see here both error messages and output messages.

The pipe symbol allows you to redirect the standard output from one command to the standard input of another command. So, in this way, you will be able to connect multiple commands together in order to implement more complex processing. For example, here I want to count the number of the current users on the system. So who will list each user on its own line. So word count -l will return the number of the lines that were generated by who. Of course, you can use any number of pipes to connect several command and to implement in this way more complex processing.

Here, you can see another example of using pipe in order to view a list of all the subdirectories that are located in the etc directory. So, as you can see, I display the file type, and the file type for a directory is indicating using this slash. So I will look for this symbol in order to be able to display only the directories. Next, I use the output of the head command in order to extract the first 10 lines from the dante file. Then I will extract the last three lines from the first 10 lines and I will send them to the printer.

So, as you saw, the greater than metacharacter allows you to redirect the standard output to a file instead of printing the output to the screen. If you would like to also see the output before it is redirected to the file, you can use the tee command. The tee command will display first the output, and then will redirect that output to the file, to be able to both see it and store into the file.

Quoting is the process that allows you to instruct the shell to mask or ignore the special meaning of a shell metacharacter. The quoting symbols are apostrophe or single forward quotation marks, that will instruct the shell to ignore all enclosed metacharacters, and double quotation marks, which will instruct the shell to ignore all enclosed metacharacters and white spaces, except for three symbols-- backslash, which is the escape symbol, single backward quotation mark, and dollar sign and parentheses. So if you use double quotation marks, you will still be able to include a command in order to use his output in your main command.

We have another quiz for this lesson. So, again, it will be a good opportunity to pause the video and try to figure out for yourself what is the correct answer for this quiz. So the correct answer here is false. Here, I redirect the standard error, not the standard output. In order to be able to redirect the list into a file, I need to redirect the standard output, not the standard error. 

types de Shell Expansions

 Brace expansion: ({}) arbitrary strings may be generated.
 sintax: [optional preamble] {string1[,string2][,stringn]} [optional postscript]
 combining the preamble with the first string and with postscript
 combining the preamble with the second string and with postscript
 and so on... 
 you will be able to generate a number of strings based on a PATTERN  - ("patron") -  that allows you to refer to a very large number, 
 complex strings that may be needed for us applications 
 ex: a{d,c,b}e => generate three different strings: ade, ace, abe

 Tilde expansion: allows you to expand to the absolute path name of the user's home directory
 (~) which represents the home directory of the current user 
 (~) which a username which represents the home directory of the specified user

 (~) equivale al nombre de ruta absoluto del home del user
 
 cambiar de directorio dentro del mismo $HOME

 cd ~/Downloads/
 pwd
 /home/hadoop/Downloads

 cambiar al $HOME de otro usuario

 cd ~user2
 pwd
 /home/user2

 Parameter expansion: there are hundreds of parameters/variables that you can define.
 and then you can use include ($) symbol prefixing
 ex: variable USER: echo $USER y variable HOME: echo $HOME
 local variables 
 environment variables

 Command substitution: allows you to use the output of a command in order to build another command.
 $(command) or (`command`)
 ex:

 $ which passwd
   /usr/bin/passwd

 $ ls -l $(which passwd)
   -rwsr-xr-x 1 root root 62024 ago 21  2019 /usr/bin/passwd

 $ ls -l `which passwd`
   -rwsr-xr-x 1 root root 62024 ago 21  2019 /usr/bin/passwd

 $ ls -l $(which vi)
 /home/hadoop/newdir
 0 lrwxrwxrwx 1 root root 20 ene  2  2020 /usr/bin/vi -> /etc/alternatives/vi

 Path Name Expansion/File Name Generation
 * - used to match zero or more characters - ex: $ ls f* - also used by regular expressions
     In the user's home directory, use the (*) expansion symbol: $ echo D*
 ? - used to match zero or a single character, also used by regular expressions - ex: $ ls d?
 [] - used to matcheds a single character, created a character class which represents a set or range of characters for a single character position:
    A SET of characters is any number of specific characters NOT ORDERED necessarily.
    - ex: [abc] = [cab] $ ls [fp]* 
    A range of characters is a series of ORDERED characteres.
    - ex: [a-z] or [0-9] $ ls [a-f]*
    also used by regular expressions
 - represents the previos working directory

 $ cd -
 /home/sc/Documents
 $ pwd
 /home/sc/Documents 
 $ cd -
 $ pwd
 /home/sc
 $ cd -

 $ echo $PWD
 $ echo $OLDPWD
 
Shell Metacharacters

 | - pipe - sends the output of the command on the left as input to the command on the right of the symbol
 & - ampersand, bakcground execution
 ; - semicolon, command separator
 \ - backslash, escape the next metacharacter to remove its meaning
 () - round brackets, command grouping
 < > >> - redirection symbols
 ` ` $( ) - command substitution
 space tab newline "whitespace" - Internal Field Separator (IFS)

Command Communication Channels: By default the shell receives or reads input from the standard input - the keyboard - and displays the output and error messages to the standard output - the screen

File Descriptors: each process works with three file descriptors

0 - stdin - Standard command input - Default Keyboard
1 - stdout - Standard command output - Default Screen
2 - stderr - Standard command error -Default Screen

Redirection Metacharacters

- Redirection of standard input (<) - stdin

  $ command < filename 
  or
  $ command 0< filename - 0 - stdin - Standard command input

  $ mailx oracle < ~/dante (dante file as the input of mailx command)

- Redirection of standard output (>) - stdout

  $ command > filename 
  or
  $ command 1> filename - 1 - stdout - Standard command output
  and 
  $ command >> filename              # appends

  $ ls -l > directory_list
  $ echo "That's my directory list file" >> directory_list; cat directory_list

- Redirection of standard output (>>) append

- Redirection of standard error (2>) - stderr

  Redirects any standard error mesagges to the: /dev/null file (delete them)
  command 2>/dev/null

- Redirection of both standard error and standard output (2>&1) redirected to the dat file.
  The standard output and the standard error redirect to dat file.
  $ ls /var /test 1> dat 2>&1
  $ less dat

ex: redirecciona la salida standard (1) y la salida standard error(2>&1)
$ touch lab/error
$ ls /var /test 1>lab/error 2>&1
$ cat -n lab/error

- The pipe symbol (|) redirects the standard output from one command to the standard input of another command
  command1 | command2

  $ who -> show who is login on
  $ wc -l -> count lines

  $ who | wc -l -> count all users are login on

  $ ls -F /etc | grep "/" | wc -l -> count all directories there are on /etc

  $ head -10 dante | tail -3 | lp -> print 

- Redirection of standard output (stdout) by using tee command 

  If you want to see the output from command1 before it's redirected to a filename:

  $ head -10 dante | tee [-a] filename -> If el fichero no existe, lo crea; si existe redirecciona la salida y con -a add la salida al final del archivo. 
 - Quoting Symbols
   (' ') - ignore all enclosed metacharacters
   (" ") - ignore all enclosed metacharacters and white space except: 
	\ - interpreting the next symbol after 
	' ' - execute and display the output for a command enclosed
	$(command) - execute and display the output of the command enclosed

 $ echo $SHELL -> /bin/bash
 $ echo '$SHELL' -> $SHELL


A variable or a parameter, it's a temporary storage area in the memory where you can set different values. You can set values as user, but you can also set such values by using programs or by using configuration files for your shell.

There are two main categories of variables that you can define. You can create local shell variables that will only be available in the current instance of your shell and generally are used for short terms, and global environment shell variables that are defined based on local shell variables that had been exported. So, in order to create a global environment shell variable, you just need to export one of your local shell variables. The global environment shell variables will be available not only for the current instance of the shell but also for any subordinate sessions, sessions that are created either by fork or spawn.

In order to display the value that is currently set for a variable, you can use parameter expansion. So echo command allows you to display in the output the value of a variable. You just need to refer to the variable using a dollar sign in front of the variable name.

If you want to display all the local shell variables that are defined right now in the current shell instance, you should use the set command. The set command, as you can see here, displays all those variables with their values.

If you want to display the values for the global environment shell variables, you can use the same syntax, echo followed by the name of the global variable. If you want to display the list of all global environment shell variables that are defined right now, so the variables that were exported, you need to use the environment command. env command will display those variables.

In order to set or unset values for local shell variables, you just need to use the assigning operator, equal operator, with the name of the variable. So history equal 50 allows you to define or to overwrite the value of this history local variable. And then echo allows you to display that value. To unset a local shell variable, you just need to use the assignment operator without any value. history equal empty will unset the value of this variable.

In order to create a global environment shell variable, as you can see here, first you need to define this variable, and then export the variable. Then, using the env command, you will be able to list the entire list of global variables. You look for history, and you can see that this variable is right now in the list.

There are a number of default shell variables that are defined on the Bourne again shell. It's important to note that each shell may have its own way to define variables. What we've discussed here is valid for the Bourne again shell. So the default variables that are created for the Bourne again shell are listed here.

EDITOR defines the default editor for the shell. FCEDIT defines the editor that will be used by the fc command. The fc command can be used with the history, command history mechanism, in order to edit the previously executed commands. You will see some examples of using the command history in one of the next sections for a current lesson.

HOME variable sets the directory to which the cd command will change when no argument is supplied on the command line. By default, this variable refers to the home directory of the current user. LOGNAME sets the login user of the current user. PATH specifies a colon-separated list of directories to be searched when the shell needs to find a command to be executed. Very important because the correct configuration of this variable will allow you to execute commands without the need to indicate the full path to those commands.

PS1 and PS2 can be used to customize the primary shell prompt and the secondary shell prompt. In this way, you can have some information about, I don't know, the local path, the host name of the computer you are working, or this kind of information that may be helpful to identify a specific shell session. And SHELL indicates the name of the shell that is currently executed.

So PS1, it's one of the variables that you can use in order to customize the Bourne again shell. Using the PS1 variable, you will be able to customize, as you can see here, the prompt that is displayed before you can enter different commands. So using this variable, for example you will be able to configure, using some shortcuts that are fully explained in the documentation, what kind of information will be included here.

For example here, the name of the current user followed by the host name will be displayed, followed by the working directory the current working directory. So those elements will be included in the prompt that you will be able to see when you work with this shell. In a similar way, you will be able to configure the prompt for the Bourne again shell on Solaris.

The PATH variable, it's another very important variable that allows you to configure the list of directories that will be searched by the shell when a command needs to be executed. Here, you will be able to put this list of directories separated by colons. So every time a command will need to be executed by the shell, the shell will search the directories that are listed in the PATH from left to right, in sequence, in order to locate the command. If the shell does not find the command in the list of directories, it will display and not found error message.

In order to be able to quickly execute commands without the need to specify the full path of those commands, you need to include the directories where you have those commands in the PATH variable. In the notes page for this student guide, you may find the commands that are needed to include the /home/oracle/lab directory into the PATH, and in this way to be able to execute commands from that directory without the need to specify the full path.

Next, we have another quiz. Again, it's a good time to take a pause and to try to think for yourself to find the correct answer to this quiz. Yes. So the correct answer here is true. Yes, the set command allows you to list all the local shell variables and their values. Yes, so this is the correct answer in this case.

you will learn about the command history. The shell, by default, is configured to keep a history of all the previously executed commands. There are two global shell variables that allows you to control the number of the entries that will be kept in this history-- HISTFILESIZE and HISTSIZE. HISTSIZE contains the number of the maximum number of entries, and the HISTFILESIZE the maximum size of the file that is used to keep those commands.

The history mechanism will allow you to view, repeat, or modify previously executed commands in order to re-execute them. The history command allows you to display all the entries that you have right now in the history file to the standard output. The history will be recorded in a special hidden file, .bash_history, that is created in your home directory.

So, in order to display the last four commands, you can use the history command followed by the number of the commands that you want to be displayed. As you can see here, each command will have an ID associated. An exclamation symbol, or so-called bang, it's an alias built in to the bash shell which enables you to repeat a command.

First of all, you can use the exclamation symbol followed by the ID of the command that you want to re-execute. So in order to re-execute, I don't know, cd etc, you need to use an exclamation symbol followed by this number, 110, for example. Here you have an example that allows you to re-execute the ps command, this one. So that's why you use exclamation mark followed by 112.

You can also use the relative location number. So if you use this syntax, you will be able to execute the, I don't know, nth command from the end. Here, I want to re-execute the second command from the end, which is, let's say, ps command.

The two exclamation marks used together can be used in order to repeat the last command that is part of the history. You can also simply recall the last command by pressing up arrow and then return, and it's the same like using two exclamation marks.

You will be able to search the history entries by using Control plus R keys together. So you will be able to specify a PATTERN  - ("patron") -  that will be used to search in the history in this way. So, if you want to search for a clear command, for the last occurrence of the clear command, you just need to enter cl, press Enter, and then see the command that was found.

If that is not the command you are looking for, just press Control plus upper R again in order to continue the reverse search. In order to exit, just use Control-C. Return or Enter will execute that command.

You can search for and execute using an exclamation mark combined with a search string. Again, please be very careful, because if you identify in this way destructive commands, you may not get the result that you are expecting.

You will also be able to edit the commands before re-executing them. In order to edit the commands, you can take advantage of the shell inline editor. The default configuration of the Bourne again shell is to use emacs as a default shell inline editor. But you can switch to vim if you are more familiarized with vim. So in order to switch between emacs and vim, just use set -o vi or set -o emacs.

You can also set the editing mode by using the EDITOR or VISUAL shell variable. So configure EDITOR or VISUAL special variables. In this way, you will be able to edit the commands before executing those commands.

File name completion, it's a very useful feature that allows you to enter the first part of a file name or a directory and then press a key to fill out or complete the file name or directory. To invoke the file name completion, just enter the desired command followed by one or more characters of your file name. And then press Escape or Tab keys, or just press Tab key.

In the case there is a single option, the file name will be automatically completed for you. This is very helpful because, in this way, you will be able to avoid typing errors. So here is a sample. Just use list sb and then press the Tab key. The shell will complete the remainder of the file name, sbin for example.

You can request also the shell to present all possible alternatives of a partial file name. This request can be invoked by pressing either Escape and the equal sign in sequence, or by pressing Tab twice. It's quite simple to just use Tab twice. So a list with all the possible options will be displayed and you will be able to continue the typing in order to be able to fill in the entire name of your file or directory.

The last section will be about how you can customize the work environment for the current user. When a shell session is started, a number of initialization files are executed out of the box in order to configure the shell session. So alongside with the home directory, where you can create and store files, the users will need an environment to be set up in order to allow them to access the tools and resources. So you need to configure the PATH. You need to configure different variables that may be used by your applications.

So when a user will log into the system, the work environment will be determined by the content of those initialization files. Because the Bourne again shell has been created based on the Bourne shell, and the Bourne shell was using some initialization files and the Bourne again shell may add another set of initialization files-- because the technology has been evolved in time and the Bourne again shell will try to be compliant with the Bourne shell-- as you will see, there is a pretty important number of initialization files that can be used to define the environment.

Some of the files are supported for back compatibility with the Bourne shell. Others were introduced by the Bourne again shell because, in practice, in practical use cases, has been considered that there is a need for different files to initialize the environment. So there is a difference between a login shell, that is configured when a user is logging into the system, and a forked shell, a shell that is started from an existing session. So there are two files that are available to configure those two kinds of shells, alongside with all the files that are supported previously by the Bourne shell.

So, as you will see, there is an important number of such files that will be used. It's good to familiarize yourself with those files in order to choose the best one when you need to configure your environment. Also, you need to take into consideration that some of the environment variables should be set up by the administrators. That's why there are some global configuration files that are configured by system administrators, and some local files that are used by each user to customize his own environment.

So the default initialization files that are defined by the administrators are defined in the etc directory and they will apply to all the users on that system. The local initialization files that are used by each user will be created in the home directory and allows each user to customize their own working directory.

So when the Bourne again shell is invoked, it will first read and execute the commands from /etc/profile file. This is a global file that is generally modified by the administrators, and it's compliant with the Bourne shell. Then bash will read and execute commands from bash_profile, bash_login, and bashrc, which will also execute /etc/bashrc if it is exists.

So bash_login, it's a special file that should only be used to initialize the login shell. bashrc, it's a special file that should be used to initialize the shell when the shell is started as a forked shell. All those three are local files that can be modified by the end users, so bash_profile, bash_login, and bashrc. While /etc/bashrc, it's a global file, and generally it's configured by the administrator.

In the absence of the files that were mentioned before, the profile file will be executed from the current directory. This profile file, it's a local file that is compatible with the Bourne shell, which will be executed only if there is no bash-specific configuration file.

You can also specify a number of commands that will be executed when the shell will exit. So the bash will read the bash_logout, will read and execute the commands from the bash_logout if such file exists. Generally, this file, it's recommended to be used to clean up the environment before you are exiting this environment.

Most of the time, the bashrc file will be used as personal initialization file for configuring the user environment. The file needs to be defined in your home directory, should have the name that is specified, should be a hidden file. So it needs to start with a dot. And here you can put any kind of commands that you need in order to configure your working environment, like, I don't know, setting shell environment variables, or configuring terminal settings, or even starting different applications.

However, if you make any changes here, it does not guarantee you that those changes will be applied immediately. So those changes will be applied normally when you recreate a Bourne again shell instance. In order to apply those changes immediately, you just need to reread, to re-execute this file.

There are two ways to reread, to re-execute the bashrc file-- exit the current terminal session and restart a new terminal session, or use the command source, which can be executed also with dot followed by space, in order to re-execute this file in the current shell, and in this way to have all the configurations from this file made for the current user for the current session. So this command or this command. Those commands are similar.

Next, we have another quiz. Again, it will be a good time to pause the video and try to figure it out for yourself what is the correct answer. So which of the following is the default command line editing mode in Bourne again shell? The correct answer here is c, emacs. The Bourne again shell is configured by default to use the emacs editor for editing the command history. You can change this with set -o.

Those are the most important information about how you can take advantage of the features that are provided by the Bourne again shell, which is the default shell used by most of the Unix or Linux distributions that are available on the market. In the second part of the practice, you will try to familiarize yourself with how you can take advantage of variables, how you can work with the command history, and how you can customize the user's work environment. This concludes the fifth lesson of our training course.

Local shell apply only to the current instance
Global environment shell are Local shell that had been exported are valid for subordinate session   

Display the value stored inside a local shell variable SHELL
$ echo $SHELL
/bin/bash

Display Local shell variables 
(Linux) there are variables and functions
(Solaris) really only has variables
$ set 
BASH=/bin/bash
PATH=/home/hadoop/anaconda3/bin:/home/hadoop/anaconda3/condabin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin:/home/hadoop/hadoop-3.2.1/sbin:/home/hadoop/hadoop-3.2.1/bin:/home/hadoop/hadoop-3.2.1/hive-3.1.2/bin:/home/hadoop/spark/spark-3.0.0-preview2-bin-hadoop3.2/bin:/home/hadoop/mongodb-linux-x86_64-ubuntu1804-4.2.2/bin


Display Global environment
$ env
SHELL=/bin/bash

Create a bash Local shell variable
$ history = 50
$ echo $history

UnSet a Local shell variable
$ history = 
$ echo $history

Create a bash environment shell variable 
$ export history = 75
$ env | grep history
$ echo $history


$ apps=/opt/
$ priv=/sc/
$ set | grep priv
$ cd $apps; pwd
$ cd $priv; pwd

EDITOR: default editor for the shell
FCEDIT: editor for fc command
HOME: cd command
LOGNAME: login name of the user
PATH: list of directories when the shell search for a command
	To include a directory in the PATH:
$ echo $PATH
/home/hadoop/anaconda3/bin:/home/hadoop/anaconda3/condabin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin:/home/hadoop/hadoop-3.2.1/sbin:/home/hadoop/hadoop-3.2.1/bin:/home/hadoop/hadoop-3.2.1/hive-3.1.2/bin:/home/hadoop/spark/spark-3.0.0-preview2-bin-hadoop3.2/bin:/home/hadoop/mongodb-linux-x86_64-ubuntu1804-4.2.2/bin
lo add al final del path existente: $ export PATH=$PATH:/sc 
lo add al inicio del path existente: $ export PATH=/sc:$PATH 
Asignar el path nuevamente:
$ PATH=/home/hadoop/anaconda3/bin:/home/hadoop/anaconda3/condabin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin:/home/hadoop/hadoop-3.2.1/sbin:/home/hadoop/hadoop-3.2.1/bin:/home/hadoop/hadoop-3.2.1/hive-3.1.2/bin:/home/hadoop/spark/spark-3.0.0-preview2-bin-hadoop3.2/bin:/home/hadoop/mongodb-linux-x86_64-ubuntu1804-4.2.2/bin

$ mkdir sbin
$ PATH=$PATH:~/sbin
$ echo $PATH

How to modify prompt

PS1: primary bash shell prompt
	(Linux)
	$ PS1='[\u@\h \W]\$' 
           \u -> user name
	   \h -> host name
           \W -> curren directory
	(Solaris)
	$ PS1='[\u@\h:\W]\$' 
PS2: secundary bash shell prompt ">"

ex: 
$ echo $PS1

$ echo $LOGNAME
hadoop
$ uname -n
sc-ubuntu-18-04-5-lts
$ echo $PWD
/home/hadoop

$ PS1="$LOGNAME`uname -n`\$PWD $ "
hadoopsc-ubuntu-18-04-5-lts/home/hadoop $

$ PS1="[\u@\h \W]\$ "
[hadoop@sc-ubuntu-18-04-5-lts ~]$ 

$ PS1="(base) \[\e]0;\u@\h: \w\a\]${debian_chroot:+($debian_chroot)}\[\033[01;32m\]\u@\h\[\033[00m\]:\[\033[01;34m\]\w\[\033[00m\]\$ "
(base) hadoop@sc-ubuntu-18-04-5-lts:~$ 

SHELL: name of shell

command history -> $ man history there are HISTFILESIZE and HISTSIZE that control the number of entries.
the commands are stored on ~/.bash_history 

$ echo $HISTFILESIZE $HISTSIZE
$ echo $HISTFILESIZE 
2000
$ echo $HISTSIZE
1000

Default -> display all history entries to standard output

to display n last lines: $ history n
$ history 10
$ history | less
to clear the history: $ history -c

to re-execute a command use: !##### 
$ !2135
$ ps -ef | grep session-2.scope

or relative location number: !-n
 2135  ps -ef | grep session-2.scope
 2136  history 10

or search and executing combined with a string - <<-O-J-O->> con el string que este buscando - USAR CON CUIDADO - 
$ !sys
$ !cl

$ !-2
$ ps -ef | grep session-2.scope
hadoop    5902  3201  0 15:12 pts/1    00:00:00 grep --color=auto session-2.scope

Repeat LAST command
$ !!
$ ps -ef | grep session-2.scope

Search a command
$ Ctrl+r and type something to repeat Ctrl+r again


The default command-line editing mode IN "bash" IS "emac"
To switch between two modes: 
$ set -o vi
$ set -o emacs

To set the editing mode by using the EDITOR or VISUAL shell variables:
$ export EDITOR=/bin/vim
$ export VISUAL=/bin/vim

File Name Completion: "Tab key" ó "Esc+=" ó "Tab key" twice

The default initialization files that are defined in the /etc and they will apply to all the users on that system

User Files for bash shell when is invoked 
if exists this files:

1. execute commands from /etc/profile -> Global file - Administrator
2. execute commands from ~/.bash_profile
3. execute commands from ~/.bash_login -> Its a special file that only intialize the login shell
4. execute commands from ~/.bashrc -> personal initialization file for configuring the user environment

if the login shell exist execute commands from ~/.bash_logout -> used to clean up the environment before exit

if NO exists then: 

5. execute commands from ~/.profile

Configure the ~/.bashrc File, is a personal initialization file for configuring the user environment., before the changes you just need to re-executed this file.
$ source ~/.bashrc or
if you are in $HOME path then: $ source .bashrc or
$ . ~/.bashrc or
$ exit

to use the emacs editor for editing the command history you can change this with set -o

You can define global definitions like this:
ex:
if [ -f /etc/bahrc ]; then
        . /etc/bashrc
fi

In the next lesson, you will learn about how you can configure the security policy for your Linux- or Unix-based operating system. So in this lesson, you will first learn about the permissions that you can use to control the access to both files and directories. Then you will learn how you can change the ownership for files and directories. In order to be able to configure the security policy, you need to be owner of that file or directory.

There are two kinds of ownerships. We have the user ownership, the user owner. It's the one that created that file or directory. Of course, the owner can be changed in the meantime, so not always the owner will be the guy that created the file or directory, because this can be changed. But initially, the user owner will be the user that created the file or directory.

And the group ownership, the group owner will be initially set to the primary group of the user that created that file or directory. If you remember when we discussed about groups, I told you that there are two kinds of groups, the primary group of a user and the secondary groups. This is the role of the primary group, to provide the group ownership for that file.

If you have ownership, either as user or as group, you will be able to make changes to the configuration, to the security policy for that file. And you will also be able to benefit from a dedicated set of permissions, because, as you will see in the next slides, on Unix and Linux, you will be able to set specific permissions for the user owner, for the group owner, and for all the others. In this way, you will configure, in fact, the security policy.

So first, you will see how you can change the ownership. Then you will see how you can change the permissions for files and directories. And last, you will see how you can modify the default permissions that will be associated with the new created files and directories. You will learn first about how those permissions are allocated, and then what is the mechanism that you can use to influence the final permissions that will be allocated to the new created files or directories.

So let's quickly start with the first section. Of course, one of the most important functions for an operating system is to provide you the mechanism to secure the system. So in order to do that, you will need to limit the access to authorized users, and to prevent unauthorized users from accessing the files or directories.

The Unix and Linux will use two basic mechanisms to prevent unauthorized access to a system. First of all, all users who are trying to work with a system will need to authenticate by verifying the username and the password. And second, you will be able to use a set of permissions, which are defined as access control list, for each file and directory in order to protect those objects, those resources.

So all files and directories in both Unix and Linux will have a default set of standard access permissions that can be configured. Those access permissions will control who can access the files, and provide the fundamental level of security to both files and directories. The standard set of access permissions will be established by special settings. It's called umask. So the umask command, which is described later in the session, will allow you to control what will be the default, the initial permissions that will be associated to each new file or directory that you create.

First of all, let's learn how we can view the current set of permissions that are configured for our files and directories. So in order to display the current permissions, you may use either ls minus l, or at ls minus n. Both of them will display, as you can see here, the list of permissions, as three groups of three characters.

The first three are used to indicate the permissions for the user owner. The next three will be used to indicate the permissions for the group owner. And the last three are used to indicate permissions for the other users.

There are some special symbols that are used to specify those permissions, r for readable, w for writable, x for executable, and dash for no permissions. You may also see from some time an s symbol used instead of x for user or group permission, or a t symbol instead of x for other permissions. Those are some special flags that can be configured to provide some special permissions for specific files or directories. We will discuss about those special permissions in the last part of the current lesson.

So there are three permissions groups, the permissions for the user owner, the permissions for the group owner, and last, the permission for all the other users. Those permissions are-- those permissions groups are indicated using the special symbols, u for user owner, g for group owner, and o for other users. Those will be in fact the symbols that you will need to use when you would like to add or remove permissions from a specific group.

Each permission group allows you to define three permissions that are called the permissions set. Each set consists of read, write, and execute permissions, that are represented by using the r, w, and x characters. Each file or directory will have in this way three permissions set for the three types of permissions groups. The first permission set represents the user owner permissions, the second set the group permissions, and the last set the other permissions.

The presence of any of those characters as r, w, or x, indicates that that specific particular permission is granted. A dash symbol indicates that a particular permission is denied. The initial permissions that will be automatically assigned to each new object that you create on Unix or Linux will be determined based on the user's umask configuration. You will learn how this configuration is used in the last part of this lesson.

So how those permissions are interpreted for files and directories? As you can see in this table, the read permission is needed for a user to be able to display the file content or to copy the file. The write permission is needed for a user to be able to modify the file content, but only if you also have read permission. And the execute permission is needed in order to be able to execute that file if it is an executable file.

Again, in order to take advantage of the execute permission, you also need to have the read permission. So only execute permission is not enough to be able to execute that file. You also need the read permission.

For directories, the read permission allows you to list the directory content with the ls command. The write permission allows you to modify the content of the directory, by deleting files for example. And the execute permission can be used in order to be able to access that directory, to be able to use the change directory command on that directory.

If you also have read access you will be able to run ls minus l to list the content of the directory. If you do not have read access, you can run the ls command as long as you know the file name that you want to see its metadata.

In order to display the current set of permissions, as I mentioned before, you can take advantage of ls minus l and ls minus n. Those two commands also display the ownership information. So ls minus l will display the username and the group name, while the ls minus n will display the user ID and the group ID. Here are the user IDs and the group IDs in this case.

So here you can see what is the output that is generated by this command. You may notice here the user ID and group ID that I was talking about.

And here are the permission sets. The first character will always be the file type.

So how those permissions are interpreted? When someone is trying to access a specific file for doing a specific operation, it will be checked that his user ID is equal or not with the owner of that file. If yes, the user owner permissions will be validated. If not, it will be checked that any of his groups is the same with the group owner of that file or directory. If so, the group permissions will be used. Otherwise, the other permissions will be used.

Next we have the first quiz for this lesson. So again, it will be good to pause the video and try to figure out for yourself what is the correct answer to this one.

So the correct answer here is a. I need read and execute permissions for owner and group. Read and execute for owner, read and execute for group, and no permission for the others.

In the second section, you will learn about how you can change the ownership for the files and directories. You saw that in Unix and Linux, every file and directory needs to be owned by somebody, somebody that generally will be able to do more operations than others. So in order to see, to learn about the ownership for any specific file or directory, you can use either ls minus l or ls minus n to display the username and the group, or the user ID and the group ID.

In order to change the ownership on files or directories, you can use two commands. Change owner, that can be used to change both the user and the group ownership. And change group, that allows you to change only the group ownership.

So here is the syntax for change owner command, which allows you to specify the new user owner and group owner for a specific resource. It's important to note that you can change the ownership only for files and directories that you own. Of course, the root, the administrator will be able to change the ownership of any object.

Please note that you can change the user owner in a way that will provide to other users the possibility to manage that object from now on. So you will give that object away and you cannot get it back without the help from the system administrator or the new owner of that object. So you need to use this command carefully.

If you only need to change the group ownership, you can take advantage of change group command by specifying the new group ownership for this file.

Next, there is the second quiz for this lesson. Again, it will be a good thing to pause the video and try to figure out for yourself the correct answer for this quiz.

Yeah. The correct answer here is true. You need to be careful when you give away the ownership, because it wont be always very easy to get it back.

Next you will learn about how you can change permissions. In order to change the permissions on files and directories, you can take advantage of the change mod command. Either the user owner of the file or directory or the root user will be able to use this command to change the permissions. The change mod command can be used in either symbolic or octal mode. The symbolic mode, you will use a combination of letters and symbols to add, remove, or set permissions for each permission group, while the octal mode, which is also called absolute mode, will use octal numbers in order to represent each permission group.

So here is how you can use the change mod command in symbolic mode in order to change the permissions for a file name. First of all, you will need to indicate who will have the permission changed, the user group, the group permissions, the other permissions, or all permissions. Then you should specify the operation. You can add permissions, remove permissions, or assign permissions. And then you can specify the actual permission that will be added, removed, or assigned.

So let's see an example. The change mod command will use a symbolic mode that consists of three parts, first the user category, followed by the function that will be performed, and the permissions that will be affected. The user category can be user, group, other, or all. The function to be performed can be add, remove, or set. The permissions affected can be read, write, or x, plus some special file permissions in sticky bit, s and t, that are described in the next. Slide I told you there are some special symbols that are used to describe some special permissions. For example, if you use g plus x in this way, you will add executable permission to the group permission.

As I mentioned before, there are some special permissions that can be specified on files or directories, which are called setuid, set group ID, and sticky bit. Let's learn about the special meaning of those permissions.

When the setuid idea or setgid permissions are set on an executable file, the process that will be started by executing that file will run by using the security identity of the owner of the file. By default, when you run and process, the process will run with the user's security identity, the user who started that process. So in this way, that process will only be able to access the files and directories that are accessible to you.

But sometimes, you may need some special processes that can access files or directories that are not normally directly accessible to your user identity. So how can you execute such a program? For example, if you like to change your password, the passwords will be stored in a specific file in an encrypted form. But that file should not be accessible, not even in read mode to end users. I shouldn't be able to go and access that file, or worse modify that file to change the password for other users.

So in this case, how a process that is started by myself to be able to modify that file, because the passwd command, it's able to modify that file? It's able to go and change the password for my user, but only to my user. Well, this is possible because that file is configured with the setuid flag, which allows that file to be executed in the security context of the owner. And the owner of that file will be the root user, which is able to access and modify that file.

So when you have special programs that need to access special files in a controlled form, you should set this special flag at either user level or group level to allow the process that is started by executing that file to be able to work with some special files based on the owner of the file permissions, not the user that started that file. I will be able to start the file, because I will have read and executable rights on the file. I will not have the right to modify the file.

But based on the owner permission, which will be the root, the process that is started will be able to modify the special file, the etc passwd or etc shadow file where the passwords are kept. So this special permission allows, as I mentioned before, a process to be started with the security content of the user owner and/or group owner.

The last special file permission, the sticky bit, should be used on directories in order to protect the files within that directory from being deleted by anyone. I want to only allow that file to be deleted by the user who owns the file, the owner of the directory, or the root user. Otherwise, normally, each user who has permissions to modify the directory will be able to delete that file.

I don't want something like that. This is useful generally when I have shared folders. And I want for anyone to be able to access the files, to create files, to modify files. But I would like only the owner of the file to be able to delete files. So that's why I can activate this sticky bit that will only allow the owner of the file, the owner of the directory, and the root user to delete that file. So in this case, the executable and the read permissions will not be enough to allow me to delete files.

Next, let's see how you can change permissions by using the octal mode. The syntax for the change mod command in the octal mode, it's listed in the current slide. You just need to use change mod, followed by the octal_mode and the file name. The octal mode, sometimes called the absolute mode, consist of three octal numbers, 4, 2, and 1, that represent a combination, a sum of the permissions, from 0 to 7 for the file or directory.

So the read permission is represented as 4, 2 at the power of 2. The write position, it's represented as 2, 2 at the power of 1. And execute permission is represented as 1, 2 at the power of 0. In this way, you represent those permissions in octal.

So as you can see here, 7 as octal value means read, write, execute permissions, so all three. 6 means only read and write permissions. 5 means read and execute permissions. 4 means only read permissions.

3 is generally not useful, because it means write and execute permissions, which doesn't make sense if you cannot read that file. You need also read permissions. That's why you are indicated to see the notes page, where this is referred.

2 means only write permissions, which again doesn't make sense. If you do not have write you cannot-- if you do not have read permissions, you cannot write. 1 means just execute permissions, which again doesn't make sense, because you cannot execute something that you cannot read. And 0 means no permission.

So you can modify the permissions for each category of users by combining octal numbers. The first set of octal numbers will define the user owner permission, the second set the group permission, and the third set the other permission. You can see here some examples, like 640, which will provide read and write permissions to user owner, read permissions to group owner, and no permission to others; 644, which will provide read and write permissions to user owner, read permissions to group owner, and read permissions to others; and so on, so such combinations.

Of course, this kind of permission doesn't make sense, again because you cannot have execute permissions without read permission. This kind of permission, it's not useful.

So in order to set the permission, you just need to use change mod, specify the octal value for the three groups. If you do not specify the octal values for all the three groups, the change mod command will use instead of any missing octal digit to the left 0s. So change mod 44 will in fact become change mod 044.

So next quiz, what is the correct octal value for write and execute file permission? Again, it will be a good thing to pause the video and try to figure out for yourself what is the correct answer.

If you remember, read means 4. Write means 2. And execute means 1. So write and execute, it's 2 for write and 1 for execute, which means that the correct octal value for write and execute should be 3.

Next one, what is the correct permissions set for read, write, execute for user; read, execute for group; and read, execute for others in the octal mode? Again, try to pause the video and figure out for yourself what is the correct answer.

The correct answer here will be 4214141, so should be 755. So 755 is c.

In the last part of our lesson, you will learn about how you can modify the default permissions. So when files and directories are created, the initial permission values are automatically assigned. Those are 666 for files and 777 for directories. But you will be able to affect the initial permissions that will be used by configuring a umask. So the umask command allows you to define a set of permissions that will be extracted from the initial maximum permissions values in order to compute the final permissions set that will be configured for your files.

To view the umask value, you can run the umask command. To set the umask value, you may run the umask command with the new value. The default umask that is used for Solaris is 022, whereas the default value for the Linux is 002. So from this point of view, Solaris is a little more secure, because it will not provide write permissions, not to groups.

So again, how you can determine the umask value? As you can see, if you have the umask value of 0, in this case the default final permissions that will be allocated to files is read, write for directories; read, write, x, because, as you remember, for files 666 is used, while for directories 777 is used. So if I do not extract anything, I will remain with 666 for files and 777 for directories.

If the umask is 1 for file permissions, I will stay with the same value. The execute permission, it's already not included. For directories, as you can see, the execute permission will not be granted anymore, so the umask will be extracted from the directory permission. Normally, the directory permissions provide you read, write, execute, so if you extract the execute, then you will remain with read, write in this case.

If the umask is 2, you will remove the right permission for both of them, and so on. So please remember that always you will subtract the umask from the actual value. So when you mask out certain permissions, the default permissions assigned to the new file and directory will be computed by extracting the umask.

If you need to change the umask, just need to execute the umask command by specifying the new value. You can check that this value has been changed by using the umask command. It's important to note that generally the default umask is set in etc/profile. You can change it in your local configuration file, like bash_profile, bashrc, or bash login, depends on the situations.

Those are the most important information about how you can work with the permissions that will secure the access to both files and directories. In the Practice, you will try the most important commands that are used to manage the file ownership, the file permissions, and to modify the default permissions for yourself. This concludes the 6th lesson of our training course.

$ ls -n
-rw-r--r-- 1 1001 1001 184781 ene 24 17:00 'Unix and Linux Essentials.txt'

- -> file type
rw-r--r-- -> permissions user, group, other
1 -> link count
1001 -> UID
1001 -> GID
184781 -> size 
ene 24 17:00 -> Last modification Data Time
'Unix and Linux Essentials.txt' -> File o Directory name


standard set of access permissions - (ACL) - Access Control List
user name and user identification number - (UID)
group name and group identification number - (GID)

user's umask configuration: umask

file type
d: directory
-: file

rw-r--r-- <-> permissions - chmod 644 

Primer grupo: Owner (u) user: rw-
Segundo grupo: Group (g) user: r-- 
Tercer grupo: Other (o) user: r-- 
Readble: r (4)
Writeable: w (2)
Executable: x (1)
No permission: -

s instead of x for user or group permission, 
t instead of x for other permissions. 

chmod -R 775 filename -> -R recursive

provide some special permissions for specific files or directories

system administrator maintains groups in /etc/group

Permissions		File				Directory

Readble: r		Display content			List the contents ls

Writeable: w		Modify content but		Modify content and deleted (rm) a file
			Only with (r) permissions 	Borrar only with (x) permissions

Executable: x 		Execute a executable file	Use cd commands
 			Execute a script Only with	ls (rx) permissions
			(rx) permissions

A directory of general use at least (rx) permissions
A file or directory can belong to ONLY one group at a time.

1 -> Link count -> hard links to the file or directory

1001 -> UID propietario del archivo ó directorio
1001 -> GID grupo de usuarios propietarios del archivo o directorio

There are two types of groups users Primary and Secondary
Primary Group  — is created when user account is created and the user is automatically added to it. 
                 the files created by the user automatically belongs to the user group
	         is stored in the /etc/passwd file 

Secondary Group  — This group is not required and only there to give users access to other resources 
		   they’re don’t already have access to.. 
		   Users can belong to none or as many secondary groups 
		   listed in the /etc/group

find the groups a user belongs to
$ groups
hadoop sudo

List and Display los grupos que existen en el system
$ less /etc/group
$ cat /etc/group

$ cat /etc/group | grep "sudo"
sudo:x:27:hadoop

$ cat /etc/group | grep "hadoop"
sudo:x:27:hadoop
hadoop:x:1001:

Display los grupos que tiene el group "hadoop"
$ groups hadoop
hadoop : hadoop sudo

Display los usuarios que existen en el system
$ users
hadoop

Display el id del user "hadoop"
$ id hadoop
uid=1001(hadoop) gid=1001(hadoop) groups=1001(hadoop),27(sudo)

Display the members of a particular group
$ getent group cdrom
cdrom:x:24:

Determining permissions

if (UID of user == UID of file or directory){ 
    USE user/owner permissions
   } 
    else if (GID of user == GID of directory ){
             USE group permissions
            } else {
                    USE other permissions
            }
   

endif

chown used to change username and group ownership 
chgrp used to change ONLY group ownership

show the UID and GID numbers 
$ ls -n
-rw-r--r-- 1 1001 1001 185669 ene 24 17:46 'Unix and Linux Essentials.txt'

show the username and the group 
$ ls -l
-rw-r--r-- 1 hadoop hadoop 185669 ene 24 17:46 'Unix and Linux Essentials.txt'

$ chown hadoop:hadoop Unix\ and\ Linux\ Essentials.txt 
a User can change the ownership ONLY for objects that user own
a root user can change the ownership of ANY object
<<-O-J-O>> 
BE CAREFUL when give away the ownership because it wont be always very easy to get it back you need help from the system administrator

$ chgrp hadoop Unix\ and\ Linux\ Essentials.txt 
a User can change the group ONLY if user is own of object

- chmod Symbolic mode: letters and symbols to add or remove permissions for each permission group
 $ chmod symbolic_mode filename
 who
	u User
        g Group
        o Other
        a (ALL) - User, Group, Other
 op
        + Add permissions
        - Remove permissions
        = Assign Permissions Absolutely

 permissions
	r Read
	w Write
	x Execute

 [ugoa][+-=][rwx]

 chmod g+x filename => Group, Add, Execute then Executable permissions is added to the Group to the file or directory
 chmod o-r filename => Other, Remove, Read then Read permissions are removed to the Other to the file or directory
 chmod g-r filename => Group, Remove, Read then Read permissions are removed to the Group to the file or directory

 ex: $ chmod g+rw mytextfile => Group, Add, Read and Write permissions is added to the Group to the file or directory

 Special file permissions Setuid, Setgid, Stick Bit [st]
 When special file permissions are set on executable files, 
 the user who runs that executable file executes it with the permissions of the UIDor GID. 
 who has the "s" inplace of the "x" for executables privileges.

 search for the user/owner permissions that has "s" inplace of "x" 
 $ find /usr/bin -perm -4000 -exec ls -l {} \;
 ex:
-rwsr-xr-x 1 root root 59640 mar 22  2019 /usr/bin/passwd

 search for the group permissions that has "s" inplace of "x" 
 $ find /usr/bin -perm -2000 -exec ls -l {} \;
 ex:
-rwxr-sr-x 1 root crontab 39352 nov 16  2017 /usr/bin/crontab

 $ ls -l /usr/bin/passwd
-rwsr-xr-x 1 root root 59640 mar 22  2019 /usr/bin/passwd

 $ sudo ls -l /etc/shadow
-rw-r----- 1 root shadow 1534 ene 12 21:51 /etc/shadow
 $ sudo ls -n /etc/shadow
-rw-r----- 1 0 42 1534 ene 12 21:51 /etc/shadow
 
 Stick Bit [st] - t flag
 Protects the files whitin a directory from being delete by anyone, except the user who owns the file
 the owner of the directory or the root user
 who has the "t" inplace of the "x" which makes it world readable and world writable
 drwxrwxrwt  16 root root      69632 ene 24 18:32 tmp

 search in (directories) for the other permissions that has "t" inplace of "x" 
 $ find / type d -perm -1000 -exec ls -l {} \;
 ex:
-rw------T 1 hadoop hadoop 263 ago 19 15:25 kernel-fd535bf5d144.json

- chmod Octal mode or absolute mode: octal numbers to represente each permission group
 $ chmod octal_mode filename
 consist of three octal numbers 4,2,1 that represent a combination (sum) of the permissions from 0-7 for the file directory
 Read - 4
 Write - 2
 Execute - 1
 
 7 - rwx - 111(4+2+1) - all permissions
 6 - rw- - 110(4+2+0) - read and write permissions
 5 - r-x - 101(4+0+1) - read and execute permissions
 4 - r-- - 100(4+0+0) - only read permissions
 THERE ARE NOT USEFUL because w+x also need r
 3 - -wx - 011(0+2+1)
 2 - -w- - 010(0+2+0)
 1 - --x - 001(0+0+1)
 0 - --- - 000(0+0+0) - no permissions

 640 - rw-r-----
 644 - rw-r--r--
 666 - rw-rw-rw- -> MAX - default permissions to a file
 750 - rwxr-x---
 751 - rwxr-x--x => NOT USEFUL because w+x also need r
 755 - rwxr-xr-x -> group and others read and execute only
 775 - rwxrwxr-x -> owner and group to include write access
 777 - rwxrwxrwx -> MAX - default permissions to a directory
 
 555 - r-xr-xr-x 
 44  - ---r--r-- = 044 all missing digits are fills by 0

 set the user's mask to an user on bashrc file or initialization file
 $ umask
 0022

 default oracle linux umask = 0002 (002)
 default oracle solaris umask = 0022 (022)
 
 umask affects for files and directories when are created (4digit octal)
 
   the first digit determines the Setuid or Setgid
   the second digit determines default user/owner
   the third digit determines default group
   the fourth digit determines default others 

 Permissions umask octal value
 Value 	- File 	- Directory
 0 	- rw-   - rwx
 1 	- rw-   - rw-
 2 	- r--   - r-x
 3 	- r--   - r--
 THERE ARE NOT USEFUL because w+x also need r
 4 	- -w-   - -wx
 5 	- -w-   - -w-
 6 	- ---   - --x
 7 	- ---   - ---

 666 - rw-rw-rw- -> MAX - default permissions to a file
 777 - rwxrwxrwx -> MAX - default permissions to a directory
 
 Then umask to change the default permissions = difference between default values and values you want to set
 ex:
 if you want to change the default permissions for files to 644 - rw-r--r-- = 666 - 644 = 0022
 if you want to change the default permissions for directories to 644 - rw-r--r-- = 777 - 644 = 0133

 To set the default permissions in a user initialization file to rw-rw-rw-: $ umask 0000
 
 Applying the umask value

 Files
 Octal     
 420420420 - 666 - rw-rw-rw- -> MAX - default permissions to a file
 420400400 - 644 - rw-r--r-- 
 Diferencia -----
 000020020 - 022 - ----w--w- -> utility value to be removed -> umask

 Directories
 Octal     
 421421421 - 777 - rwxrwxrwx -> MAX - default permissions to a directory
 421401401 - 755 - rwxr-xr-x 
 Diferencia -----
 000020020 - 022 - ----w--w- -> utility value to be removed -> umask

how you can manage the processes that need to run on your operating system. So in the first part, you will learn about how a process is represented on Unix or Linux operating system, and you will learn about its attributes. And then in the second part you will learn about the commands that are available to manage the processes, to control their lifecycle, and also to learn about the statistics that are collected by the operating system about each process.

So let's quickly start with the first part. First, a few general information about the processes. The processes, which are also known as tasks, are the running form of a program-- a program that can be either an executable or a shell script.

The programs and shell scripts are stored on disk, and contain the code that need to be executed by your machine. When you will start their execution, a process will be created which is represented by a memory area where the data for this process will be stored, and a thread that is used to execute code.

Of course, the process may create additional processes by using either spawn or fork. In this way, you can define, let's say, a parent-child relationship between those processes. Always on Unix or Linux, the processes are started by another process by using either spawn or fork. Only the initial process that is used to boot the system will have no parent. All other processes will have a parent, which can communicate with it.

You can create multiple processes that can run in parallel. Also, it's important to note that when a parent process is killed, generally, the child processes need to be notified in order to react to this event. By default, the child processes will also be closed. That's why, for example, when you try to start some processes from a terminal, and then for any reason you may kill the terminal, the shell, the processes that were started by that terminal, which are child processes for the main process, will also receive a signal that, by default, will lead to their death. They will also be killed. You can sometimes start processes as child processes and then reallocate those processes to other parents in order to survive their initial parent.

The attributes that are defined for each process, the kernel, is the operating system component that needs to manage the processes. The kernel will manage also all the interactions between the processes and the different resources that are needed for that process to be executed. That's why the kernel will need a way to uniquely identify each process, or will assign a unique identification number to those processes. This identification number is called process ID, or PID.

The kernel will use this PID in order to track, control and manage the processes. For each process, there will be an owning parent process ID, which is used to define the parent-child relationship that I was talking about earlier. Each process is further associated with a user ID and then group ID. Those two IDs will indicate the process owner. Those IDs are generally based on the user ID and the group ID of the user who started the process.

If you remember, in one of the lessons from the previous days, you learned that you can use a specific permission, set UID and set GID, in order to configure a process to be started not with the UID and the GID of the user who started that process, but with the UID and GID of the owner of the process. Generally, this is useful when you need to be able to do something more that you are not allowed as a user on that system. For example, to edit some critical files that may exist in your system. A good example is to be able to change your own password.

Of course, the user ID and the GID that is associated with the process will be used to determine the security policy that will be applied to that process, and to identify the permissions that the process has. As I mentioned before, the kernel will be responsible to manage each process and to provide access to all processes to the resources that are needed to successfully execute. Also, the kernel will be responsible to provide administrators information about how the different processes are performing, and in which state a process may be.

So the kernel will use a number of states that can be reported to administrators in order to describe the current status for a process. In the current slide, you can learn about the most important state that a process may be-- uninterruptible sleep, which is generally associated with input/output operations, running or runnable, which is the, let's say, normal state for a process, interruptible sleep when the process is waiting for an event to complete, stopped, either by a job control signal or because it's being traced right now and you want to be able to troubleshoot it, and zombie processes-- processes that are terminated but are not notified to the parent. So they are not cleaned up from the statistics that are kept by the kernel.

The state of a process can be reported by the kernel by using the ps command-- process state. In the main page for this command, you can learn more about which informations are available when you run this command.

Each time you boot a system, you execute a command or start an application, the system will create one or more processes, as I tried to describe previously. Of course, a process, when it runs, will use the resources that are made available by various subsystems on your operating system, like disks, network, memory, and CPU. Of course, in order to be able to monitor a process, you need to learn about which resources a process will use and to understand why, in some situations, the process may run slowly, or even halt or crash.

So the kernel, in order to be able to provide you this kind of information, will collect performance statistics that can help you to troubleshoot such situations. You can access those informations by using the management commands that are available at the operating system level.

So in the second part of this lesson, you will learn about such commands that you can use in order to manage your processes. The most important one is the process status-- ps command-- that allows you to list, by default, the processes that are associated with your shell. Of course, by using different options-- the ps command supports a lot of options-- you will be able to customize this output and to include in the report not only the processes that are started from your shell, but also other processes that are running on your operating system.

For each process, the ps command displays the process ID, the terminal identifier, the cumulative execution time, and the command name. You can add additional information, additional statistics that will be reported by the kernel by using options. Again, for more information about the options that you have for this command, you should take a look in the main page.

Next slide shows you a sample of using the process state command, the ps command, with two options, -e -f, which allow you to list the full format of all the processes that are currently scheduled to run on this system. So this time, you will not only be able to see the processes that were started from the current terminal, but all the processes that are running on the system.

The next slide shows you the most important attributes that are listed when you use a -f option. You will be able to see the user name of the owner of the process, the unique process identification number, the parent process identification number, the processor utilization, the time the process started, the controlling terminal for the process, if the process has been started as daemon, has been started by the system during the boot up procedure-- you will see a question mark in this place-- the cumulative execution time, and the command name, the options and the arguments that were used to start that process.

In order to see the processes using a hierarchical approach by taking into account the parent-child relationship, you need to use the pstree command on Linux. In this case, the route will be either the system daemon or the process that is identified by the process ID used as parameter for this command.

In a similar way, on Solaris, you can use the process tree command, ptree, to list again the running processes, routed either by the start daemon, which is the process used to initialize your system, or by the process ID that you send as a parameter that you send as an argument for this command.

Next, we have a quiz. Again, it is a good time to pause the video and try to figure out for yourself what is the correct answer for this quiz.

So if you remember, UID and GID both are process attributes that are needed to be able to identify the security policy that will be applied for a process. Also, the PID, the process ID, is an attribute that stores the unique identifier for a process. So the single one which is not a process attributes from this list is the PS. PS is a command, process state, that you can use in order to report the state of a process, or multiple processes.

There may be times when you would like to be able to terminate an unwanted process, because that process may have some issues. It may have entered into an endless loop, or it might be hung. So you will be able to kill or stop any process that you want. In order to do something like that, you need to send a signal to that process.

So on Unix or Linux, the processes are communicating using signals. In order to send the signals, you should use the kill command. So the kill command is not used just for killing a process. The kill command is generally used when you need to send a signal to that process.

There are multiple forms of the kill command that you can use. In fact, there are multiple commands that are allowing you to send signals. pkill is another one that will use not the process ID to identify the process you want to communicate with, but the process name.

There are multiple type of signals that you can send to processes. The most important ones are SIGINT, that allows you to interrupt the process from the keyboard, SIGQUIT, that allows you to send a quit signal from the keyboard, SIGKILL, which sends the kill signal to a process. This is one of the few signals that cannot be catched by the process. Normally, the process will be able to catch the signals that are sent, in order to react in a different way for different signals.

For example, the process may receive-- in SIGTERM, for example, the termination signal, which is 15. This is, in fact, the default signal that is sent by both kill and pkill. So it may catch the SIGTERM and clean up all the resources that are used by that process in order to be able to close itself in a safe manner.

SIGKILL, as I mentioned before, is one of the few signals, alongside with SIGSTOP, that cannot be caught, blocked or ignored. Those signals are catched by the kernel and will do, let's say, an unsafe destruction, an unsafe termination of that process. That's why generally SIGKILL should not be used lightly. So SIGKILL should be used only as a last resort, if all other options, all other signals, didn't work.

Generally, it is recommended to try first with SIGQUIT, signal 3, then SIGTERM, signal 15, and if those two are not working, then you can try SIGKILL, which is the signal with the value 9. Of course, you can find full details about the signals that are supported by both Linux and Solaris by using the documentation from the manual.

So next, you can see some samples of commands that you can use to communicate with processes. You can terminate any process by sending the appropriate signal to the process. The kill command will sent by default a termination signal, signal 15, to one or more processes that are identified by the process ID. As I mentioned before, the SIGTERM can be catched by the process in order to do a safe exiting of that process.

There are other signals that can be used. For example, SIGHUP, which is sent to all of the subordinate child processes when the parent process is terminated, to notify them about this situation. And normally SIGHUP, as I mentioned before, will lead to a close of all the child processes. But SIGHUP can be caught by processes, so each process may decide what to do when such signal is received.

To terminate, a command line command, you usually use the Control C keyboard command, which sends a SIGINT signal 2, causing that program to be interrupted. Also, in place of the exit command, used to exit a terminal session, you can use the Control D keyboard command, which sends a SIGQUIT, which is signal 3, to quit that specific terminal session. Also, to stop the command line command execution, you can use Control plus Z keyboard command. That allows you to send a stop SIGSTOP signal, which is the 19 signal, in order to stop or suspend the execution of that process.

And then you will be able to decide what to do with that process, to continue its execution in the foreground or in the background, because you have at the terminal level, the possibility to control the execution of multiple processes using foreground or background execution.

Next, you can see a sample of how you can terminate a process. I use, first, ps to learn about the process ID. And then I use kill in order to send the SIGTERM signal to one of the processes. Then I check again that that process is not displayed any more.

Instead of using the process ID, you can use the process name to identify a process, or a regular pattern   - ("patron") -  to identify a process. To do so, you need to use the pkill command. It's important to know that the pkill command will kill all the processes that match the pattern    - ("patron") - (patron) that you specify. So you should use pkill carefully.

As you can see in this example, I start a process. I display the process ID and the process name, and I use the process name in order to kill that process with pkill.

Here you can see another example of terminating a process using pkill based on the name.

As I mentioned before, the recommended way to terminate processes is to try first to use the termination signal, 15. If the process does not respond to this termination signal because, as I mentioned before, this signal can be caught by your process, you can force the termination of the process by sending the SIGKILL command. In order to send the SIGKILL signal, you should identify the idea of the signal. Kill -9 specified that I wanted to send the signal 9, which is SIGKILL, instead of signal 15, which is sent by default.

Sending the signal 15 does not necessary kill a process gracefully, but gives the process the chance to terminate gracefully. So of course, only if the signal is caught by the process, in order to clean up the resources in an orderly fashion, this mechanism will work. If not, that process will just die. But anyway, using the signal 15 at least gives the chance to the process to clean up safely. If you use directly SIGKILL, the process will not have any chance to terminate safely. So even if the process has the code that allows a clean exit, that code will not be executed if you send directly SIGKILL.

The second quiz for this lesson asks you if ordinary users can only kill processes they own. Again, you can pause the video and try to figure it out the answer for yourself.

Yes. The answer is true. The ordinary users can only kill processes they own. Only the root user is able to kill any process on the system.

In the practice, you will try to use the commands that we discussed about in this lecture in order to learn how you can control the processes that are running on your system. 

A Process = A Task = PID (Process ID) 
Each Process ID to control has a PPID (Parent Process ID)
Is asociated with a UID and GID normally are the same as the user who started the process 
A process consist of an address space and a metadata object.
The process space pertains to all the memory and swap space a process consumes.
The process metadata is just an entry in the kernel's process table and stores all other information about a process

Process States: (ps command) s, stat and state output describe the state of a process
 D: Uninterruptible sleep (usually IO)
 R: Running or runnable (on run queue)
 S: Interruptible sleep (waiting for an event to complete)
 T: Stopped, either by a job control signal or because it is being traced
 Z: Defunct ("zombie") process, terminated but not reaped by its parent
 when the stat keyword is used
 <: High-priority(not nice to other users)
 N: Low-priority(nice to other users)
 L: Has pages locked into memory(for real time and customIO)
 s: Is a session leader
 l: ls multi-threaded
 +: ls in the foreground process group

 nice is a useful program that is used to decrease or increase the scheduling priority of a process or batch processes. Users can assign nice values between -20 (most favorable), 0(no effect) and 19(least favorable). The higher the nice value, the lower the scheduling priority

       To see every process on the system using standard syntax:
          ps -e   - Prints info about every process currently running
          ps -ef  - Generates a full listing
          ps -eF
          ps -ely - Long listing

       To print a process tree:
          ps -ejH
          ps axjf

          ps -eo format: Writes information according to the format specification given. Multiple -o options can be specified. 
The format specification is interpreted as the space-character-separated concatenation of all the format option arguments.

A process, as it runs, uses the resources of the various subsystems 
         ------------------------
         | Unix or Linux Kernel |
         ------------------------

Disk I/O    Network     Memory      CPU
Subsystem   Subsystem   Subsystem   Subsystem

Control     Controls    Controls    Controls 
disk        the through the utili-  CPU
utiliza-    put and     zation and  resources
tion and    directional allocation  loading
resour-     flow of     of physical and sche-
cing as     data        virtual and duling
well as     between     shared me-
file        systems     mory
system      over a 
perfor-     network
mance       connection

         <-- Process Subsystem -->

process status (ps) list the processes that are associated with your shell 
$ ps -ef | less
$ ps -ef

for each process show: PID, TTY, TIME, CMD .etc..

UID: The username of the owner of the process
PID: The unique process identification number of the process 
PPID: The parent process identification number of the process  
C: Processor Utilization    
SZ   
RSS 
PSR 
STIME: The time the process started (hh:mm:ss) 
TTY: The controlling terminal for the process.
     (?) - started without the use of a terminal.
TIME: The cumulative execution time for the process (hh:mm:ss) 
CMD: The command name, options, and arguments

$ pstree command list the running processes, rooted at either system or PID
$ ps -f
UID        PID  PPID  C STIME TTY          TIME CMD
hadoop   26838 25200  0 20:18 pts/1    00:00:00 bash
hadoop   27841 26838  0 21:12 pts/1    00:00:00 ps -f

$ pstree 25200
gnome-terminal-─┬─bash───vi
                ├─bash───pstree
                └─3*[{gnome-terminal-}]

Terminating a Process kill or stop any process that you own
send signals to processes directing them to terminate.
each signal has a number/value, name, and an associated event.
(Linux) man 7 signal
(Solaris) man -s3c signal

kill PID
pkill -l

       Signal     Value     Action   Comment
       ───────────────────────────────────────────────────────────────────
───
       SIGHUP        1       Term    Hangup detected on controlling termin kill all subordinate child processes
al
                                     or death of controlling process
       SIGINT        2       Term    Interrupt from keyboard = Ctrl+C
       SIGQUIT       3       Core    Quit from keyboard = Ctrl+D
       SIGTERM      15       Term    Termination signal in an orderly manner (default)
       SIGILL        4       Core    Illegal Instruction
       SIGABRT       6       Core    Abort signal from abort(3)
       SIGFPE        8       Core    Floating-point exception
       SIGSEGV      11       Core    Invalid memory reference
       SIGPIPE      13       Term    Broken pipe: write to pipe with no
                                     readers; see pipe(7)
       SIGALRM      14       Term    Timer signal from alarm(2)
       SIGKILL       9       Term    Kill signal - last resort
       SIGTSTP   18,20,24    Stop    Stop typed at terminal suspend the foreground execution Ctrl+Z command-line command execution

All command-line commands execute in the foreground unless they are submitted followed by an &(ampersand). 
To Stop Ctrl+Z (SIGTSTP signal 19) to stop the foreground processing.
Then use a bg %n command to resume the command in the foreground processing

There are processes that should not be terminated, such as the scv.startd, init or systemd processes.

root user can use kill command on any process

ps or pgrep locate the PID of the process

pgrep and pkill 

To execute a process in the background: use "&": 
$ sleep 500 &
$ pgrep sleep
$ pgrep -l sleep
$ pkill sleep -> requires you to specify the ProcessName or a regex_PATTERN  - ("patron") - 

$ ps -e | wc -l

$ gnome-calculator
$ pkill gnome-calculator

(Linux)
$ bc <<<"236-192"
44
$ bc <<<"1+1"
2

If you’d rather have that as a function:
$ c() { printf "%s\n" "$*" | bc }
$ c 1+1
2
 
$ tty
/dev/pts/1

(Linux)
$ pgrep -t pts/1
26838
$ kill 26838
$ kill -9 26838
$ kill -l -> list all options about kill 
$ kill -l 9 -> list details options 9

(Solaris)
$ pgrep -t pts/1
26838
$ pkill 26838
$ pkill -9 -t pts/1
$ pkill -9 26838
$ kill -l -> list all options about kill 
$ kill -l 9 -> list details options 9

$ sleep 500&
[1] 1422
$ ps
  PID TTY          TIME CMD
 1103 pts/1    00:00:00 bash
 1422 pts/1    00:00:00 sleep
 1423 pts/1    00:00:00 ps
$ pgrep -t pts/1
1103
1422
$ kill 1422
[1]+  Terminated              sleep 500

$ sleep 500&
[2] 1431
$ ps
  PID TTY          TIME CMD
 1103 pts/1    00:00:00 bash
 1428 pts/1    00:00:00 sleep
 1431 pts/1    00:00:00 sleep
 1436 pts/1    00:00:00 ps
$ pstree -p 1103
bash(1103)─┬─pstree(1441)
           ├─sleep(1428)
           └─sleep(1431)
$ kill 1428
[1]-  Terminated              sleep 500
$ pstree -p 1103
bash(1103)─┬─pstree(1445)
           └─sleep(1431)

In the next module, you will learn about some advanced features that are provided by Bourne again shell. First, you will learn how you can manage processes that are started from your shell in order to be able to execute multiple processes in the same time. Then you will learn about how you can create shell functions in order to be able to quickly execute some logic that may be needed repeatedly.

And the last and very interesting topic, you will learn the basics about creating shell scripts. Shell scripts are very useful when you need to automate different activities, different tasks. And that's why this topic has been included in this training session. Of course, we will not have enough time during this session to explore all the possibilities that are provided by shell scripts. There are dedicated training sessions on Oracle University curriculum for that. But you will get a, let's say, first introduction to shell scripts and you'll learn about the core constructs that you can use to create such scripts.

So let's quickly start with the first part of this lesson. Let's see how you can manage jobs in Bourne again shell a job in Bourne again shell, it's used to indicate a process that is managed by the current shell. Generally, the processes that are managed by the current shell are processes that are started from this shell. Each job that is started in the current shell will be assigned a sequential job ID, and you will be able to manage how that job will be executed based on this ID.

In the same shell, you will be able to have multiple processes running in the same time, but only one of them will have the ownership on the terminal, will be able to read data and to generate the data in the terminal. This job, it's called the foreground job.

All the other jobs will run in background. So the jobs that are running in parallel with the foreground job are named background jobs and are not able to generate right now output or receive output from the terminal. You can also have interrupted or stopped jobs that are not active, that are not executing, waiting for you to decide if that job will need to be executed in foreground or in background.

Most of the shell supports job control, to be able to move jobs from foreground to background, to stop, to resume jobs, and so on, except the Bourne shell. The Bourne again shell, the bash shell, supports this kind of management. In fact, working with the jobs that are managed by your terminal requires for the terminal to send different signals to those jobs. So SIGSTOP, for example, will be used when you need to stop a job in order to move it from foreground and background, and so on.

First of all, let's learn about the job control commands that you can use in order to manage the jobs from the current terminal. You can use Control-Z in order to send the SIGSTOP signal to a foreground job in order to stop it and to be able to resume it at background job if needed.

The jobs command allows you to list all the current jobs and their IDs. Then you can use the background and foreground commands in order to move a job into background, to start it in background, or to start it as foreground process. Those two commands does not require for you to indicate the process ID as argument, but the process number. The process number is the one that is displayed by the jobs command.

The kill command, with the process number indicated, allows you to delete a job that is running from the background. The kill -19 will send explicitly the SIGSTOP command. It's similar with using Control plus Z. In this way, you will be able to stop that job in order to decide what to do with it next, to execute it either in background or in foreground.

If you want to start a job initially in background, you can just enter the command that you use normally to start the process in foreground. Normally, when you start a process in a terminal, the process will be run in foreground. In order to move it in background, you need to stop it and then start it with bg in background.

If you want to start it from the beginning in background; you just need to append an ampersand at the end of the command line, as you can see here. This is the normal command that allows you to start this process, sleep 500. This process will normally start in foreground. If you would like this process to start in background, just add the ampersand at the end of this command. The shell will return the job ID in brackets and you will be able to use this job ID in order to manage this process.

Next, you can see how you can use jobs command in order to list the jobs that are currently running or are stopped. And then you can use the foreground command to bring the background job to the foreground. Similarly, you can stop a foreground process and move it into the background with the bg command.

Next, we have the first quiz for this lesson. It will be good to pause the video and try to figure out for yourself what is the correct answer for this one. So the correct answer here is false. You need to append an ampersand symbol at the end of the command line in order to run the job in the background, not a pipe. The pipe is used to connect multiple commands together to use the output of one command as input for another command.

An alias is a shorthand shell notation that allows you to abbreviate commands. So instead of executing a very long command, you can just use a shorter name for it. In order to define an alias, you just need to use the alias command, specify the alias name followed by the command string. The shell will maintain a list of aliases that will be searched when you execute a specific command.

When you define an alias, you need to comply with a number of rules. There can be no white space on either side of the equal sign. The command string must be quoted if it includes any options, metacharacters, or white space. And each command in a single alias must be separated by a semicolon.

You can group several commands under a single alias. As you can see here, the individual commands need to be separated by semicolons and you should quote the command. Here, I execute three commands using the same alias.

On Linux, the Bourne again shell, it's already preconfigured with a number of aliases. You can display all the existing aliases by using the alias command. alias command without any parameter will display the existing aliases.

You can define your own aliases. Here is an example on how you can define an alias as for the history command, h, for example.

You can temporarily deactivate an alias by placing a backslash-- which is the escape metacharacter-- in front of the alias on the command line. So let's assume that here we have an alias, rm for rm -i, to always be asked before deleting a file. So if I would like to deactivate temporary this alias, I need to use backslash followed by rm.

And, as you can see, I am not asked any more. So the standard rm command will be executed, remove command will be executed. So the alias will be not taken into consideration in this case. The file will be deleted without any confirmation. If you want to attempt to delete an alias permanently, you should use that unalias command.

Oh, next quiz. Which of the following rules does not apply while creating an alias? Again, I recommend you to pause the video and try to figure out for yourself what is the correct answer. The correct answer here is b, a backslash is placed in front of the alias only if I want to temporary deactivate that alias. It doesn't have any influence on how the alias is created.

Next section is about shell functions. Functions are a very powerful feature of the shell programming. Allows you to define a group of commands that can be executed quickly. You can define hundreds of shell functions to simplify the execution. They are easy-to-manage units that can be called with parameters and can return values.

Using a function, of course, involves two steps. First, you need to define the function, and then you should use the function, invoke the function. In order to define a function, you need to use the following syntax-- function followed by the name of the function, optionally followed by parameters, and then the body of the function. Here, you can see how I can define a function called num that will display the total number of users currently logged into the system.

In order to remove a function, you just need to use the unset -f command, indicating the name of the function. In order to invoke the function, just enter the function name on the command line.

The shell also supports options. Options are switches that will control the behavior of the shell. There are about 27 different options. Options are Boolean values, which means that they can be either on or off. To show the current option settings, you just need to use set -o. To turn on an option, enter set -o followed by the option name. To turn off an option, enter set +o followed by the option name.

One of the options that you can use is noclobber. Of course, all the other options are described in the documentation for your shell. The noclobber option allows you to avoid overwriting the content of an existing file when you redirect the standard output. This process of overwriting existing data is known as clobbering. To prevent this overwrite to occur, the shell supports this noclobber option. So when the noclobber option is set, the shell will refuse to redirect the standard output to the existing file and will display an error message on the screen.

So let's see how you can deactivate the noclobber option using set +o. In order to activate it, you need to your set -o and the name of the option. You can also temporary deactivate the noclobber option by using the greater than and pipe metacharacters together without any space between them to temporary deactivate this function, this option.

Next quiz. Which of the following syntaxes can be used to turn off an option? Again, I recommend you to pause the video and try to figure out for yourself the answer to this question. So the correct answer here is a, set +o option-name.

The second part of this lesson shows you the most important concepts about writing shell scripts. A shell script is just a text file that you can define in order to reuse a sequence of commands very quickly. The shell scripts are created in order to automate complex tasks. They are very useful because they can be easily scheduled to be executed even if no one is attending that machine.

Also, shell scripts can be used when the system is started in order to also start the required applications on that system. There are many shell script languages that you can use, like Perl, PHP, Tcl. We will focus in this lesson on the default shell scripting that is supported by Bourne again shell.

This language is based on Perl, but it's somehow simplified for users with little or no programming experience to be able to create and run shell scripts. After you create the shell script as a text file-- according of course to the mandatory requirements-- and after you configure that shell script file to be executable, you will be able to just run the shell script by simply entering the name of the shell script in the command line, like any other executable.

So, as I mentioned before, both Solaris and Linux supports different shell script languages in order to define such automating objects. That's why it's important to indicate in your shell script file which interpreter should be used to execute the commands in the script.

So the first line of the shell script, which is called shebang and needs to start with a specific combination of symbols. This is followed by exclamation mark, followed immediately by the absolute path name of the shell program will indicate which program should be used to interpret this script. So here is an example of such a first line that you can use in a file in order to indicate that the script should be interpreted by bash, Bourne again shell.

To create a shell script, you will need a text editor. That's why vim, it's very important. Of course, you can use any other text editor you like, like emacs or, I don't know, gedit. So, using the text editor, you will just need to enter first the shebang line, which indicates the interpreter for the script. And then you can enter, I don't know, comments, like in this example. The second line here is a comment. And the set of commands that will be part of this shell script. This is a very simple shell script that will just display hello world in the output.

After you've created the shell script, you can run it. To run the shell script, first of all you need to configure the file to be executable. So you need to grant read and execute permissions to the user in order to be able to execute that shell script. To do that, you can use change mode and add the read and execute permissions for that shell script. After that, you can just execute shell script by using the shell script's file name on the command line.

A comment is just a text or a description that is included in the script in order to explain the commands that are part of the script. I strongly recommend you to always use comments, because most of the shell scripts will not be used only by you but also probably by your team members. So any additional information may be very useful.

You should also take into account that sometimes it wouldn't be very easy for you to remember what you wanted to implement in that shell script if you created that shell script, I don't know, a couple of months ago. That's why any kind of descriptive information that is included in the shell script can be very helpful in such situations.

So you can define comments by using the hash symbol in the script file. When such a symbol is encountered in the file, the line following it is ignored by the shell.

You can pass command line arguments to a shell script when you run that shell script. The arguments that will be passed will be stored by the shell in an array. And in the shell script, you will be able to refer those arguments by using a special set of variables. Those variables are called positional parameters and allows you to access the arguments, starting with $1, $2, until $9. Also, it's important to note that you have a special variable available-- it's $#-- that will store the number of the arguments that were passed when the script has been executed.

Next, we have another quiz. Again, it will be good to pause the video and try to figure out for yourself the correct answer for this one. So the correct answer here is true. In order to run a shell script, indeed the user must have write permissions.

Each command that you execute on Unix or Linux will return a numeric value that will indicate how that command finished its execution. A value of zero will indicate success. A non-zero value will indicate failure. A non-zero value can be an integer in the range of 1 to 255. 255, yes.

This value is called exit status. You will be able to access the exit status for any command you execute in Unix or Linux by taking advantage of the read-only shell variable, question mark. So when you display the question mark variable, you will be able to see this exit value. A developer can use this exit status in order to check if a previous command has been executed successfully or not.

Inside the shell script, you will be able to control the exit status by using the exit command with a value. So when you use exit equal a specific number, you will control, in fact, the exit value, exit status, for that shell script.

In a shell script, you will be able to take advantage of the test command. The test command allows you to test conditions. And here is the special notation that you should use when you create such a test command. The test command allows you to evaluate expressions-- like variables, file access permissions, file types-- using comparison operators, like integer test comparison, string test comparison, file test comparison, and so on.

In the following few tables, you can learn about the operators that are supported. For integers, equal to, not equal to, less than or equal to, greater than or equal to, less than, greater to. So normal test comparison operators. Next, you can see the operators that are available for string testing. Next, the operators that can be used to test files.

Generally, the test commands are used together with if, while, until, this kind of command. So conditional execution commands and repetitive execution commands. So, in most cases, the test command will be used to test a condition for an if statement. The if statement allows me to evaluate a condition, and if the result will be true, I will execute a specific set of commands. Otherwise, I will execute another set of commands. If can use not only test conditions but can also validate the result of a command. So you can test a command and check if the result is zero or not.

When you create a shell script, you will be able to use some options that are available at the Bourne again shell level, which allows you to configure how your script will be interpreted. So you can use -x to debug that script, -v to activate the verbose and to generate in this way more information, and -n to check the syntax. Those options can be activated either when you run your script using bash followed by the options, or directly in the shebang line of your script, on the first line of your script, by indicating the options as parameters for the bash.

The shell also provides you some special expressions that allows you to run a command based on the success or failure of the preceding command. Those are and operator, or operator, if statement, and case statement.

So here is again seeing how you can use the and operator to ensure that the second command is run only if the preceding command succeeds. And or operator that ensures that the second command is run only if the preceding command fails.

The if statement, as I mentioned before, can be used to evaluate either the exit status of a command and initiate additional actions based on the return value, or to evaluate a test command. If supports elif construct if you need to test multiple commands.

The case statement allows you to compare a single value against other values and run a command or a group of commands when a match is found. The values will be compared in order. And you can use and catch-all section This is the catch-all section.

You can also take advantage of looping constructs, like for, while, and until. Here is the for, that allows you to repeat a command or a group of commands in this loop. So the for command will evaluate the exit status of the operation that follow it. If the exit status is zero, any instruction that follows the do are run. The command or the test is rerun and the exit start rechecked. If the exit status is non-zero, the loop terminates.

As I mentioned before, in Bourne again shell you will be able to pass command line arguments using positional parameters, using $0, $9. Bash only supports a single number after dollar. So any attempt to access a value in the 10th argument using the notation $10 will result in the value of $1 followed by a 0. Probably it's not what I want.

It's important to note that Korn shell and bash can access the 10th parameter directly with the value dollar and, inside braces, 10. But this could be very cumbersome to be used. That's why it is recommended to use the shift command, that allows you to move your parameters back by one position. So in this way the second parameter becomes first, and so on. In this way, you will be able to access any number of positional parameters using only the first nine numbers.

Next, you can see how you can take advantage of while command in order to repeat a command or a group of commands, again in a loop. The while command will evaluate the exit status of the command or the test command, and if the exit is zero, the instructions that follow the do are run. The command or the test is rerun and the exit status is rechecked. If the exit status is non-zero, the loop will terminate.

In a similar way, the until command can be used. Again, it will check the exit status of the command or the test. If the exit status is not zero, the instructions that follow the do are run. The command or test is rerun and the exit status rechecked. If the exit status is zero, the loop terminates.

Next, we have another quiz. Which of the following evaluates the exit status of a command and initiates additional actions based on the return value? Again, you can pause the video and try to figure out for yourself the correct answer. So the correct answer here is if and while. Both those statements are evaluating the exit status of a command and will initiate additional actions based on the return value.

Those are the most important features that are available in the shell and the basic information that you need to start writing shell scripts. Of course, you can learn more by trying the practices. And I recommend you-- after, I don't know, some weeks-- to try to follow up this course with some dedicated training courses that can help you to learn more about shell script programming. This concludes the lecture of these eight lesson.

There are three types of job statuses:

- Foreground: When you enter a command terminal window, the command occupies that terminal window until it completes.
- Background: When you enter (&) at the end of a command line, the commands run whitout occupying the terminal window. The shell is displayed inmmediately after you press Return
- Stopped: Ctrl+Z while a foreground job is running or enter the stop command.

Job control commands place jobs in the foreground or background and to start or stop jobs

Option      Description

Ctrl+Z      Stops the foreground job and places it in the background as a stopped job
jobs        Lists all jobs and their job IDs
bg [%n]     Places the current stopped job or the specified job ID in the background, where n is the job ID
fg [%n]     Brings the current or specified job ID from the background to the foreground, where n is the job ID
kill %n     Deletes the job from the background, where n is the job ID
kill -19 %n Or, if signal 19(SIGSTOP - Ctrl+Z) is used, places the process associated with the job ID (n) in a stopped state

The job control commands run a manage multiple jobs in a shell.
However you can use the job control commands only in the shell where the job was started.

There are two signals 19s, 
Stop process (SIGSTOP signal 19) that is usually associated with "kill -19 PID" and 
Stop typed at terminal (SIGTSTP signal 19) which is Ctrl+Z sent from the keyboard, both stop the process without killin it.
Then using the two bash shell built-ins, bg(background) and fg(foreground) they send a signal Continue if stopped (SIGCONT signal 18) to continue processing either in the background or in the foreground.

When a background job is complete and you press Return, the shell displays a messages:
[1]+  Done sleep 600


To run a job in the background = command + &
$ sleep 600&
[1] 1791

List all jobs
$ jobs
[1]+  Running                 sleep 600 &

Process States
$ ps
  PID TTY          TIME CMD
 1103 pts/1    00:00:00 bash
 1791 pts/1    00:00:00 sleep
 1793 pts/1    00:00:00 ps

Brings the current job ID from the background to the foreground
$ fg %1
sleep 600

$ sleep 600&
[1] 5597

$ jobs
[1]+  Running                 sleep 600 &
$ ^C
$ 

$ jobs
[1]+  Running                 sleep 600 &
$ bg %1
bash: bg: job 1 already in background

$ fg %1
sleep 600
^Z
[1]+  Stopped                 sleep 600

to terminate a job use kill 

$ jobs
[1]+  Stopped                 sleep 600

$ sleep 500&
[1] 2241

$ jobs
[1]+  Running                 sleep 500 &

$ kill %1

$ jobs
[1]+  Terminated              sleep 500


Alias to customize and abbreviate commands, no whitespaces on either side of the equal sign, command must be quoted, each command in a single alias must be separated by ;
alias aliasname="command string"
alias l='ls -CF'

group several commands under a single aliasname
alias info="uname -a; id; date"

$ info
Linux sc-HP-Compaq-2710p 5.4.0-65-generic #73~18.04.1-Ubuntu SMP Tue Jan 19 09:06:49 UTC 2021 i686 i686 i686 GNU/Linux
uid=1000(sc) gid=1000(sc) groups=1000(sc),4(adm),24(cdrom),27(sudo),30(dip),46(plugdev),116(lpadmin),122(sambashare)
mar ene 26 01:25:29 CET 2021

Display both system and user defined aliases (Linux) provide several system-defined aliases Soraris No.

$ alias
alias alert='notify-send --urgency=low -i "$([ $? = 0 ] && echo terminal || echo error)" "$(history|tail -n1|sed -e '\''s/^\s*[0-9]\+\s*//;s/[;&|]\s*alert$//'\'')"'
alias apps='cd /opt/'
alias cp='cp -i'
alias egrep='egrep --color=auto'
alias fgrep='fgrep --color=auto'
alias grep='grep --color=auto'
alias h='history'
alias info='uname -a; id; date'
alias l='ls -CF'
alias la='ls -A'
alias ll='ls -alF'
alias ls='ls --color=auto'
alias mv='mv -i'
alias cls='clear'
alias priv='cd /home/sc'
alias rm='rm -i'

# <<< ALIAS SCELIs <<<
set -o vi
alias apps='cd /opt/'
alias priv='cd /home/sc'
alias info="uname -a; id; date"
alias h=history
alias rm='rm -i'
alias cp='cp -i'
alias mv='mv -i'
alias cls='clear'
alias ls='pwd; ls -ltsha'
alias lf='pwd; ls -lF'
# <<< ALIAS SCELIs <<<


<<-O-J-O>> revisar
###################### $ alias which='alias | /usr/bin/which --tty-only --read-alias --show-dot --show-tilde'
<<-O-J-O>> revisar

Remove an Alias
alias which='alias | /usr/bin/which --tty-only --read-alias --show-dot --show-tilde'
$ unalias which

Deactivating temporarily an Alias -> Utilizar el \ antes del nombre del alias -> \rm
ex: 
$ rm Unix\ and\ Linux\ Essentials.txt 
rm: remove regular file 'Unix and Linux Essentials.txt'? no
$ ls -l
total 236
-rw-r--r-- 1 hadoop hadoop 238810 ene 26 17:01 'Unix and Linux Essentials.txt'
$ \rm Unix\ and\ Linux\ Essentials.txt 
$ ls -l
total 0

alias cls='clear'
$ cls

Shell Functions: Group of commands organized by common functionality
return a single value with no additional output
- Defining the function: 
	function fuctionname [()] {compound-command [redirections];}
        ex:
        total number of users current logged in to the system:
        function num { who | wc -l ;}
- Invoking the function
	fuctionname [()]

To display a list of all functions, use the following command: $ typeset -f

- Los alias no toman argumentos como las funciones
- Si un nombre de comando se define como función y alias, el alias tiene prioridad

To display the name of all functions. use the following command: $ typeset -F

To delete/remove a function use the following command: $ unset -f

$ function num { who | wc -l ;}
$ num
1
$ unset -f num
$ num
Command 'num' not found

$ function list { ls -al | wc -l ;}
$ list
109

$ unset -f info2
$ typeset -f info2
$ function info2 { pwd; whoami; who | wc -l; }
$ typeset -f info2
info2 () 
{ 
    pwd;
    whoami;
    wc -l;
}
$ info2

Shell Options In the bash shell there are about 27 options (on or off)
To show the current options settings: $ set -o ór $ set -o | more

$ set -o | grep noclobber
noclobber      	off

To turn on an option: $ set -o optionname 
$ set -o noclobber
$ set -o | grep noclobber
noclobber      	on

To turn off an option: $ set +o optionname 
$ set +o noclobber
$ set -o | grep noclobber
noclobber      	off

Can change only a single option setting at a time

Activating the noclobber Shell Option
Clobbering is the process of overwriting existing data to prevent the shell supports a noclobber option
When the noclobber option is set, the shell refuses to redirect standard output to the existing file and display an error message on the screen

$ ps -ef > filenew
$ cat /etc/passwd > filenew

To ensure that the noclobber option is available to every shell invoked place set -o noclobber in .bashrc file

Deactivate the noclobber option temporarily (>|) is ignored for this command line Only: $ ls -l >| filenew

ls -l > filenew

$ set -o 
allexport      	off
braceexpand    	on
emacs          	on
....

$ set -o | grep noclobber
noclobber      	off
$ set -o noclobber 
$ set -o | grep noclobber
noclobber      	on
$ ls -l > filenew
bash: filenew: cannot overwrite existing file
$ ls -l >| filenew

Shell bash Script can be executed on the command line if it is made executable with the "chmod u+rx script-name" permission.
Then if the script is not found in "echo $PATH", you will need to preface script with "./scriptname. 
The "./" says look in the current working directory.
Nonexecutable scripts can be executed by using the appropriate-script-interpreter script-name, for example, bash script-name.

Determining the shell 

The first line of a shell script identifies the shell program that interprets and executes the commands in the script
The first line should always begin with the symbols (#! - shebang) folowed immediately by the absolute pathname of the shell program used to interpret the script

#!/full-pathname-of-shell

#!/usr/bin/bash

Shell scripts are rarely compiled into binary form

#!/usr/bin/bash
# This is my first shell script
echo "Hello World!"

Can be directly keyed into the command-line interface:
$ #!/usr/bin/bash << EOF
> # This is my first shell script
> echo "Hello World!"
> EOF
Hello World!
$

EOF - here document - ending/closing - encapsulate the code of the script
You can use any delimiting string you want like "ThisIsTheEnd" although the delimiting string "EOF" is fairly common

Executing a Shell Script the user must have write permissions: chmod u+rx myScript
u User
+ Add permissions
r Read
w Write
./myScript

$ cat myScript 
echo running myScript
FMHOME=/usr/frame
MYBIN=/export/home/oracle/bin
echo $FMHOME

$ ls -l myScript 
-rw-rw-r-- 1 sc sc 83 ene 27 01:25 myScript

$ ./myScript
bash: ./myScript: Permission denied
$ chmod u+rx myScript 

$ ./myScript
running myScript
/usr/frame

$ vi info.sh
#!/bin/sh
#info.sh
# This script displays the date, time, username and the current directory.
echo "Date and time: " 
date
echo
echo "Your user name is: `whoami`"
echo "Your current directory is: `pwd`"
$ chmod +x info.sh
$ ./info.sh

$ vi greetings.sh
#!/bin/sh
#greetings.sh
echo $1 $2 # echo the first two parameters passed
$ chmod +x greetings.sh 
$ ls greetings.sh
$ ./greetings.sh Hello World
Hello World

FMHOME is not defined in the parent shell
$ echo $FMHOME
$ grep $FMHOME
Usage: grep [OPTION]... PATTERN [FILE]...
Try 'grep --help' for more information.

The arguments that will be passed will be stored by the shell in an array are variables called Positional Parameters 
After the script name into variable $1, $2, ... $9 $#-- this store the number of the arguments that were passed

Exit status is a numeric value 
zero = sucess
nonzero = failure

? is a variable read-only that contain the exit status: 
$ echo $?
2

this exit status can be set in a shell script:
exit=##


$ grep hadoop /etc/group
sudo:x:27:hadoop
hadoop:x:1001:
$ echo $?
0

$ grep hadoops /etc/group
$ echo $?
1

$ ls -l myScript 
-rwxr--r-- 1 hadoop hadoop 95 ene 27 14:21 myScript
$ echo $?
0

$ ls -l some_bad_filename
ls: cannot access 'some_bad_filename': No such file or directory
$ echo $?

The test command

Used for testing conditions, can be written as a test expression or written using [expression] notation
Using for evaluating expresions like variables values, file access permissions, file types.

There are several types or categories of bash shell test comparation operators:
- Integer/Arithmetic test comparison operators
- String test comparison operators
- File test comparison operators
- And there are other test comparison operators 

$ echo $LOGNAME
hadoop

$ test "$LOGNAME" = "oracle"
$ echo $?
1

$ test "$LOGNAME" = "hadoop"
$ echo $?
0
 
$ ["$LOGNAME" = "hadoop"]
[hadoop: command not found

$ [ "$LOGNAME" = "hadoop" ]
$ echo $?
0
$ 

- Integer/Arithmetic test comparison operators

 Operator 		Meaning			Syntax

	-eq 	Equal to			[ "$var1" -eq "$var2" ]
	-nq 	Not equal to 			[ "$var1" -nq "$var2" ]
	-le 	Less than or equal to		[ "$var1" -le "$var2" ]
	-ge 	Greather than or equal to	[ "$var1" -ge "$var2" ]
	-lt 	Less than 			[ "$var1" -lt "$var2" ]
	-gt 	Greather than 			[ "$var1" -gt "$var2" ]


$ int1=1; int2=2

$ echo "int1 = '$int1' and int2 = '$int2' "
int1 = '1' and int2 = '2' 

$ echo $int1, $int2
1, 2

$ [ $int1 -eq $int2 ]
$ echo $?
1

$ [ $int1 -ne $int2 ]
$ echo $?
0

$ [ $int1 -le $int2 ]
$ echo $?
0

$ [ $int1 -ge $int2 ]
$ echo $?
1

$ [ $int1 -lt $int2 ]
$ echo $?
0

$ [ $int1 -gt $int2 ]
$ echo $?
1

$ [ $int1 -eq "1" ]
$ echo $?
0

$ [ $int2 -eq "2" ]
$ echo $?
0

$ [ $int1 -eq 1 ]
$ echo $?
0

$ [ $int2 -eq 2 ]
$ echo $?
0

- Integer/Arithmetic test comparison operators

 Operator 		Meaning			Syntax

	= ór ==	Equal to			[ "$strA" == "$strB" ]
	!= 	Not equal to 			[ "$strA" != "$strB" ]
	-z 	String is null, zero length	[ "$strA" -z "$strB" ] ???
	-n 	String is not null       	[ "$strA" -n "$strB" ] ???
	< 	Sorts before			[ "$strA" < "$strB" ]
	> 	Sorts after			[ "$strA" > "$strB" ] ???

$ strA=abc
$ strB=def

$ echo "strA = $strA and strB = $strB"
strA = abc and strB = def

$ [ $strA == "abc" ]
$ echo $?
0

$ [ $strB == "def" ]
$ echo $?
0

$ [ $strA == $strB ]
$ echo $?
1

$ test "$strA" == "$strB"
$ echo $?
1

$ [ $strA != $strB ]
$ echo $?
0

$ [ "$strA" > "$strB" ]
$ echo $?
0

$ test "$strA" < "$strB"
$ echo $?
0

File test Comparison Operators

 Operator 		Meaning			Syntax

 -e or -a filename 	File exists			[ -e filename ]
 -f filename		File is a regular file  	[ -f filename ]
 -d filename		File is a directory		[ -d filename ]
 -c filename		File is a character device 	[ -c filename ]
 -b filename		File is a block device 		[ -b filename ]
 -h or -L filename	File is a symbolic link		[ -b filename ]
 -r filename		File is a readable 		[ -r filename ]
 -w filename		File is a writeable 		[ -w filename ]
 -x filename		File is a executable 		[ -x filename ]
 -s filename		File size is bigger than zero 	[ -s filename ]
			bytes (not empty)

$ [ -e myScript ]
$ echo $?
1

$ cd IFCD17\ FUNDAMENTOS\ Y\ ADMINISTRACIÓN\ DE\ ORACLE\ DATABASE_A.V._18_801/Oracle\ University\ Learning/
$ [ -e myScript ] 
$ echo $?
0 : --> # si existe

$ touch example
$ ls -l ex*
-rw-r--r-- 1 hadoop hadoop 0 ene 27 18:18 example
$ [ -f example ]
$ echo $?
0 : --> # is a regular file

ls -l 
-rw-r--r--  1 hadoop hadoop      0 ene 27 18:18  example
drwxr-xr-x  2 hadoop hadoop   4096 ene 27 18:21  examples

$ [ -d examples ]
$ echo $?
0 : --> # is a directory

Using test an if statement

if test condition
   then 
   command...
   ...
fi
	or
if [ expression ]
   then 
   command...
   ...
fi

$ if [ $LOGNAME == "hadoop" ]
then 
echo $?
echo "Hello $LOGNAME"
fi
0
Hello hadoop

How to test/Debug a Shell Script
-x described as a debugger
-v described as a verbose
-n described as a syntax checker
 
$ cat myScript 
   echo running myScript
   FMHOME=/usr/frame
   MYBIN=/export/home/oracle/bin
   echo $FMHOME

$ bash -x myScript 
+ echo running myScript
running myScript
+ FMHOME=/usr/frame
+ MYBIN=/export/home/oracle/bin
+ echo /usr/frame
/usr/frame

$ bash -v myScript 
   echo running myScript
running myScript
   FMHOME=/usr/frame
   MYBIN=/export/home/oracle/bin
   echo $FMHOME
/usr/frame

$ bash -n myScript 

$ bash -xv myScript 
   echo running myScript
+ echo running myScript
running myScript
   FMHOME=/usr/frame
+ FMHOME=/usr/frame
   MYBIN=/export/home/oracle/bin
+ MYBIN=/export/home/oracle/bin
   echo $FMHOME
+ echo /usr/frame
/usr/frame

$ bash -xn myScript 
$ 

$ cat myScript 
   #!/usr/bin/bash -xv
   echo running myScript
   FMHOME=/usr/frame
   MYBIN=/export/home/oracle/bin
   echo $FMHOME


   #!/usr/bin/bash << EOF
   #!/usr/bin/bash -xv << EOF
   echo running myScript
   FMHOME=/usr/frame
   MYBIN=/export/home/oracle/bin
   echo $FMHOME
   >> EOF


Conditional Expressions

The && operator: ensures that the second command is run only if the preceding command succeeds, both command succeed
$ mkdir $HOME/newdir && cd $HOME/newdir
$ pwd
/home/hadoop/newdir

$ mkdir $HOME/newdir && cd $HOME/newdir
mkdir: cannot create directory ‘/home/hadoop/newdir’: File exists

The || operator: ensures that the second command is run only if the preceding command fails
$ pwd
/home/hadoop
$ mkdir $HOME/newdir || cd $HOME/newdir
mkdir: cannot create directory ‘/home/hadoop/newdir’: File exists
$ pwd
/home/hadoop/newdir

The if statement: evaluates the exit status of a command and initiates additional actions based on the return value
if [ command | test ];
   then 		# on true execute when exit status is zero 
   command1..
   ...
else
   command2..           # on false execute when exit status is nonzero 
   ...
fi

$ id
uid=1001(hadoop) gid=1001(hadoop) groups=1001(hadoop),27(sudo)
$ if test $LOGNAME = root
then
echo Hello System Administrator
else
echo $?
echo "Hello " $LOGNAME
fi
1
Hello  hadoop


if [ command1 | test1 ];
   then 			# on true execute when exit status is zero 
   	commandn..              # on true execute
   	...
   elif [ command2 | test2 ];   # on false run a second nested test
        then
	     commandn           # on true from the second nested test
   	     ...
        else
             commandn..         # on false from the second nestead test
             ...
fi

$ whoami
hadoop
$ if [ $LOGNAME == root ]
  then 
    echo Hello System Administrator
  elif [ $LOGNAME == hadoop ] 
    then
      echo $?
      echo "Hello " $LOGNAME
    else
      echo "Don't know LOGNAME"
  fi
0
Hello  hadoop

The case statement: compares a single value against other values, 
and runs a command or group of commands when a match is found

$ case value in
  pat1)
  command1
  ...
  ;;
  patn)
  commandn
  ...
  ;;
  *)
  echo "Usage: $0 ( pat1 | patn )"
  exit 3
  ;;
  esac 

After a match is found for start or stop and the respective commands are run,
no other patterns are checked

#!/sbin/sh
case "$1" in
'start')
  if [ -f /etc/vold.conf -a -f /usr/sbin/vold-a \ 
  "${_INIT_ZONENAME:=`/sbin/zonename`}" = "global" ]; then
  echo 'volume management starting.'
  /usr/sbin/vold >/dev/msglog 2>&1 &
  fi
  ;;
'stop')
 /usr/bin/pkill -x -u 0 vold
 ;;
*)
 echo "Usage: $0 { start | stop }"
 exit 1
 ;;
esac

Looping Constructs Many programming/scripting languages provide structures 
to iterate through a list of objects.

The bash shell provides the following three loop structure

- for loop statement

  Evalua the exit status of the in operation: 
  if es zero any instructions are run, command or test is rerun and the exit status is re-checked
  if is nonzero, the loop terminates.

  for arg in []
  do
    commandn
    ...
  done

  ex:

  $ for (( i=1 ; i<=5 ; i++ ))
    do
      echo $i
    done
  1
  2
  3
  4
  5

  $ for (( i=5 ; i>=1 ; i-- )); do   echo $i; done
  5
  4
  3
  2
  1

  Shifting Positional Parameters in a Loop
  While passing command-line arguments, the Bourne (sh) shell accepts only a single number after the $sign ($0-$9).
  An attempt to access the value in the tenth argument using the notation $10 results in the value of $1 followed by a zero (0)
  Both the Korn (ksh) Shell and Bash shell can access the 10th parameter directly whith the value of the 10th argument ${10}. 
  However, that could become very cumbersome in a loop.
  The shift command enables you to shift your positional parameter values back by one position 
  when processing the positional parameters in a loop.
       The value of the $2 parameter becomes assigned to the $1 parameter 
       Therefore, there is no limit on the number of positional parameters that can be passed to a shell script 

  Use the set command to assign values for six positional arguments:

  $ set 5 4 3 2 1 Blastoff
  $ echo $@
  5 4 3 2 1 Blastoff
  $ for arg in $@
	do
          (( i = i + 1 ))
	  echo "Parameter $1 the loop $i"
   	  shift
        done 

- while (true) loop statement

  repeat a command or group of commands in a loop

  Evalua the exit status of the command or test command:
  if is zero, any instructions follow the do statement are run
     command or test is rerun and the exit status is re-checked
  if nonzero, the loop terminates.

  while [ command | test ]
  command or test is rerun, and the exit status rechecked
    do
      commandn
      ...
    done
   
  $ set this is a while loop
  $ echo $@
  this is a while loop 
  $ while [ $# -gt 0 ] 
    do 
      echo $1
      shift
    done

- until (true) loop statement

  repeat a command or group of commands in a loop - At least run ONCE

  Evalua the exit status of the command or test command:
  if is NONzero, any instructions follow the do statement are run
     command or test is rerun and the exit status is re-checked
  if is zero, the loop terminates.

  until [ command | test ]
    do
      commandn
      ...
    done

  $ set this is an UNTIL loop
  $ echo $@
  this is an UNTIL loop
  $ until [ $# -le 0 ]
    do
      echo $1
      shift
    done

<<-O-J-O>> probar

#!/bin/sh
#leaptest.sh (biciesto)
# This shell check if a year is a leap year or not

year=`date +%Y`

echo "The year is: $year"

if [ $[$year % 400] -eq "0" ]; then 
     echo "This is an leap year: February has 29 days"
elif [ $[$year % 4] -eq 0 ]; then 
       if [ $[$year % 100] -ne 0 ]; then 
            echo "This is an leap year: February has 29 days"
       else
            echo "This is NOT an leap year: February has 28 days"
       fi      
else
     echo "This is NOY an leap year: February has 28 days"
fi

<<-O-J-O>> probar

The next module provides us some information about some operations that are commonly needed on Unix or Linux operating systems, like archiving and compressing files and performing remote file transfers. Those operations are very important when you need to save the current state of some configuration files in order to backup them on some, I don't know, persistent layers that probably are located remotely, in order to be able to recover them in case of disaster. So generally, these kinds of operations will support disaster recovery solutions.

In the first part, you will learn about the tools that are available to archive and retrieve files. Then you will learn about the tools that you can use to compress, view, and uncompress file. And in the last section, you will learn about the applications that are available on the Unix and Linux systems in order to perform remote connections and file transfers.

Let's start with the first section. As I mentioned before, in order to safeguard your files and directories, it will be useful for you to be able to create a copy of all the files and directories in your file system, or at least in some specific, very important directories on your file system, where you have the configuration files for your application.

This copy will be a repository of files and directories, which is called an archive, and will generally be used as backup in the event of data loss. You generally will create such archive on a storage device, such as a remote disk or a type, that can either be-- send it away in a remote location in order to have it handy in case of a disaster would strike. The most commonly used command to support the creation of such archive is the tar command.

You have here a note, which is pretty important. It is a good practice to use a relative path names when you archive your files in order to be able to recover them in other physical locations if needed.

Next, you can see the general syntax that can be used for creating archives. The tar command can be used to create archives to add, delete files from a archive, to list the content of an archive, or to extract the files from an archive file.

The output of the tar commanded, it's a tar file. The default output location for a tar file, it's standard output, but you will be able to indicate a file for this location instead. Of course, the options that are available for the tar command are fully explained in the main page. The most important ones are also listed in the following slide.

So in order to create archives, you should use the C option. In order to list the table of contents for an archive, you should use the T option. To extract the files from the archive, you should use the X option.

To specify the archive file or the tape device where the output will be redirected, you should use the F option. To execute the command in verbose mode in order to generate information about the operations that are executed, you should use the V option.

To follow the symbolic links as standard files or directories, you should use the age H option. To additionally compress the files and directories that are included in your archive, by using gzip, you can use the Z option. And in order to compress the files and directories, that will be included in the archive by using bzip2. You should use the G option.

So as you can see, tar commands provide you support to also compress the data while creating archives. Normally the data will not be compressed in any way, or it will just be put together in the same file. Then you can choose what tool, what algorithm you would like to be used to also compress that file if you want to minimize the space needed to store those files. But you can also use those two options in order to choose one of the two supported algorithms to do both operations together-- to create the archive and also to compress the archive.

Next you can see some samples of creating an archive. First-- so you need to use the C option, and you will create an archive. Here, you create an archive on a disk-- dev remote mount 0, and you will have archive the current working directory-- probably your home directory. Second shows you how you can create these files start archive by putting together a file1, file2, and file3.

The second sample shows you how you can explore the content of an archive. So if you want to view the table of contents, you need to use the T option, indicating the location of the archive. And also in the verbose mode to display more information about each file, which is part of that archive.

In order to extract an archive, you need to use the X option. Again, indicating as parameter the location of your archive, which can be either on disk or on file.

Next, we have the first quiz for this lesson. Which command do you use to view the table of contents of an archive file named file8.tar? Again, you can pause the video and try to figure out for yourself. So the correct answer here is c. In order to see the table of contents, you need to use T option.

In the second part, you will learn about how you can compress, view, and uncompress files. As you saw, tar out of the box only provide you support to create the hypes without applying any kind of compression. That will save some storage.

But you can take advantage of other utilities in order to save disk space and optimize the data transfer time. Like gzip, zip, and bzip2. So here you can see how you can take advantage of gzip command to compress files.

The main difference between those commands are the compression algorithms that are used. Over time, there were different compression algorithms that were developed. So different tools will support different compression algorithms. One of them may be more efficient by others.

So generally, it will be a good thing to have a look in the main page to learn about the compression algorithms that are used and the efficiency that is provided by those compression algorithms. So you can see here an example on how you can use gzip command in order to compress three files-- four files. Next, you can see him how you can uncompress the files that were created with gzip by using either gunzip or gzip minus d.

Oracle Linux, you can take advantage of zcat command in order to print the uncompressed form for the uncompressed file to standard output, and in this way to view the content of that file. You can also see here an example.

On Oracle Solaris, the gzcat command can be used to display the content of a file that were compressed with gzip comment to standard output. And again, you have here an example for this operation.

The zip comment can also be used on Linux and Solaris in order to archive and compress multiple files into a singular high file, which is compatible with the files created on Windows, for example. So here you can see how you can take advantage of zip in order to create the file.zip archive, which is also compressed by using the file 2 and file 3.

In order to view and uncompress zip files, you can use the unzip command. The bz2 commands can also be used to compress files. Here you can see an example of this command.

In order to uncompress a file that was compressed to be zipped to, you should use bunzip2. In order to view the file that was compressed with bzip2, you can use the bzcat command.

The next quiz, which command has packaging and compression capabilities in addition to archiving features? Again, you can pause the video and try to figure out the answer for yourself.

Here, in my opinion, both are true. If you remember, tar has some options that allows you to compress the archive, and also zip is able to create archives by also applying a compression algorithm.

Another quiz. The Oracle Solaris gscat command is used to view files that has been compressed by using the gzip command. Again, you can pause the video and try to figure out the answer for yourself. So, the correct answer here is true.

The next one-- what is the output of the specified command? Again, you can pause the video and try to figure out the answer for yourself.

So the correct answer here is c. The file7.zip will be created containing the file4 and file12 files. So those two files are archived and compressed. 

File Archival

cpio is yet another archival program. Unlike tar, which automatically recurses
subdirectories, cpio reads a list of files and directories from stdin, creates the archive, and writes
the archive to stdout

Tar command create, add, delete, list or extracts files in a tape archive file: $ man tar ór tar --help

$ tar [options] archivefile filenames

The output of using a tar command is a tar file
The default output location for a tar file in UNIX and Linux is stdout

Option	Description
------	-----------
  c	Create un nuevo tar file
  t	List the table of contents of the tar file
  x	Extracts files from the tar file
  f	Specifies the archieve file or tape device the output will be redirected 
  v	Executes in verbose mode; generate information about the operations that are executed; writes to the standard output
  h	Follows symbolic links as standard files or directories
  z 	Compresses and extracts files and directories by using gzip
  j 	Compresses and extracts files and directories by using bzip2

  c	Create un nuevo tar file - optional [-] - at the beginning of the output shows "a" that a file has been added to the archive 

 - tar multiple files(file?) into an archive file(files.tar): $ tar [-]cvf files.tar file1 file2 file3

	$ tar cvf file.tar file?
	file1
	file2
	file3
	file4
	file5

	$ ls -lF file*.tar
	/home/hadoop/newdir
	12K -rw-r--r-- 1 hadoop hadoop 10K feb  5 01:56 file.tar

 - tar home directory on a disk: $ tar [-]cvf /dev/rmt/0 .
 
 Basic Device Names for Backup Devices 

  Tape: /dev/rmt/n
  Diskette: /vol/dev/rdiskette0/unlabeled 

  t	List the table of contents of the tar file - optional [-]

	$ tar tvf file.tar
	-rw-r--r-- hadoop/hadoop     6 2021-02-05 01:54 file1
	-rw-r--r-- hadoop/hadoop     6 2021-02-05 01:55 file2
	-rw-r--r-- hadoop/hadoop     6 2021-02-05 01:55 file3
	-rw-r--r-- hadoop/hadoop     6 2021-02-05 01:55 file4
	-rw-r--r-- hadoop/hadoop     6 2021-02-05 01:55 file5

 
 - to view the table of contents of Oracle's home directory on the disk: $ tar [-]tf /dev/rmt/0

 - to view the verbose content of the file(files.tar): $ tar [-]tvf files.tar

  x	Extracts files from the tar file - optional [-] - at the beginning of the output shows "x" that a copy of the file was extracted

	$ tar xvf ../file.tar
	file1
	file2
	file3
	file4
	file5
	$ ls -lF
	/home/hadoop/newdir/retrieve
	total 28K
	4,0K drwxr-xr-x 2 hadoop hadoop 4,0K feb  5 02:06 ./
	4,0K drwxr-xr-x 3 hadoop hadoop 4,0K feb  5 02:06 ../
	4,0K -rw-r--r-- 1 hadoop hadoop    6 feb  5 01:55 file5
	4,0K -rw-r--r-- 1 hadoop hadoop    6 feb  5 01:55 file4
	4,0K -rw-r--r-- 1 hadoop hadoop    6 feb  5 01:55 file3
	4,0K -rw-r--r-- 1 hadoop hadoop    6 feb  5 01:55 file2
	4,0K -rw-r--r-- 1 hadoop hadoop    6 feb  5 01:54 file1

 - to retrieve all the files from the disk archieve: $ tar [-]xvf /dev/rmt/0

 - to extract or restore a single file from the files.tar: $ tar [-]xvf files.tar file1 

 ex: $ tar -xf file.tgz

 Compressing a File: gzip command: gzip [options] filename(s)
 - to compress a set of files: $ gzip file1 file2 file3 file4 file5
   ls *.gz

	$ gzip file1 file2 file3 file4
	$ ls -l
	/home/hadoop/newdir
	total 44K
	4,0K drwxr-xr-x  3 hadoop hadoop 4,0K feb  5 02:20 .
	4,0K drwxr-xr-x  2 hadoop hadoop 4,0K feb  5 02:06 retrieve
	 12K -rw-r--r--  1 hadoop hadoop  10K feb  5 01:56 file.tar
	4,0K -rw-r--r--  1 hadoop hadoop    6 feb  5 01:55 file5
	4,0K -rw-r--r--  1 hadoop hadoop   32 feb  5 01:55 file4.gz
	4,0K -rw-r--r--  1 hadoop hadoop   32 feb  5 01:55 file3.gz
	4,0K -rw-r--r--  1 hadoop hadoop   32 feb  5 01:55 file2.gz
	4,0K -rw-r--r--  1 hadoop hadoop   32 feb  5 01:54 file1.gz
	4,0K drwxr-xr-x 72 hadoop hadoop 4,0K feb  4 23:50 ..


 Uncompressing a File: gzip command: gzip [options] filename
 - to uncompress a file1: $ gzip -d file1.gz

 Uncompressing a File: gunzip command: gunzip [options] filename
 - to uncompress a file1: $ gunzip file1.gz
	$ gunzip file?.gz
	(base) hadoop@sc-ubuntu-18-04-5-lts:~/newdir$ ls -lF
	/home/hadoop/newdir
	total 44K
	4,0K drwxr-xr-x  3 hadoop hadoop 4,0K feb  5 02:38 ./
	4,0K drwxr-xr-x  2 hadoop hadoop 4,0K feb  5 02:06 retrieve/
	 12K -rw-r--r--  1 hadoop hadoop  10K feb  5 01:56 file.tar
	4,0K -rw-r--r--  1 hadoop hadoop    6 feb  5 01:55 file5
	4,0K -rw-r--r--  1 hadoop hadoop    6 feb  5 01:55 file4
	4,0K -rw-r--r--  1 hadoop hadoop    6 feb  5 01:55 file3
	4,0K -rw-r--r--  1 hadoop hadoop    6 feb  5 01:55 file2
	4,0K -rw-r--r--  1 hadoop hadoop    6 feb  5 01:54 file1
	4,0K drwxr-xr-x 72 hadoop hadoop 4,0K feb  4 23:50 ../

 
 Viewing a Compressed File: zcat command: zcat [options] filename
 - view the content of the file file1.gz: $ zcat file1.gz | less
	$ zcat file?.gz
	file1
	file2
	file3
	file4
	$ zcat file1.gz
	file1

 Viewing a Compressed File with the gzip command: gzcat command: gzcat [options] filename
 - view the content of the file file1.gz: $ gzcat file1.gz

 Compressing multiple files into a single archive file, and is compatible with files created with pkzip: 
   zip command: zip [options] archivefile filename(s)
 - to compress file2 and file3 into a file.zip: $ zip file.zip file2 file3
   ls *.zip

	$ zip myfiles.zip file*
  	adding: file1 (stored 0%)
  	adding: file2 (stored 0%)
  	adding: file3 (stored 0%)
  	adding: file4 (stored 0%)
  	adding: file5 (stored 0%)
  	adding: file.tar (deflated 98%)

	$ ls -l myfiles.zip
	/home/hadoop/newdir
	4,0K -rw-r--r-- 1 hadoop hadoop 1,1K feb  5 02:47 myfiles.zip

 ex: $ zip myfiles.zip *

 Viewing and Uncompressing Archive Files: unzip command: unzip [options] archivefile
 - to uncompress the file.zip archive file: $ unzip file.zip

	$ mkdir unzip
	$ cd unzip/
	$ unzip -l ../myfiles.zip 
	Archive:  ../myfiles.zip
	  Length      Date    Time    Name
	---------  ---------- -----   ----
	        6  2021-02-05 01:54   file1
	        6  2021-02-05 01:55   file2
	        6  2021-02-05 01:55   file3
	        6  2021-02-05 01:55   file4
	        6  2021-02-05 01:55   file5
	    10240  2021-02-05 01:56   file.tar
	---------                     -------
	    10270                     6 files

	$ unzip ../myfiles.zip 
	Archive:  ../myfiles.zip
	replace file1? [y]es, [n]o, [A]ll, [N]one, [r]ename: A
	 extracting: file1                   
	 extracting: file2                   
	 extracting: file3                   
	 extracting: file4                   
	 extracting: file5                   
	  inflating: file.tar  

 Compressing a File: bzip2 command: bzip2 [options] filename(s)
 - to compress a set of files, file1, file2, file3, and file4: $ bzip2 file1 file2 file3 file4 
   ls *.bz2

 Uncompressing a File: bunzip2 command: that has been compressed with the bzip2 command: bunzip2 [options] filename
 - to uncompress the file1.bz2: $ bunzip2 file1.bz2

 Viewing a Compressed File: bzcat command: bzcat [options] filename
 - to view the content of the file1.bz2: $ bzcat file1.bz2 | less

 Computer Networking 

In the second part of this lesson, you will learn about how you can perform remote connections and file transfers. So most of the time, your computer will be part of a computer network, which is a group of computer components that are connected with each other by some special communication channels. In this way, you will be able to share resources and information.

A computer system that is part of a network is called a host. This can be either a personal computer, a server, or a piece of network hardware that will be used to provide support for this architecture. It can be a bridge, a router, a switch, a printer.

Generally, you refer with the local host term to your current working system. This is generally a PC, a personal computer. And the remote host is any system that is accessed from your local host by taking advantage of the networking infrastructure.

The next slide shows you a graphical description on how such a network may look like. As you can see, I have here two PCs, one server-- sorry. I have three PCs, two servers and a printer. And of course, the communication channel that allows me to share resources on this network.

The communication channel doesn't need to be always a physical, let's say, layer. We don't need to have cables. You can also create wireless networks right now. As long as you are able to communicate between those hosts, you should be in this kind of architecture.

In order to work on a network and to take advantage of the network, both Unix and Linux-based systems provide you a suite of network utilities, which are known as OpenBSD Secure Shell-- OpenSSH-- which provides you support for being able to take advantage of the network in a secured environment.

The most important utilities that are part of this package are SSH, the secure shell, which allows you to connect to a client server by using encrypted communication communication. But that takes advantage of public and private key pairs for encrypting the communication channel.

In order to generate the public and private keys that will be used to secure the communication channel, you can use the SSH Key Gen utility, which is not listed here, but it's another very important utility which allows you to manage, as I mentioned before, the public and the private key pairs that are needed to support this secured communication.

So as I mentioned before, the most important tool from this list is SSH, which provides you a terminal-like session, that can be used to connect to a remote machine in a secure way, and to access that remote host like a local host. So you will be able to work on that remote host in a similar way with how you worked when you are directly connected to that host.

In order to be able to use SSH, you need a program to run on the remote host in order to execute the commands that you send from your remote terminal. This program is the Secure Shell Server Daemon, the SSHD, which needs to be configured on the remote machine, to be used as the partner in the communication between your local machine and the remote machine.

The SSHD application provide you the support for securing the connection between the local machine and the remote machine. The other two utilities that are listed here are also very commonly used when you need to copy files securely, either by using a terminal-like approach, or an FTP-like approach.

The SFTP has been developed mostly to emulate standard FTP sessions. The FTP tools have been the first developed for a Unix system in order to support file transfer. The standard FTP works in an unsecured way, because initially, there were no major problems with the security.

But right now, because as I'm sure you are aware, there are a lot of security risks. The FTP protocol has been secured using this utility, but in the same time, allows you to take advantage of the knowledge that you had as administrator for normal FTP servers, and to be able to do the common operations without the need to familiarize with, I don't know, some other command.

So you will be able to open remote network connections between your client machine and any server machine that is running SSHD in order to do either secure copy or to be able to work on that remote machine like you can work when you are connected locally. Each session will be authenticated with the user name and the password and will be secured using the public and private key pair that is configured.

So the SSH network protocol provides you a secure, encrypted communication channel between two untrusted hosts over an unsecure network. SSH can use public key encryption to authenticate the remote login session, based on public private key pairs that can be generated with SSH Key Gen. In both Oracle Solaris and Oracle Linux, this suite of applications, OpenSSH, is installed by default and already configured.

Next, you can see some samples of commands that you can use in order to copy files and directories between the local and the remote host using the Secure Copy command. So here is the syntax that should be used with Secure Copy. In order to copy from the local directory, you just need to indicate first the local file, and then the details that are needed to be able to connect to the remote machine, and indicate the location where the source file will be copied.

The user name is only needed if you connect to using another identity than the current one. If you want to copy from the remote host to the local directory, the syntax will be inverse. So you need to specify the details that allows you to identify the remote source file first, followed by the local target file.

You can also use Secure Copy to copy entire directories to and from another system by taking advantage to the minus r option-- the recursive copy. Here we can see two examples that allows you to copy a directory to any remote host, and to copy a remote directory to the local host.

Next, we have a few quizzes. The first one-- identify the correct comment to copy the /opt/dante file from a remote host to the temp directory in your system. Again, you can pause the video and try to figure it out for yourself which is the correct answer for this one.

So in order to copy from the remote host to the temp directory, first you need to indicate the remote file, and then the local directory as parameters for the Secure Copy command. So the correct option here is D.

In the last section of this lesson, you will learn about FTP, the file transfer protocol. It's a network protocol that was created in order to support exchanging files over a network. FTP implements user-based password authentication, but also allows anonymous user access when you need to publish some files to everyone.

In order to access on a remote server for exchanging files in a secure way, it is recommended to take advantage of the SFTP command right now. So the SFTP, the secure FTP command-- it has been developed as an interactive file transfer program that allows you to perform all the standard FTP operations, such as file access transfer management, but over an encrypted SSH infrastructure.

Being an extension of OpenSSH protocol, the SFTP is using many of the features of SSH, such as public key authentication and encryption to enforce security. SFTP is using only the binary transfer mode, which is byte for byte transfer, so you cannot use text-based access mode.

You learned previously how you can determine the file type using the file command. It's important to note that even this text file is reported as ASCII English text. There are differences on how the English text is stored on different operating systems, more specifically, related to the symbol that is used to represent the end of line, or new line, on each system.

So Mac, pre-OS X, it's using a single character carriage return, while Mac OS X, it's using the Control M single character to indicate the end of the line, same as Unix and Linux, while Microsoft is using a double CRLF character, carriage return plus line feed to end a line. So in order to be able to correctly display the content of a text file, you need to convert the file based on the destination where the file will be transferred. So you should use commands like dos2unix and unix2dos in order to convert the file's format based on the destination to which the file will be transferred.

So you can see here how you can convert from Microsoft to Unix, Linux or Mac, or how you can convert from Unix, Linux or Mac to Microsoft when you need to transfer the file between those operating systems.

Then you can use the commands that are available on SFTP, like open, get, put, mget, mput, bye, exit and quit. The semantics of those commands is pretty straightforward in order to do different operations in an SFTP session.

Here is an example where you can see how you can transfer a single file using SFTP. So I use the get command transfer to the file, and then to check that this file has been indeed transferred on my local host. And here you can see how you can use get with a pattern in order to transfer multiple files together.

And check that those files have been successfully transferred. Local ls allows you to see the files that were transferred in this session, probably those ones.

Our last set of quizzes for this session. Which is the most secure command for remotely logging in to another system within the network? Again, you can pause the video and try to figure out the correct answer for yourself. The correct answer in this case is SSH.

Then select the three correct SFTP command syntaxes to end an FTP session. Again, you can pause the video.

The correct answer here is A-- exit, B-- quit, and D-- bye.

OpenSSH and Remote Network Connections - OpenBSD Secure Shell - security utilities using the Secure Shell (SSH) network protocol.

- sshd: (secure shell server daemon) secure end-to-end encrypted connection in an unsecure network
- ssh: (secure shell) which connects a client to a server 
- scp: (secure copy) which copies files securely
- sftp: (secure ftp) which provides a secure file transfer protocol connection

Remote login network connections can occur between a client machine and a server running sshd and between one server 
to another server running sshd.

Each new connection/session is authenticated with a username and password.

Once the session is authenticated and established, both the local and remote hosts communicate with each other via the 
Secure Shell (SSH) network protocol

To generate public and private key pairs for authentication when connecting in Oracle's Cloud Environment: 
	$ ssh-keygen -t [ rsa1 | dsa | ecdsa | rsa ] 

the type of key pairs being generated depends on the version of OpenSSH: 
"rsa1"  Version1 and 
"dsa", "ecdsa", "rsa" Version2

- ssh: (secure shell) provides a secure encrypted communication between two untrusted host over an unsecure network
  allows you to connect and log in to a specified remote host

  $ ssh [options] [-l login_name | username@]hostname [command]

  ssh can use public-key encryption to authenticate a remote login session.
      In public-key encryption, the ssh-keygen command generates a public-key that can 
      be copied to all hosts that intend to communicate with the holder of the matching private-key

	$ ssh hadoop@192.168.1.155
	Welcome to Ubuntu 18.04.5 LTS (GNU/Linux 5.4.0-64-generic x86_64)

	 * Documentation:  https://help.ubuntu.com
	 * Management:     https://landscape.canonical.com
	 * Support:        https://ubuntu.com/advantage

	 * Canonical Livepatch is available for installation.
	   - Reduce system reboots and improve kernel security. Activate at:
	     https://ubuntu.com/livepatch

	0 packages can be updated.
	0 of these updates are security updates.

	New release '20.04.2 LTS' available.
	Run 'do-release-upgrade' to upgrade to it.

	Your Hardware Enablement Stack (HWE) is supported until April 2023.
	Last login: Thu May 28 19:21:07 2020 from ::1

	$ uname -n
	sc-ubuntu-18-04-5-lts
	$ ps -ef | grep whatever proccess on the remote machine
	$ kill xxxxx whatever proccess on the remote machine
        $ exit
	$ uname -n

  enable X11 forwarding: $ ssh -X username@hostname

  users know that you can connect to a Linux server quite easily using a variety of SSH (Secure Shell) clients. 
  That's all well and good but what about if you need to use some tool that has a GUI? The answer is to use X11 forwarding. 
  X11 forwarding is a mechanism that allows a user to start up remote applications 
  but forward the application display to your local Windows machine.

  PuTTY: select SSH, X11 and tick the box X11 forwarding. 
         The xdisplay location should also be set to localhost:0, 
         which is basically the display you are working on currently

  The best practice is to set SSH to not permitted for root user because any user would be able to su - into root.
  This provides a layer of protection for the root user.

- scp: (secure copy) which copies files and directories both ways securely between a Local and Remote Host.
     $ scp [options] SourceFile [username@]hostname:/directory/TargetFile 
     $ scp localFile remoteHost:/tmp

     	$ scp 'Screenshot from 2020-12-31 14-17-51.png' hadoop@192.168.1.155:/home/hadoop/newdir
	Welcome to Remote Login!
	Screenshot from 2020-12-31 14-17-51.png                    100%  169KB  86.2MB/s   00:00    
	$ 
	$ ls -l /home/hadoop/newdir
	/home/hadoop/Pictures
	total 224K
	172K -rw-rw-r--  1 hadoop hadoop 170K feb  6 00:19 'Screenshot from 2020-12-31 14-17-51.png'

  The [username@] syntax is needed only when connecting as a different user other than the logged in user 
  and requires you know that user's password.

  Reversing the direction and copying Files from a Remote Host to a Local Host
     $ scp [username@]hostname:/directory/SourceFile TargetFile 
     $ scp remoteHost:/tmp/remoteFile /localFile 

	$ scp hadoop@192.168.1.155:/home/hadoop/newdir/myfiles.zip .
	Welcome to Remote Login!
	myfiles.zip                                                 100% 1072    33.7KB/s   00:00    
	$ ls -l myfiles.zip 
	/home/hadoop/newdir
	4,0K -rw-r--r-- 1 hadoop hadoop 1,1K feb  6 00:29 myfiles.zip

  Copying Local Directories to and from a Remote Host
  -r option recursively copies entire directories to and from another system 
     $ scp -r ~/localFile remoteHost:/tmp
     $ scp -r remoteHost:/tmp ~/localFile 
  
  File Transfer Protocol (FTP): exchanging files over a TCP/IP protocol, user-based password authentication.
  also allows anonymous user access, where the password is usually a valid email address
  sftp securely to access a remote server for exchanging files
  sftp only uses the binary transfer mode which is a byte-for-byte transfer mode.

  - $ sftp [options] [username@]hostname

  <>

  ftp userspace command: refers to all of the code in an operating system that lives outside of the kernel. 
  Most Unix-like operating systems (including Linux) come pre-packaged with all kinds of utilities, programming languages, and graphical tools
  - these are user space applications. We often refer to this as “userland.”

  ls and cd commands are available at the sftp> prompt. 

  $ sftp hadoop@192.168.1.155
  Connected to 192.168.1.155.
  sftp> ls
  sftp> pwd
  Remote working directory: /home/hadoop

	$ sftp hadoop@192.168.1.155
	Welcome to Remote Login!
	Connected to 192.168.1.155.
	sftp> pwd
	Remote working directory: /home/hadoop
	sftp> get newdir/file.tar 
	Fetching /home/hadoop/newdir/file.tar to file.tar
	/home/hadoop/newdir/file.tar                                               0%    0     0.0KB/s   --:-- ETA
	sftp> lls
	file1  file2  file3  file4  file5  file.tar  myfiles.zip  retrieve  unzip
	sftp> pwd
	Remote working directory: /home/hadoop
	sftp> 
	sftp> pwd
	Remote working directory: /home/hadoop
	sftp> mget newdir/file* 
	Fetching /home/hadoop/newdir/file.tar to file.tar
	Fetching /home/hadoop/newdir/file1 to file1
	/home/hadoop/newdir/file1                                                   0%    0     0.0KB/s   --:-- ETA
	Fetching /home/hadoop/newdir/file2 to file2
	/home/hadoop/newdir/file2                                                   0%    0     0.0KB/s   --:-- ETA
	Fetching /home/hadoop/newdir/file3 to file3
	/home/hadoop/newdir/file3                                                   0%    0     0.0KB/s   --:-- ETA
	Fetching /home/hadoop/newdir/file4 to file4
	/home/hadoop/newdir/file4                                                   0%    0     0.0KB/s   --:-- ETA
	Fetching /home/hadoop/newdir/file5 to file5
	/home/hadoop/newdir/file5                                                   0%    0     0.0KB/s   --:-- ETA
	sftp> pwd
	Remote working directory: /home/hadoop
	sftp> 
	sftp> put newdir/file.tar
	sftp> mput newdir/file* 

  sftp> ?
  sftp> help
  Available commands:
  bye                                Quit sftp
  cd path                            Change remote directory to 'path' - on the remote machine
  chgrp grp path                     Change group of file 'path' to 'grp'
  chmod mode path                    Change permissions of file 'path' to 'mode'
  chown own path                     Change owner of file 'path' to 'own'
  df [-hi] [path]                    Display statistics for current directory or
                                     filesystem containing 'path'
  exit                               Quit sftp
  get [-afPpRr] remote [local]       Download file - from remote to local			$ get filename
  reget [-fPpRr] remote [local]      Resume download file
  reput [-fPpRr] [local] remote      Resume upload file
  help                               Display this help text
  lcd path                           Change local directory to 'path'
  lls [ls-options [path]]            Display local directory listing
  lmkdir path                        Create local directory
  ln [-s] oldpath newpath            Link remote file (-s for symlink)
  lpwd                               Print local working directory
  lrmdir path                        Remove local directory
  ls [-1afhlnrSt] [path]             Display remote directory listing
  lumask umask                       Set local umask to 'umask'
  mkdir path                         Create remote directory
  progress                           Toggle display of progress meter
  put [-afPpRr] local [remote]       Upload file - from local to remote
  pwd                                Display remote working directory
  quit                               Quit sftp
  rename oldpath newpath             Rename remote file
  rm path                            Delete remote file
  rmdir path                         Remove remote directory
  symlink oldpath newpath            Symlink remote file
  version                            Show SFTP version
  !command                           Execute 'command' in local shell
  !                                  Escape to local shell
  ?                                  Synonym for help
  sftp> 
  
  open				     Opens a connection to another computer on the network
  mget				     Transfers multiple files from the remote to the local 	$ mget filename
  mput 				     Transfers multiple files from local on the remote 

  $ ftp hadoop@192.168.1.155
  ftp: hadoop@192.168.1.155: Name or service not known
  ftp> help
  ftp> ?
  Commands may be abbreviated.  Commands are:
  !		dir		mdelete		qc		site
  $		disconnect	mdir		sendport	size
  account	exit		mget		put		status
  append	form		mkdir		pwd		struct
  ascii		get		mls		quit		system
  bell		glob		mode		quote		sunique
  binary	hash		modtime		recv		tenex
  bye		help		mput		reget		tick
  case		idle		newer		rstatus		trace
  cd		image		nmap		rhelp		type
  cdup		ipany		nlist		rename		user
  chmod		ipv4		ntrans		reset		umask
  close		ipv6		open		restart		verbose
  cr		lcd		prompt		rmdir		?
  delete	ls		passive		runique
  debug		macdef		proxy		send
  Command

  The symbol that is used to represent the end-of-line or newline:

  Mac pre OS X --> uses CR(a single character -- carriage return)
  Mac OS X, UNIX and Linux --> ^M (a single character -- Ctrl-M)
  Microsoft --> uses CRLF(a double character -- carriage return plus line feed)

  Using dos2unix or unix2dos - the original file is overwritten
  Commands to convert the file's format based on the destination to which the file is being transferred.

  from Microsoft to UNIX, Linux or MAC: $ dos2unix filename
  from UNIX, Linux or MAC to Microsoft: $ unix2dos filename 

In this last section of our training course, you will learn about the basic concepts for cloud computing. This is an optional lesson which will provide you some details about the Oracle offering for cloud. We will focus, of course, on Infrastructure as a Service because using a virtual machine that is available on the cloud-- a machine that is configured on Unix and Linux-- is part of this kind of offering-- Infrastructure as a Service. But we will also learn about the other kind of services that can be used from the cloud-- the Platform as a Service and the Software as a Service.

So during this lesson, I will try to give you some basic information about the Oracle Management Software that can be used for cloud solutions and to describe the key concepts and terms that are used when we discuss about Infrastructure as a Service. And you will learn the basic steps that are needed to set up a virtual machine that is running Oracle Linux in the cloud. So let's try to start.

First of all, what is cloud computing? Cloud computing provides you support to be able to use services that are available everywhere-- services that are accessible over internet. So every time when, for example, you use an email service, in fact you're using cloud-based service.

Oracle provides you these kind of services. And there are three levels of services that are part of the Oracle portfolio. First of all, we have the Infrastructure as a Service. The Infrastructure as a Service is a form of cloud computing that provides you infrastructure services over internet. This is generally the most basic type of service that can be provided over the internet.

In this way, you will have access to a number of computing resources, memory resources-- storage, networking resources that can be assembled together to build a virtual machine. Then it's your responsibility to install any kind of software you need on that machine in order to support your business processes. The Infrastructure as a Service, of course, it's required by all the other kind of cloud services, like Platform as a Service or Software as a Service.

The Platform as a Service provides you a number of services over internet that can help you develop or run your own business applications. So you will have access in this way to an infrastructure that can support your development or business processes. But it's up to you which kind of applications you install in this infrastructure. Generally, you can use services like Database as a Service or Java as a Service or Mobile as a Service or Security as a Service-- identity services. These are the kind of services that are available as Platform as a Service appliances.

The last and the most complex level in the same time is the Software as a Service. Generally, as Software as a Service, you will be able to access full business applications-- human resource applications or a project management applications or production management applications. So applications that directly support your business model. In this case, the cloud provider will be responsible to administer and to maintain the entire stack of technologies that are needed for those business applications to run.

For the other two kinds of services, like Platform as a Service or Infrastructure as a Service, the cloud provider will only be responsible until the level that you asked for. For example, the cloud provider will be responsible for maintaining your WebLogic server, which is accessible in the cloud. It's your responsibility to maintain any application that is deployed in that WebLogic server. The same is true for Infrastructure as a Service. The cloud provider will only maintain the resources that are used to assemble your virtual machine. It's up to you how you manage the lifecycle of the applications that will run in that specific virtual machine.

Next, what is Oracle Private Cloud Appliance? The Oracle Private Cloud Appliance-- it's a converged infrastructure appliance that provides you stability, high availability, and automation. Also, the Oracle Private Cloud Appliance comes with orchestration software that automatically handles the hardware. And it supports provisioning of Infrastructure and Platform as a Service on demand. In this way, you will be able to better take advantage of the cloud services, focusing on the services, not on managing the hardware. And you will be able to simplify in this way the application deployment and the management.

What is the Oracle OpenStack? It's a cloud management software that can be used to manage large pools of compute, storage, and networking resources. Oracle OpenStack, in fact, it's used as a management software for the Infrastructure as a Service solutions. It's based on OpenStack community release. It's developed as an enterprise-grade solution for managing an entire IT infrastructure and allows you to deploy very rapidly Oracle and third-party applications across shared compute, network, or storage resources. This is the technology that is right now used by the Oracle Infrastructure Cloud Services.

Oracle Cloud Infrastructure Services are a set of complementary cloud services that you enable to build and run a wide range of applications and services in a highly-available hosted environment. You can have services like compute services that provide you support to execute different processes, networking services that allow you to create and manage the network components that are needed for your cloud resources, block volume services that provide you support for storage solutions, and database services. In fact, database services are more a part of the Platform as a Service, not infrastructure services. But because they are commonly used regardless of what kind of applications you install on those machines, are also discussed together with the Cloud Infrastructure Services.

Identity and access management services that can be used to secure the resources, load balancing services that provide you support for highly-available architecture, object storage services that provide you support for unstructured data-- data that cannot be stored in relational database management systems, and audit services that allow you to track the usage and to be aware about all the security events.

Next, let's learn about some of the key concepts and terms that are used in cloud infrastructure. First of all-- Regions and Availability Domains. First of all, it's important to note that Oracle Cloud Infrastructure is physically hosted in such Regions and Availability Domains. So the bare metal services are physically hosted in such Regions and Availability Domains.

A Region is just a localized geographical area that is composed of several Availability Domains. An Availability Domain is one or more data centers that are located within a Region. And it's important to note that Availability Domains are isolated from each other, are fault-tolerant, and are very unlikely to fail simultaneously. So in this way, the different services will be distributed on those Regions and Availability Domains in order to benefit from high availability.

The Tenancy-- it's used in order to define a secure and isolated partition within the Oracle Cloud Infrastructure where you can create, organize, and administer your cloud resources. Oracle will create a Tenancy for your company when you sign up for Oracle Cloud Infrastructure. Your Tenancy will be the root for all the compartments that you will use to organize your cloud resources.

The Compartments allow you to organize and control the access to your cloud infrastructure resources. Of course, in order to work with your Compartments, you need to have the permissions. You can customize the compartment that you will use within a Tenancy. And every time when you will create new resources, you will need to specify the core compartment where you want that resource to belong.

Here, you can see how the user interface that is needed to manage the cloud resources looks like. And here, you can see the link that allows you to access the Compartment. And here, you have the menu items that allow you to manage the security policy, the compute resources, the database resources, the network resources, the storage resources, and the audit resources. Using those menus, you will be able to manage all the cloud resources that are needed for your organization.

The resources will be made available through instances. An instance is just a compute host that is running on the cloud. It's important to note that bare metal compute instances run on bare metal servers without an hypervisor to provide you better performance. You maintain the sole control of the physical CPU, memory, and Network Interface Cards, and you do not share the physical machine with any other tenants.

Managed virtual machine instances are also available for workloads that don't require dedicated physical servers or the high performance of bare metal instances. An image is just a template of a virtual hard drive that you can use to tour to quickly install an operating system and add their software for your instance. When you launch an instance, you also need to define its characteristics by choosing the image. The shape will be used to specify the number of the CPUs and the amount of memory that will be allocated to that instance in order to control the processing resources that are available on that instance.

The next slide shows you some information about the type of the images that are supported and the type of the shapes that you can use to configure the processing power that will be available for your cloud virtual machines. A Virtual Cloud Network-- it's a virtual version of a traditional network. A Virtual Cloud Network will include subnets, route tables, and gateways. Resides within a region, but subnets can belong to different Availability Domains.

Can have an optional Internet Gateway to handle public traffic. Can have an optional IP Secure VPN connection to securely extend your on-premises network. In order to run instances, you will always need to configure in Virtual Cloud Network first.

A block volume is just a virtual disk that provides you persistent block storage space for your instances. You can move, of course, the block volumes from one instance to another if you need without losing the data. Object storage-- it's a storage architecture that allows you to store and manage data as objects. You can create data files of any type and up to 50 gigabytes in size.

Next, you can see the task flow that is needed in order to launch an Oracle Cloud Infrastructure instance. So first, you need to create and assess SSH key pair. Then, you need to create or choose a compartment for your resources. Then create or choose a Virtual Cloud Network. Create a subnet for the Virtual Cloud Network. Then you will be able to launch instances. Connect to your instance and provision and manage block storage volumes for your instance. In order to provision block storage volume, first of all you need to add the block storage volume then attach the volume to the instance and then you will be able to connect the volume to your instance guest operating system.

Next, you can see the graphical user interface that is provided in the management application that allows you to do some of the most important tasks. So first of all, how to set up a Virtual Cloud Network. You need to go to the Networking menu. You remember the menus were available here? Yeah. So this is the Networking menu. So you need to go to the Networking menu, click on Virtual Cloud Network, create Virtual Cloud Network, provide all the required parameters for this network. And then Create Virtual Cloud network.

Then, you should create one or more subnets for your Virtual Cloud Network. When you create a subnet, you will need to provide the parameters for the subnet and then create this subnet. After you've created the subnet, you will be able to launch the instance. In order to launch the instance, you need to go to the Compute menu, click on Instances, and here, launch the instance.

Again, you will need to provide the parameters for the instance. Most important are the shape, the Virtual Cloud Network, the subnet. Optionally, you can specify a private address, but it's not mandatory. You can ask for your instance to be assigned on public IP address to be able to access it from remote if this instance will host software that needs to be accessible to your end users over internet.

After your launch the instance, you will be able to see details about this instance. Optionally, you can create a Block Storage Volume. Again, you need to go to the Storage, Block Volumes, Create Block Volumes. Then, you should provide the parameters for your Block Storage Volume. Then, you will need to attach the Block Storage Volume to your instance and connect the Block Storage Volume to the Instance Guest Operating System. Then, you will be able to log in to your instance and connect the block storage to your operating system using the commands that I've listed in the slide.

To learn more about how you can manage the cloud computing infrastructure services, you can use the information that are available on the Oracle website for the cloud portfolio. At the end of this lesson, we have a couple of quizzes. Again, you can pause the video and try to figure out the answer for the first quiz for yourself.

So the correct answer here are A, C, and D.

The second one-- what of the following statements about Oracle Cloud Infrastructure instances are true? Select all that apply. Again, you can pause the video and try to figure out the correct answer for yourself.

So the correct answers here are A, B, and C.

Those are the most important information about how you can configure and manage the Infrastructure Cloud Services. And this will conclude our training session. 

 Service models in Cloud Computing

 * Infrastructure as a Service (IaaS): Infrastructure services over the internet
   Users can access: Computer processors, Storage, Networks, Other infrastructure resources
   Their applications and data from anywhere, compute capacity, network bandwidth, strore capacity
   Providing hardware, maintenance, cloud infrastructure up to the virtualization level
   Create virtual machines and decide operating system and apps to use

 * Software as a Service (SaaS): Software services over the internet
   Users has access: only to the applications provided by the SaaS provider. (email provider)
   The provider has full control of the entire infrastructure including applications
  
   
 * Platform as a Service (PaaS): Platform services over the internet
   Users is able: Deploy applications using programs and tools provided by the provider who has full control of 
   the infrastructure up to the point where users are able to modify their applications and environment.
   (a web hosting provider that offers tools and programs to deploy a website)
 
 Oracle Private Cloud Appliance = (IaaS + PaaS), is a highly scalable integrated system that makes it easy 
 for customers to deploy and manage diverse workloads. 
 Full-stack performance optimizations allow customers to optimize the performance of containerized, 
 cloud-native applications and enterprise applications running on multiple operating systems.
 https://www.oracle.com/engineered-systems/private-cloud-appliance/
 https://www.oracle.com/servers/private-cloud-appliance/

 Oracle OpenStack (IaaS): Offers the ability to deploy different deployment configurations depending on the
 demand. As an IaaS cloud management platform, it centralizes enterprises' cloud operations for 
 OpenStack operators to manage and deploy resourses within an IT network environment.
 Oracle OpenStack is a software-defined network (SDN) solution in deploying VMs and virtual networks 
 abstracted from the physical infrastructure of a data center. Optimized for Oracle Linux,
 Oracle OpenStack securely steamlines the deployment of compute resources while decreasing the
 time to deploy applications.
 http://www.oracle.com/openstack

 Oracle Cloud Infrastructure Services 


<<-O-J-O>> probar
<<-O-J-O>> probar
<<-O-J-O>> probar
# check user and group names also against this regular expression.
#NAME_REGEX="^[a-z][-a-z0-9_]*\$"

to see the ip $ ip a
inet 192.168.1.155/24

Para utilizar aplicaciones windows en Ubuntu con playOnLinux + Wine
https://www.playonlinux.com/en/download.html

For the Bionic version
Type the following commands:

wget -q "http://deb.playonlinux.com/public.gpg" -O- | sudo apt-key add -
sudo wget http://deb.playonlinux.com/playonlinux_bionic.list -O /etc/apt/sources.list.d/playonlinux.list
sudo apt-get update
sudo apt-get install playonlinux


--------------------------------------------------------------------------------

He probado esta parte para hibernate por linea de comandos y me funciona:

https://askubuntu.com/questions/6769/hibernate-and-resume-from-a-swap-file


Estos son los pasos en mi ordenador:

- Make your /swapfile have at least the size of your RAM

swapoff  disables  swapping  on the specified devices and files
- si tienes swapfile deshabilitalo: sudo swapoff /swapfile

(base) hadoop@sc-ubuntu-20-04-2-lts:~$ sudo dd if=/dev/zero of=/swapfile bs=$(cat /proc/meminfo | awk '/MemTotal/ {print $2}') count=1024 conv=notrunc
        1024+0 records in
1024+0 records out
8114491392 bytes (8,1 GB, 7,6 GiB) copied, 152,056 s, 53,4 MB/s
(base) hadoop@sc-ubuntu-20-04-2-lts:~$ sudo mkswap /swapfile
Setting up swapspace version 1, size = 7,6 GiB (8114487296 bytes)
no label, UUID=1c3eb1c2-8213-4934-bb56-3756b611e695
(base) hadoop@sc-ubuntu-20-04-2-lts:~$ sudo swapon /swapfile

- Note the UUID of the partition containing your /swapfile

(base) hadoop@sc-ubuntu-20-04-2-lts:~$ sudo findmnt -no UUID -T /swapfile
53f40e22-f92e-494a-b657-8097c9ac74f9

- Reconfigure the package uswsusp in order to correctly use the swapfile:

(base) hadoop@sc-ubuntu-20-04-2-lts:~$ sudo dpkg-reconfigure -pmedium uswsusp

# Answer "Yes" to continue without swap space
# Select "/dev/disk/by-uuid/53f40e22-f92e-494a-b657-8097c9ac74f9"
# Encrypt: "No"

update-initramfs: deferring update (trigger activated)
Processing triggers for initramfs-tools (0.136ubuntu6.7) ...
update-initramfs: Generating /boot/initrd.img-5.4.0-1066-gke

- Edit the SystemD hibernate service using sudo systemctl edit systemd-hibernate.service and fill it with the following content:

(base) hadoop@sc-ubuntu-20-04-2-lts:~$ sudo systemctl edit systemd-hibernate.service
[Service]
ExecStart=
ExecStartPre=-/bin/run-parts -v -a pre /lib/systemd/system-sleep
ExecStart=/usr/sbin/s2disk
ExecStartPost=-/bin/run-parts -v --reverse -a post /lib/systemd/system-sleep

File /etc/systemd/system/systemd-hibernate.service.d/.#override.conf818ac1747df6fe54 saved

- Note the resume offset of your /swapfile:

(base) hadoop@sc-ubuntu-20-04-2-lts:~$ sudo swap-offset /swapfile
resume offset = 34816

- Configure Grub to resume from the swapfile by editing /etc/default/grub and modify the following line:

(base) hadoop@sc-ubuntu-20-04-2-lts:~$ sudo vi /etc/default/grub

#sc: 26/03/2022: he modificado la siguiente linea:
#GRUB_CMDLINE_LINUX_DEFAULT="quiet splash"
GRUB_CMDLINE_LINUX_DEFAULT="resume=UUID=53f40e22-f92e-494a-b657-8097c9ac74f9 resume_offset=34816 quiet splash"

- Update Grub:

(base) hadoop@sc-ubuntu-20-04-2-lts:~$ sudo update-grub
Sourcing file `/etc/default/grub'
Sourcing file `/etc/default/grub.d/init-select.cfg'
Generating grub configuration file ...
Found linux image: /boot/vmlinuz-5.4.0-1066-gke
Found initrd image: /boot/initrd.img-5.4.0-1066-gke
Found linux image: /boot/vmlinuz-5.4.0-1057-gke
Found initrd image: /boot/initrd.img-5.4.0-1057-gke
Found linux image: /boot/vmlinuz-5.4.0-72-generic
Found initrd image: /boot/initrd.img-5.4.0-72-generic
Found memtest86+ image: /boot/memtest86+.elf
Found memtest86+ image: /boot/memtest86+.bin
done

- Create the following 

(base) hadoop@sc-ubuntu-20-04-2-lts:~$ sudo vi /etc/initramfs-tools/conf.d/resume

RESUME=UUID=53f40e22-f92e-494a-b657-8097c9ac74f9 resume_offset=34816
    # Resume from /swapfile

    Update initramfs:

sudo update-initramfs -u -k all

Now you can hibernate 

(base) hadoop@sc-ubuntu-20-04-2-lts:~$ sudo systemctl hibernate

--------------------------------------------------------------------------------

// Esto no lo hice:

One can also create those scripts:

sudo tee /usr/local/bin/gotosleep <<EOF
dbus-send --type=method_call --dest=org.gnome.ScreenSaver /org/gnome/ScreenSaver org.gnome.ScreenSaver.Lock
sleep 2
sudo /usr/sbin/s2both
EOF
sudo chmod +x /usr/local/bin/gotosleep
sudo tee /usr/local/bin/gotohibernation <<EOF
dbus-send --type=method_call --dest=org.gnome.ScreenSaver /org/gnome/ScreenSaver org.gnome.ScreenSaver.Lock
sleep 2
sudo systemctl hibernate
EOF
sudo chmod +x /usr/local/bin/gotohibernation

So you can sleep with gotosleep or hibernate with gotohibernation.

You must be able to execute sudo s2both, sudo s2ram and sudo systemctl hibernatewithout having to enter your password for the previous scripts to work.

You could do that for example by creating a powerdev group, add your current user to it, and configure the following sudoers config (edit it with sudo visudo -f /etc/sudoers.d/powerdev):

%powerdev ALL=NOPASSWD: /usr/sbin/s2both, /usr/sbin/s2ram, /bin/systemctl hibernate

// Esto no lo hice:
--------------------------------------------------------------------------------

