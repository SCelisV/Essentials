# Python application 
"""
to execute:
scelisdev03@cluster-cca175-m:~$ vi app-bomberos-SanFrancisco.py

scelisdev03@cluster-cca175-m:~$ spark-submit app-bomberos-SanFrancisco.py
"""

"""
definition
Este fichero contiene las llamadas al departamento de bomberos de San Francisco a lo largo de varios años.
1. Crea la SparkSession
2. Define el schema
3. Crea el DataFrame a partir del fichero
4. Cambia el nombre y el tipo de algunas columnas.
El motivo de cambiar el tipo de las columnas es que lo que contienen son fechas que
no están en el formato timestamp. Se necesita este formato para poder ejecutar cier-
tas funciones sobre las columnas.
Write the results to /devsh_loudacre/accounts_by_state/state-code (such as accounts_by_state/CA).
"""

import sys

from pyspark.sql import SparkSession
from pyspark.sql.types import *
from pyspark.sql.functions import *

if __name__ == "__main__":

  # Crea la SparkSession
  spark = SparkSession. builder. appName("Bomberos San Francisco py"). getOrCreate()

  # Change the application log level from ERROR (the default) to WARN
  spark. sparkContext. setLogLevel("ERROR")

  # Define el schema

  devColumns = [
  StructField( "CallNumber", IntegerType() ),
  StructField( "UnitID", StringType() ),
  StructField( "IncidentNumber", IntegerType() ),
  StructField( "CallType", StringType() ),
  StructField( "CallDate", StringType() ),
  StructField( "WatchDate", StringType() ),
  StructField( "CallFinalDisposition", StringType()),
  StructField( "AvailableDtTm", StringType() ),
  StructField( "Address ",StringType() ),
  StructField( "City", StringType() ),
  StructField( "Zipcode", IntegerType() ),
  StructField( "Battalion", StringType() ),
  StructField( "StationArea", StringType() ),
  StructField( "Box", StringType() ),
  StructField( "OriginalPriority", StringType() ),
  StructField( "Priority", StringType() ),
  StructField( "FinalPriority", IntegerType() ),
  StructField( "ALSUnit", BooleanType() ),
  StructField( "CallTypeGroup", StringType() ),
  StructField( "NumAlarms", IntegerType() ),
  StructField( "UnitType", StringType() ),
  StructField( "UnitSequenceInCallDispatch", IntegerType() ),
  StructField( "FirePreventionDistrict", StringType() ),
  StructField( "SupervisorDistrict", StringType() ),
  StructField( "Neighborhood", StringType() ),
  StructField( "Location", StringType() ),
  StructField( "RowID", StringType() ),
  StructField( "Delay", FloatType() )
  ]

  devSchema = StructType( devColumns )

  # Crea el DataFrame a partir del fichero
  csvfile = "/devsh_loudacre/sf-fire-calls.csv"
  sfDF = spark. read. schema( devSchema ). option ( "header", True ). csv( csvfile  )

  # Cambia el nombre y el tipo de algunas columnas.
  """
    El motivo de cambiar el tipo de las columnas es que lo que contienen son fechas que no están en el formato timestamp. 
    Se necesita este formato para poder ejecutar ciertas funciones sobre las columnas.
    Columnas necesarias:
    Para el ejercicio se van a utilizar las siguientes columnas del DataFrame:

    Nombre: ResponseDelayedInMins - Tipo: Float - Contenido: Tiempo de respuesta en minutos. 
    Nombre: IncidentDate - Tipo: TimeStamp - Contenido: Fecha en la que se produjo la llamada
    Nombre: CallType - Tipo: String - Contenido: Tipo de llamada. Ejemplos: "Medical Incident", "Structure Fire"
    Nombre: Neighborhood - Tipo: String - Contenido: Barrio
    Nombre: Zipcode - Tipo: String - Contenido: Código postal desde donde se produjo la llamada.
  """

  # DF Transformado
  sfTDF = ( sfDF. withColumnRenamed( "Delay", "ResponseDelayedInMins" ). withColumn( "IncidentDate", to_timestamp( col( "CallDate" ), "MM/dd/yyyy" ) ). drop( "CallDate" ).  withColumn( "OnWatchDate", to_timestamp( col( "WatchDate" ), "MM/dd/yyyy" ) ). drop( "WatchDate" ).  withColumn( "AvailableDtTS", to_timestamp( col( "AvailableDtTm" ), "MM/dd/yy hh:mm:ss a" ) ). drop( "AvailableDtTm" ). persist() )

  """
  1. ¿Cuantos tipos distintos de llamadas se hicieron a los bomberos? No hay que incluir los valores nulos.
  """

  countCalls = ( sfTDF. select( "CallType" ). where( col( "CallType" ). isNotNull() ). distinct(). count() )
  print( "Distinct types: " + str( countCalls ) )

  """
  2. ¿Cuántas llamadas tuvieron un tiempo de respuesta superior a 5 minutos?
  """

  respGt5 = ( sfTDF. where( "ResponseDelayedInMins > 5" ). count() ) 
  print( "Delayed more than 5 mins: " + str( respGt5 ) )

  """
  3. Ordenar los meses del año 2018 de acuerdo al número de llamadas.
  """

  ( sfTDF. filter( year( col( "IncidentDate" ) ) == 2018 ). select ( "IncidentDate" ). groupBy( month( col( "IncidentDate" ) ). alias("month") ). count(). orderBy( col( "count" ). desc() ) . show() )

  """
  4. ¿Qué barrio de San Francisco generó el mayor número de llamadas en el año 2018? 
  """
  ( sfTDF. filter( year( col( "IncidentDate" ) ) == 2018 ). groupBy( "Neighborhood" ). count() .orderBy( col( "count" ). desc() ) . show() .first() )
  print( first[0] )

  """
  5. Averiguar los 10 barrios que tuvieron el peor tiempo de respuesta en las llamadas del año 2018.
  """
  ( sfTDF. filter( year( col( "IncidentDate" ) ) == 2018 ).
      groupBy( "Neighborhood" ).
      avg( "ResponseDelayedInMins" ).
      withColumnRenamed( "avg(ResponseDelayedInMins)", "AverageResponseTime" ).
      orderBy( col( "AverageResponseTime" ).desc() ).
      select( col( "Neighborhood" ), format_number( col( "AverageResponseTime" ), 2 ).
      name("AverageResponseTime") ).
      show( 10, False ) )

  """
  6. ¿Qué barrios de Snn Francisco tienen como Zipcode 94102 o 94103? 
  """ 
  ( sfTDF. select( "Neighborhood", "Zipcode" ).
  where( col( "Zipcode" ) == 94102 | col( "Zipcode" ) == 94103 ).
  distinct().
  show() 
  ) 

  """
  7. Mostrar las 10 semanas en las que se produjeron más llamadas independientemente del año. 
  """
  ( sfTDF. 
  groupBy (). 
  count().
  orderBy( col( "year" ).desc() ).
  show() 
  ) 
  
  #stop the Spark session:
  spark.stop()