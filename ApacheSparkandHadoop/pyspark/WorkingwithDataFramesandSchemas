#------------------
#Hands-On Exercise: Working with DataFrames and Schemas
#------------------

#export PYSPARK_DRIVER_PYTHON=ipython
#PYSPARK_DRIVER_PYTHON_OPTS=ipython
#pyspark

#$ beeline -u jdbc:hive2://localhost:10000 -e "DESCRIBE devsh.accounts"
#hive

#hive> describe devsh.accounts;
spark
accountsDF = spark.read.table("devsh.accounts")

#$hive -e "SELECT * FROM devsh.accounts LIMIT 10"
#$hive -e "DESCRIBE devsh.accounts"

accountsDF = spark.read.table("devsh.accounts")

accountsDF.printSchema()
#accountsDF.where("zipcode = 94913").write.mode("append").option("header", "true").csv("/devsh_loudacre/accounts_zip94913")
accountsDF.where("zipcode = 94913").write.mode("overwrite").option("header", "true").csv("/devsh_loudacre/accounts_zip94913")

#$hdfs dfs -ls /devsh_loudacre/

acczip94913DF = spark.read.csv("/devsh_loudacre/accounts_zip94913")
acczip94913DF.printSchema()

acczip94913DF = spark.read.option("inferschema", "true").csv("/devsh_loudacre/accounts_zip94913") 
acczip94913DF.printSchema()

#$ hdfs dfs -ls /devsh_loudacre/devices*

devDF = spark.read.json("/devsh_loudacre/devices.json")

devDF.printSchema()

from pyspark.sql.types import *

devColumns = [
StructField("devnum",LongType()),
StructField("make",StringType()),
StructField("model",StringType()),
StructField("release_dt",TimestampType()),
StructField("dev_type",StringType())]

devSchema = StructType(devColumns)

devDF = spark.read.schema(devSchema).json("/devsh_loudacre/devices.json")

devDF.printSchema()

devDF.write.mode("overwrite").option("header", "true").save("/devsh_loudacre/devices_parquet")

#$ hdfs dfs -ls /devsh_loudacre/

#$ hdfs dfs -get /devsh_loudacre/devices_parquet /tmp/
#$ ls -l dev*

#$ parquet-tools schema /tmp/devices_parquet/
#message spark_schema{
#  optional binary dev_type (UTF8);
#  optional int64 devnum;
#  optional binary make (UTF8);
#  optional binary model (UTF8);
#  optional int96 release_dt;
#}

parquetDF = spark.read.parquet("/devsh_loudacre/devices_parquet")
parquetDF.printSchema()