//------------------
//Hands-On Exercise: Working with DataFrames and Schemas
//------------------

//scelisdev02@cca175-m:~/training_materials/devsh/data$ beeline -u jdbc:hive2://localhost:10000 -e "DESCRIBE devsh.accounts"
//scelisdev02@cca175-m:~/training_materials/devsh/data$ hive
//hive> describe devsh.accounts;
val accountsDF = spark.read.table("devsh.accounts")
//scelisdev02@cca175-m:/etc/hive/conf.dist$  hive -e "SELECT * FROM devsh.accounts LIMIT 10"

accountsDF.where("zipcode = 94913").write.mode("overwrite").option("header", "true").csv("/devsh_loudacre/accounts_zip94913")

//scelisdev02@cca175-m:~$ hdfs dfs -ls /devsh_loudacre/

val acczip94913DF = spark.read.csv("/devsh_loudacre/accounts_zip94913")

acczip94913DF.printSchema

val acczip94913DF = spark.read.options(Map("inferSchema"->"true", "header"->"true")).csv("/devsh_loudacre/accounts_zip94913")

acczip94913DF.printSchema
//scelisdev02@cca175-m:~$ hdfs dfs -ls /devsh_loudacre/devices*

val devDF = spark.read.json("/devsh_loudacre/devices.json")
import org.apache.spark.sql.types._

val devColumns = List(
StructField("devnum",LongType),
StructField("make",StringType),
StructField("model",StringType),
StructField("release_dt",TimestampType),
StructField("dev_type",StringType))

val devColumns = List(StructField("devnum", LongType), StructField("make", StringType), StructField("model", StringType), StructField("release_dt",TimestampType), StructField("dev_type", StringType))

val devSchema = StructType(devColumns)

val devDF = spark.read.schema(devSchema).json("/devsh_loudacre/devices.json")

devDF.printSchema

devDF.write.mode("overwrite").save("/devsh_loudacre/devices_parquet")

//scelisdev02@cca175-m:~$ hdfs dfs -ls /devsh_loudacre/

//scelisdev02@cca175-m:~$ hdfs dfs -get /devsh_loudacre/devices_parquet /tmp/
//scelisdev02@cca175-m:/tmp$ ls -l dev*
/*
[training@dev ~]$ parquet-tools schema /tmp/devices_parquet/
message spark_schema{
  optional binary dev_type (UTF8);
  optional int64 devnum;
  optional binary make (UTF8);
  optional binary model (UTF8);
  optional int96 release_dt;
}
*/

val parDF = spark.read.parquet("/devsh_loudacre/devices_parquet")

parDF.printSchema
